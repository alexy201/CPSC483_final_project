{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a8d9fa0",
   "metadata": {},
   "source": [
    "# Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7250ceb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import collections\n",
    "import torch\n",
    "import random\n",
    "import math\n",
    "import time\n",
    "print(\"Using torch\", torch.__version__)\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "random.seed(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8715bcb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.datasets import MovieLens100K, IGMCDataset\n",
    "\n",
    "mov = MovieLens100K('/tmp/movielens')[0]\n",
    "#doub = IGMCDataset('/tmp/douban', 'Douban')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e12d5e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_nodes = mov.num_nodes\n",
    "print('dataset has {} nodes'.format(num_nodes))\n",
    "\n",
    "num_edges = mov.num_edges\n",
    "print('dataset has {} edges'.format(num_edges))\n",
    "\n",
    "num_users = mov['user'].x.shape[0]\n",
    "print('dataset has {} users'.format(num_users))\n",
    "\n",
    "num_movies = mov['movie'].x.shape[0]\n",
    "print('dataset has {} items'.format(num_movies))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c00ec60",
   "metadata": {},
   "source": [
    "# Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab6d9538",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_edge_weights = True  #@param {type: \"boolean\"}: Determine whether model uses edge weights as attention coefficients\n",
    "\n",
    "config_dict = {\n",
    "    \"num_samples_per_user\": 200,\n",
    "    \"num_users\": num_users,\n",
    "\n",
    "    \"epochs\": 50,\n",
    "    \"batch_size\": 100,\n",
    "    \"lr\": 0.001,\n",
    "    \"weight_decay\": 1,\n",
    "\n",
    "    \"embedding_size\": 64,\n",
    "    \"num_layers\": 5,\n",
    "    \"mf_rank\": 8,\n",
    "\n",
    "    \"minibatch_per_print\": 100,\n",
    "    \"epochs_per_print\": 1,\n",
    "\n",
    "    \"val_frac\": 0.2,\n",
    "    \"test_frac\": 0.1,\n",
    "\n",
    "    \"K\": 10,\n",
    "\n",
    "    \"model_name\": \"model.pth\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a56cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def edge_list_to_adjacency(edge_index, ratings, user_num, item_num):\n",
    "    # Create an empty adjacency matrix\n",
    "    adjacency = torch.zeros(user_num, item_num)\n",
    "    \n",
    "    # Fill the adjacency matrix using the edge list\n",
    "    for i in range(edge_index.size(1)):\n",
    "        start_node = edge_index[0, i].item()\n",
    "        end_node = edge_index[1, i].item()\n",
    "        #adjacency[start_node, end_node] = ratings[i]\n",
    "        \n",
    "        if ratings[i] > rating_threshold:\n",
    "            adjacency[start_node, end_node] = 1  # Assuming it's an unweighted graph\n",
    "    \n",
    "    return adjacency\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "global_edge_index = edge_list_to_adjacency(\n",
    "    mov[('user', 'rates', 'movie')]['edge_index'],\n",
    "    mov[('user', 'rates', 'movie')]['rating'],\n",
    "    num_users,\n",
    "    num_movies\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0527433",
   "metadata": {},
   "source": [
    "# Model Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5bc295b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn, optim, Tensor\n",
    "from torch_geometric.nn import MessagePassing\n",
    "from torch_geometric.typing import Adj\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class LightGCNConv(MessagePassing):\n",
    "    r\"\"\"The neighbor aggregation operator from the `\"LightGCN: Simplifying and\n",
    "    Powering Graph Convolution Network for Recommendation\"\n",
    "    <https://arxiv.org/abs/2002.02126#>`_ paper\n",
    "\n",
    "    Args:\n",
    "        in_channels (int): Size of each input sample, or :obj:`-1` to derive\n",
    "            the size from the first input(s) to the forward method.\n",
    "        out_channels (int): Size of each output sample.\n",
    "        num_users (int): Number of users for recommendation.\n",
    "        num_items (int): Number of items to recommend.\n",
    "        **kwargs (optional): Additional arguments of\n",
    "            :class:`torch_geometric.nn.conv.MessagePassing`.\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels: int, out_channels: int,\n",
    "                 num_users: int, num_items: int, **kwargs):\n",
    "        super(LightGCNConv, self).__init__(**kwargs)\n",
    "\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "\n",
    "        self.num_users = num_users\n",
    "        self.num_items = num_items\n",
    "\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        pass  # There are no layer parameters to learn.\n",
    "\n",
    "    def forward(self, x: Tensor, edge_index: Adj) -> Tensor:\n",
    "        \"\"\"Performs neighborhood aggregation for user/item embeddings.\"\"\"\n",
    "        user_item = \\\n",
    "                torch.zeros(self.num_users, self.num_items, device=x.device)\n",
    "        user_item[edge_index[:, 0], edge_index[:, 1]] = 1 # global_edge_index[edge_index[:, 0], edge_index[:, 1]]\n",
    "\n",
    "        att = \\\n",
    "                torch.zeros(self.num_users, self.num_items, device=x.device)\n",
    "        att[edge_index[:, 0], edge_index[:, 1]] = global_edge_index[edge_index[:, 0], edge_index[:, 1]]\n",
    "\n",
    "        user_neighbor_counts = torch.sum((user_item > 0), axis=1)\n",
    "        item_neightbor_counts = torch.sum((user_item > 0), axis=0)\n",
    "\n",
    "        # Compute weight for aggregation: 1 / sqrt(N_u * N_i)\n",
    "\n",
    "        if use_edge_weights:\n",
    "            weights = att / torch.sqrt(\n",
    "                user_neighbor_counts.repeat(self.num_items, 1).T \\\n",
    "                * item_neightbor_counts.repeat(self.num_users, 1))\n",
    "        else:\n",
    "            weights = (user_item > 0) / torch.sqrt(\n",
    "                    user_neighbor_counts.repeat(self.num_items, 1).T \\\n",
    "                    * item_neightbor_counts.repeat(self.num_users, 1))\n",
    "        \n",
    "        weights = torch.nan_to_num(weights, nan=0)\n",
    "        out = torch.concat((weights.T @ x[:self.num_users],\n",
    "                            weights @ x[self.num_users:]), 0)\n",
    "        return out\n",
    "\n",
    "    def __repr__(self):\n",
    "        return '{}({}, {})'.format(self.__class__.__name__, self.in_channels,\n",
    "                                   self.out_channels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54dfd56b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LightGCN(nn.Module):\n",
    "    def __init__(self, \n",
    "                 config: dict,\n",
    "                 device=None,\n",
    "                 **kwargs):\n",
    "        super().__init__()\n",
    "\n",
    "        self.num_users  = config[\"n_users\"]\n",
    "        self.num_items  = config[\"m_items\"]\n",
    "        self.embedding_size = config[\"embedding_size\"]\n",
    "        self.in_channels = self.embedding_size\n",
    "        self.out_channels = self.embedding_size\n",
    "        self.num_layers = config[\"num_layers\"]\n",
    "\n",
    "        # 0-th layer embedding.\n",
    "        self.embedding_user_item = torch.nn.Embedding(\n",
    "            num_embeddings=self.num_users + self.num_items,\n",
    "            embedding_dim=self.embedding_size)\n",
    "        self.alpha = None\n",
    "\n",
    "        # random normal init seems to be a better choice when lightGCN actually\n",
    "        # don't use any non-linear activation function\n",
    "        nn.init.normal_(self.embedding_user_item.weight, std=0.1)\n",
    "        print('use NORMAL distribution initilizer')\n",
    "\n",
    "        self.f = nn.Sigmoid()\n",
    "\n",
    "        self.convs = nn.ModuleList()\n",
    "        self.convs.append(LightGCNConv(\n",
    "                self.embedding_size, self.embedding_size,\n",
    "                num_users=self.num_users, num_items=self.num_items, **kwargs))\n",
    "\n",
    "        for _ in range(1, self.num_layers):\n",
    "            self.convs.append(\n",
    "                LightGCNConv(\n",
    "                        self.embedding_size, self.embedding_size, \n",
    "                        num_users=self.num_users, num_items=self.num_items,\n",
    "                        **kwargs))\n",
    "\n",
    "        self.device = None\n",
    "        if device is not None:\n",
    "            self.convs.to(device)\n",
    "            self.device = device\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        for conv in self.convs:\n",
    "            conv.reset_parameters()\n",
    "\n",
    "    def forward(self, x: Tensor, edge_index: Adj, *args, **kwargs) -> Tensor:\n",
    "        xs: List[Tensor] = []\n",
    "\n",
    "        edge_index = torch.nonzero(edge_index)\n",
    "        for i in range(self.num_layers):\n",
    "            x = self.convs[i](x, edge_index, *args, **kwargs)\n",
    "            if self.device is not None:\n",
    "                x = x.to(self.device)\n",
    "            xs.append(x)\n",
    "        xs = torch.stack(xs)\n",
    "        \n",
    "        self.alpha = 1 / (1 + self.num_layers) * torch.ones(xs.shape)\n",
    "        if self.device is not None:\n",
    "            self.alpha = self.alpha.to(self.device)\n",
    "            xs = xs.to(self.device)\n",
    "        x = (xs * self.alpha).sum(dim=0)  # Sum along K layers.\n",
    "        return x\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return (f'{self.__class__.__name__}({self.in_channels}, '\n",
    "                f'{self.out_channels}, num_layers={self.num_layers})')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4df0a3d7",
   "metadata": {},
   "source": [
    "# Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b49659ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getUsersRating(model, users, data):\n",
    "    \"\"\" Get the embedding of users\n",
    "    INPUT:\n",
    "        model: the LightGCN model you are training on\n",
    "        users: this is the user index (note: use 0-indexed and not user number,\n",
    "            which is 1-indexed)\n",
    "        data: the entire data, used to fetch all users and all items\n",
    "    \"\"\"\n",
    "    all_users_items = model(model.embedding_user_item.weight.clone(), global_edge_index)\n",
    "    #print(\"USERS: \", users)\n",
    "    #print(\"ALL USERS ITMES: \", all_users_items)\n",
    "    #print(\"ALL USERS SHAPE: \", all_users_items.shape)\n",
    "    all_users = all_users_items[:len(data[\"user\"].x)]\n",
    "    items_emb = all_users_items[len(data[\"user\"].x):]\n",
    "    users_emb = all_users[users.long()]\n",
    "    rating = model.f(torch.matmul(users_emb, items_emb.t()))\n",
    "    #print(\"RATING: \", rating)\n",
    "    return rating\n",
    "\n",
    "def getEmbedding(model, users, pos, neg, data, mask):\n",
    "    \"\"\"\n",
    "    INPUT:\n",
    "        model: the LightGCN model you are training on\n",
    "        users: this is the user index (note: use 0-indexed and not user number,\n",
    "            which is 1-indexed)\n",
    "        pos: positive index corresponding to an item that the user like\n",
    "        neg: negative index corresponding to an item that the user doesn't like\n",
    "        data: the entire data, used to fetch all users and all items\n",
    "        mask: Masking matrix indicating edges present in the current\n",
    "            train / validation / test set.\n",
    "    \"\"\"\n",
    "    # assuming we always search for users and items by their indices (instead of\n",
    "    # user/item number)\n",
    "    all_users_items = model(model.embedding_user_item.weight.clone(),\n",
    "                            global_edge_index * mask)\n",
    "    # print(all_users_items)\n",
    "    all_users = all_users_items[:len(data[\"user\"].x)]\n",
    "    all_items = all_users_items[len(data[\"user\"].x):]\n",
    "    users_emb = all_users[users]\n",
    "    pos_emb = all_items[pos]\n",
    "    neg_emb = all_items[neg]\n",
    "    n_user = len(data[\"user\"].x)\n",
    "    users_emb_ego = model.embedding_user_item(users)\n",
    "    # offset the index to fetch embedding from user_item\n",
    "    pos_emb_ego = model.embedding_user_item(pos + n_user)\n",
    "    neg_emb_ego = model.embedding_user_item(neg + n_user)\n",
    "    return users_emb, pos_emb, neg_emb, users_emb_ego, pos_emb_ego, neg_emb_ego"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96f0e5c7",
   "metadata": {},
   "source": [
    "# Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f2f9971",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bpr_loss(model, users, pos, neg, data, mask):\n",
    "    \"\"\" \n",
    "    INPUT:\n",
    "        model: the LightGCN model you are training on\n",
    "        users: this is the user index (note: use 0-indexed and not user number,\n",
    "            which is 1-indexed)\n",
    "        pos: positive index corresponding to an item that the user like\n",
    "            (0-indexed, note to index items starting from 0)\n",
    "        neg: negative index corresponding to an item that the user doesn't like\n",
    "        data: the entire data, used to fetch all users and all items\n",
    "        mask: Masking matrix indicating edges present in the current\n",
    "            train / validation / test set.\n",
    "    OUTPUT:\n",
    "        loss, reg_loss\n",
    "    \"\"\"\n",
    "    # assuming we always sample the same number of positive and negative sample\n",
    "    # per user\n",
    "    assert len(users) == len(pos) and len(users) == len(neg)\n",
    "    (users_emb, pos_emb, neg_emb, \n",
    "    userEmb0,  posEmb0, negEmb0) = getEmbedding(model, users.long(), pos.long(),\n",
    "                                                neg.long(), data, mask)\n",
    "    reg_loss = (1/2)*(userEmb0.norm(2).pow(2) + \n",
    "                        posEmb0.norm(2).pow(2)  +\n",
    "                        negEmb0.norm(2).pow(2))/float(len(users))\n",
    "    pos_scores = torch.mul(users_emb, pos_emb)\n",
    "    pos_scores = torch.sum(pos_scores, dim=1)\n",
    "    neg_scores = torch.mul(users_emb, neg_emb)\n",
    "    neg_scores = torch.sum(neg_scores, dim=1)\n",
    "    \n",
    "    loss = torch.mean(torch.nn.functional.softplus(neg_scores - pos_scores))\n",
    "    \n",
    "    return loss, reg_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d150b0e4",
   "metadata": {},
   "source": [
    "# Personalized Top K Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e47c6da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def personalized_topk(pred, K, user_indices, edge_index):\n",
    "    \"\"\"Computes TopK precision and recall.\n",
    "\n",
    "    Args:\n",
    "        pred: Predicted similarities between user and item.\n",
    "        K: Number of items to rank.\n",
    "        user_indices: Indices of users for each prediction in `pred`.\n",
    "        edge_index: User and item connection matrix.\n",
    "\n",
    "    Returns:\n",
    "        Average Top K precision and recall for users in `user_indices`.\n",
    "    \"\"\"\n",
    "    per_user_preds = collections.defaultdict(list)\n",
    "    for index, user in enumerate(user_indices):\n",
    "        per_user_preds[user.item()].append(pred[index].item())\n",
    "    precisions = 0.0\n",
    "    recalls = 0.0\n",
    "    for user, preds in per_user_preds.items():\n",
    "        while len(preds) < K:\n",
    "            preds.append(random.choice(range(edge_index.shape[1])))\n",
    "        top_ratings, top_items = torch.topk(torch.tensor(preds), K)\n",
    "        correct_preds = edge_index[user, top_items].sum().item()\n",
    "        total_pos = edge_index[user].sum().item()\n",
    "        precisions += correct_preds / K\n",
    "        recalls += correct_preds / total_pos if total_pos != 0 else 0\n",
    "    num_users = len(user_indices.unique())\n",
    "    return precisions / num_users, recalls / num_users\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e6d53f4",
   "metadata": {},
   "source": [
    "# Training, Validation, and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1852ec82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _sample_pos_neg(data, mask, num_samples_per_user):\n",
    "    \"\"\"Samples (user, positive item, negative item) tuples per user.\n",
    "\n",
    "    If a user does not have a postive (negative) item, we choose an item\n",
    "    with unknown liking (an item without raw rating data).\n",
    "\n",
    "    Args:\n",
    "        data: Dataset object containing edge_index and raw ratings matrix.\n",
    "        mask: Masking matrix indicating edges present in the current\n",
    "            train / validation / test set.\n",
    "        num_samples_per_user: Number of samples to generate for each user.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor object of (user, positive item, negative item) samples.\n",
    "    \"\"\"\n",
    "    print(\"=====Starting to sample=====\")\n",
    "    start = time.time()\n",
    "    samples = []\n",
    "    all_items = set(range(len(data[\"movie\"].x)))\n",
    "    #print(data[\"movie\"].x)\n",
    "    #print(data[\"user\"].x)\n",
    "    #print(\"DEBUG: \", len(data[\"movie\"].x), len(data[\"user\"].x))\n",
    "    for user_index, user in enumerate(data[\"user\"].x):\n",
    "        #print(\"HERE: \", user_index, user)\n",
    "        pos_items = set(\n",
    "            torch.nonzero(global_edge_index[user_index])[:, 0].tolist())\n",
    "        #print(\"POSITIVE: \", pos_items)\n",
    "        unknown_items = all_items.difference(\n",
    "                set(\n",
    "                    torch.nonzero(global_edge_index[user_index])[:, 0].tolist()))\n",
    "        neg_items = all_items.difference(\n",
    "            set(pos_items)).difference(set(unknown_items))\n",
    "        unmasked_items = set(torch.nonzero(mask[user_index])[:, 0].tolist())\n",
    "        if len(unknown_items.union(pos_items)) == 0 or \\\n",
    "                len(unknown_items.union(neg_items)) == 0:\n",
    "            continue\n",
    "        for _ in range(num_samples_per_user):\n",
    "            if len(pos_items.intersection(unmasked_items)) == 0:\n",
    "                pos_item_index = random.choice(\n",
    "                    list(unknown_items.intersection(unmasked_items)))\n",
    "            else:\n",
    "                pos_item_index = random.choice(\n",
    "                    list(pos_items.intersection(unmasked_items)))\n",
    "            if len(neg_items.intersection(unmasked_items)) == 0:\n",
    "                neg_item_index = random.choice(\n",
    "                    list(unknown_items.intersection(unmasked_items)))\n",
    "            else:\n",
    "                neg_item_index = random.choice(\n",
    "                    list(neg_items.intersection(unmasked_items)))\n",
    "            samples.append((user_index, pos_item_index, neg_item_index))\n",
    "    end = time.time()\n",
    "    print(f\"=====Sampling completed (took {end - start} seconds)=====\")\n",
    "    return torch.tensor(samples, dtype=torch.int32)\n",
    "\n",
    "def sample_pos_neg(data, train_mask, val_mask, test_mask, num_samples_per_user):\n",
    "    \"\"\"Samples (user, positive item, negative item) tuples per user.\n",
    "\n",
    "    If a user does not have a postive (negative) item, we choose an item\n",
    "    with unknown liking (an item without raw rating data).\n",
    "\n",
    "    Args:\n",
    "        data: Dataset object containing edge_index and raw ratings matrix.\n",
    "        train_mask: Masking matrix indicating edges present in train set.\n",
    "        val_mask: Masking matrix indicating edges present in validation set.\n",
    "        test_mask: Masking matrix indicating edges present in test set.\n",
    "        num_samples_per_user: Number of samples to generate for each user.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor object of (user, positive item, negative item) samples for\n",
    "        train, validation and test.\n",
    "    \"\"\"\n",
    "    train_samples = _sample_pos_neg(data, train_mask, num_samples_per_user)\n",
    "    val_samples = _sample_pos_neg(data, val_mask, num_samples_per_user)\n",
    "    test_samples = _sample_pos_neg(data, test_mask, num_samples_per_user)\n",
    "    return train_samples, val_samples, test_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d0c451",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_users = mov['user'].x.shape[0]\n",
    "m_items = mov['movie'].x.shape[0]\n",
    "\n",
    "def train_val_test_split(num_user, num_item, val_frac, test_frac):\n",
    "    \"\"\"\n",
    "    Return two mask matrices (M, N) that represents edges present in the\n",
    "    train and validation set\n",
    "    \"\"\"\n",
    "    # get number of edges masked for training and validation\n",
    "    num_train_replaced = round((test_frac+val_frac)*num_user*num_item)\n",
    "    num_val_show = round(val_frac*num_user*num_item)\n",
    "\n",
    "    # edges masked during training\n",
    "    indices_user = np.random.randint(0, num_user, num_train_replaced)\n",
    "    indices_item = np.random.randint(0, num_item, num_train_replaced)\n",
    "\n",
    "    # sample part of edges from training stage to be unmasked during\n",
    "    # validation\n",
    "    indices_val_user = np.random.choice(indices_user, num_val_show)\n",
    "    indices_val_item = np.random.choice(indices_item, num_val_show)\n",
    "\n",
    "    train_mask = torch.ones(num_user, num_item)\n",
    "    train_mask[indices_user, indices_item] = 0\n",
    "\n",
    "    val_mask = train_mask.clone()\n",
    "    val_mask[indices_val_user, indices_val_item] = 1\n",
    "\n",
    "    test_mask = torch.ones_like(train_mask)\n",
    "\n",
    "    return train_mask, val_mask, test_mask\n",
    "\n",
    "\n",
    "train_mask, val_mask, test_mask = train_val_test_split(\n",
    "    num_user = n_users,\n",
    "    num_item = m_items,\n",
    "    val_frac = config_dict[\"val_frac\"],\n",
    "    test_frac = config_dict[\"test_frac\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47769412",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config = {\n",
    "    \"n_users\": n_users,\n",
    "    \"m_items\": m_items,\n",
    "    \"embedding_size\": config_dict[\"embedding_size\"],\n",
    "    \"num_layers\": config_dict[\"num_layers\"],\n",
    "}\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"DEVICE: \", device)\n",
    "lightGCN = LightGCN(model_config, device=device)\n",
    "\n",
    "num_samples_per_user = config_dict[\"num_samples_per_user\"]\n",
    "epochs = config_dict[\"epochs\"]\n",
    "batch_size = config_dict[\"batch_size\"]\n",
    "lr = config_dict[\"lr\"]\n",
    "weight_decay = config_dict[\"weight_decay\"]\n",
    "\n",
    "lightGCN.to(device)\n",
    "\n",
    "samples_train, samples_val, samples_test = sample_pos_neg(\n",
    "    mov, train_mask, val_mask, test_mask, num_samples_per_user)\n",
    "\n",
    "samples_train=samples_train.to(device)\n",
    "samples_val=samples_val.to(device)\n",
    "samples_test=samples_test.to(device)\n",
    "train_mask=train_mask.to(device)\n",
    "val_mask=val_mask.to(device)\n",
    "test_mask=test_mask.to(device)\n",
    "mov = mov.to(device)\n",
    "\n",
    "print(f\"#Training samples: {len(samples_train)}\",\n",
    "      f\"#Validation samples: {len(samples_val)}\",\n",
    "      f\"#Test samples: {len(samples_test)}\")\n",
    "\n",
    "optimizer = optim.Adam(lightGCN.parameters(), lr=lr)\n",
    "print(\"Optimizer:\", optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5467c096-bda5-465a-818e-23264197e9a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_tracked = []\n",
    "train_topks = []\n",
    "val_topks = []\n",
    "bprs = []\n",
    "K = config_dict[\"K\"]\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(\"Training on the {} epoch\".format(epoch))\n",
    "    lightGCN.train()\n",
    "    loss_sum = 0\n",
    "    # Shuffle the order of rows.\n",
    "    samples_train = samples_train[torch.randperm(samples_train.size()[0])]\n",
    "    for batch_idx in range(math.ceil(len(samples_train) / batch_size)):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        current_batch = \\\n",
    "            samples_train[batch_idx*batch_size: (batch_idx+1)*batch_size]\n",
    "        # Shuffle the order of rows.\n",
    "        current_batch = current_batch[torch.randperm(current_batch.size()[0])]\n",
    "        users = current_batch[:, 0:1]\n",
    "        pos = current_batch[:, 1:2]\n",
    "        neg = current_batch[:, 2:3]\n",
    "\n",
    "        loss, reg_loss = bpr_loss(lightGCN, users, pos, neg, mov,\n",
    "                                  train_mask)\n",
    "        reg_loss = reg_loss * weight_decay\n",
    "        loss = loss + reg_loss\n",
    "        loss_sum += loss.detach()\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch_idx % config_dict[\"minibatch_per_print\"] == 0:\n",
    "            all_users = torch.linspace(start=0,\n",
    "                                       end=n_users - 1, steps=n_users).long()\n",
    "            user_indices = current_batch[:, 0]\n",
    "            user_indices = user_indices.repeat(2).long()\n",
    "            item_indices = torch.cat(\n",
    "                (current_batch[:, 1], current_batch[:, 2])).long()\n",
    "            pred = getUsersRating(lightGCN,\n",
    "                                  all_users,\n",
    "                                  mov)[user_indices, item_indices]\n",
    "            truth = global_edge_index[user_indices, item_indices]\n",
    "            topk_precision, topk_recall = \\\n",
    "                personalized_topk(pred, K, user_indices, global_edge_index)\n",
    "\n",
    "            print(\"Training on epoch {} minibatch {}/{} completed\\n\".format(epoch, batch_idx+1,\n",
    "                                                                            math.ceil(len(samples_train) / batch_size)),\n",
    "                  \"bpr_loss on current minibatch is {}, and regularization loss is {}.\\n\".format(round(float(loss.detach().cpu()), 6),\n",
    "                                                                                                 round(float(reg_loss.detach().cpu()), 6)),\n",
    "                  \"Top K precision = {}, recall = {}.\".format(topk_precision, topk_recall))\n",
    "\n",
    "    if epoch % config_dict[\"epochs_per_print\"] == 0:\n",
    "        epochs_tracked.append(epoch)\n",
    "\n",
    "        # evaluation on both the trainisng and validation set\n",
    "        lightGCN.eval()\n",
    "        # predict on the training set\n",
    "        users = samples_train[:, 0:1]\n",
    "        user_indices = samples_train[:, 0]\n",
    "        user_indices = user_indices.repeat(2).long()\n",
    "        item_indices = torch.cat(\n",
    "            (samples_train[:, 1], samples_train[:, 2])).long()\n",
    "        pred = getUsersRating(lightGCN,\n",
    "                              users[:,0],\n",
    "                              mov)[user_indices, item_indices]\n",
    "        truth = global_edge_index[users.long()[:,0]]\\\n",
    "            [user_indices, item_indices]\n",
    "        train_topk_precision, train_topk_recall = \\\n",
    "            personalized_topk(pred, K, user_indices, global_edge_index)\n",
    "        train_topks.append((train_topk_precision, train_topk_recall))\n",
    "\n",
    "        # predict on the validation set\n",
    "        users_val = samples_val[:, 0:1]\n",
    "        pos_val = samples_val[:, 1:2]\n",
    "        neg_val = samples_val[:, 2:3]\n",
    "\n",
    "        loss_val, reg_loss_val = bpr_loss(\n",
    "            lightGCN, users_val, pos_val, neg_val, mov, val_mask)\n",
    "        bprs.append(round(float((loss_val+reg_loss_val)/len(samples_val)), 6))\n",
    "        reg_loss_val = reg_loss_val * weight_decay\n",
    "\n",
    "        # predict on the validation set\n",
    "        user_indices = samples_val[:, 0]\n",
    "        user_indices = user_indices.repeat(2).long()\n",
    "        item_indices = torch.cat((samples_val[:, 1], samples_val[:, 2])).long()\n",
    "        pred_val = getUsersRating(lightGCN,\n",
    "                                  users_val[:,0],\n",
    "                                  mov)[user_indices, item_indices]\n",
    "        truth_val = global_edge_index[users_val.long()[:,0]]\\\n",
    "            [user_indices, item_indices]\n",
    "        val_topk_precision, val_topk_recall = \\\n",
    "            personalized_topk(pred_val, K, user_indices, global_edge_index)\n",
    "        val_topks.append((val_topk_precision, val_topk_recall))\n",
    "\n",
    "        print(\"\\nTraining on {} epoch completed.\\n\".format(epoch),\n",
    "              \"Average bpr_loss on train set is {} for the current epoch.\\n\".format(round(float(loss_sum/len(samples_train)), 6)),\n",
    "              \"Training top K precision = {}, recall = {}.\\n\".format(train_topk_precision, train_topk_recall),\n",
    "              \"Average bpr_loss on the validation set is {}, and regularization loss is {}.\\n\".format(round(float((loss_val+reg_loss_val)/len(samples_val)), 6),\n",
    "                                                                                                      round(float(reg_loss_val/len(samples_val)), 6)),\n",
    "              \"Validation top K precision = {}, recall = {}.\\n\".format(val_topk_precision, val_topk_recall))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e5740ad-ce2c-44cd-853f-dac2bad6e06d",
   "metadata": {},
   "source": [
    "# Plot Top K over epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f940387-40e0-4216-8597-c072f804d54f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(epochs_tracked, [precision for precision, _ in train_topks],\n",
    "         label=\"Train\")\n",
    "plt.plot(epochs_tracked, [precision for precision, _ in val_topks],\n",
    "         label=\"Val\")\n",
    "#plt.plot(epochs_tracked, [loss for loss in bprs],\n",
    "#         label=\"BPR Loss\")\n",
    "plt.ylabel(f\"Top {K} precision\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.legend()\n",
    "plt.title(\"Top 10 Precision for LightGCN on MovieLens100K (500 samples/user)\")\n",
    "plt.show()\n",
    "\n",
    "plt.plot(epochs_tracked, [loss for loss in bprs],\n",
    "         label=\"BPR Loss\")\n",
    "plt.ylabel(f\"Loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "362ce4f8-dafb-4874-949e-b4f5f7bb3b33",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db294ae3-07df-4550-a387-fd4100a09696",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict on the test set\n",
    "lightGCN.eval()\n",
    "print(\"Training completed after {} epochs\".format(epochs))\n",
    "\n",
    "users_test = samples_test[:, 0:1]\n",
    "pos_test = samples_test[:, 1:2]\n",
    "neg_test = samples_test[:, 2:3]\n",
    "\n",
    "loss_test, reg_loss_test = bpr_loss(\n",
    "    lightGCN, users_test, pos_test, neg_test, mov, test_mask)\n",
    "reg_loss_test = reg_loss_test * weight_decay\n",
    "\n",
    "# predict on the test set\n",
    "user_indices = samples_test[:, 0]\n",
    "user_indices = user_indices.repeat(2).long()\n",
    "item_indices = torch.cat((samples_test[:, 1], samples_test[:, 2])).long()\n",
    "pred_test = getUsersRating(lightGCN, users_test[:,0], mov)\\\n",
    "    [user_indices, item_indices]\n",
    "truth_test = global_edge_index[users_test.long()[:,0]]\\\n",
    "    [user_indices, item_indices]\n",
    "test_topk_precision, test_topk_recall = personalized_topk(\n",
    "    pred_test, K, user_indices, global_edge_index)\n",
    "\n",
    "print(\"Average bpr_loss on the test set is {}, and regularization loss is {}.\\n\".format(round(float((loss_test+reg_loss_test)/len(samples_test)), 6),\n",
    "                                                                                                round(float(reg_loss_test/len(samples_test)), 6)),\n",
    "      \"Top K precision = {}, recall = {}.\".format(test_topk_precision, test_topk_recall))\n",
    "\n",
    "# Save model embeddings.\n",
    "torch.save(lightGCN, config_dict[\"model_name\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64d33dad-8bb4-4f4b-8874-b1fa1c6c1609",
   "metadata": {},
   "source": [
    "# Baseline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c8a704",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorly import decomposition\n",
    "\n",
    "def matrix_factorization(user_item, rank):\n",
    "    \"\"\"Runs matrix factorization on `user_item` and get user-item similarities.\n",
    "\n",
    "    Args:\n",
    "        user_item: User-item connectivity matrix.\n",
    "        rank: Number of numbers to represent a user / item.\n",
    "\n",
    "    Returns:\n",
    "        User-item similarities.\n",
    "    \"\"\"\n",
    "    weights, (user_factors, item_factors) = \\\n",
    "        decomposition.parafac(user_item, rank)\n",
    "    similarities = user_factors @ item_factors.T\n",
    "    return 1 / (1 + np.exp(- similarities))\n",
    "\n",
    "# Compute baseline metrics using matrix factorization.\n",
    "user_indices = samples_test[:, 0]\n",
    "user_indices = user_indices.repeat(2).long()\n",
    "item_indices = torch.cat((samples_test[:, 1], samples_test[:, 2])).long()\n",
    "baseline_pred = matrix_factorization(\n",
    "        global_edge_index.detach().cpu().numpy(),\n",
    "        config_dict[\"mf_rank\"])[user_indices.cpu(), item_indices.cpu()]\n",
    "baseline_topk_precision, baseline_topk_recall = \\\n",
    "        personalized_topk(baseline_pred, config_dict[\"K\"], user_indices, global_edge_index)\n",
    "print(\"Baseline (PARAFAC matrix factorization) produces \",\n",
    "      \"Top K precision = {}, recall = {}.\".format(baseline_topk_precision,\n",
    "                                                  baseline_topk_recall))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
