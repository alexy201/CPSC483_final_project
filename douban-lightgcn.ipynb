{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a8d9fa0",
   "metadata": {},
   "source": [
    "# Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7250ceb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using torch 2.1.0+cu121\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import collections\n",
    "import torch\n",
    "import random\n",
    "import math\n",
    "import time\n",
    "print(\"Using torch\", torch.__version__)\n",
    "\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8715bcb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading https://github.com/muhanzhang/IGMC/raw/master/raw_data/douban/training_test_dataset.mat\n",
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.datasets import MovieLens100K, IGMCDataset\n",
    "\n",
    "mov = IGMCDataset('/tmp/douban', 'Douban')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e12d5e81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset has 6000 nodes\n",
      "dataset has 246404 edges\n",
      "dataset has 3000 users\n",
      "dataset has 3000 items\n"
     ]
    }
   ],
   "source": [
    "num_nodes = mov.num_nodes\n",
    "print('dataset has {} nodes'.format(num_nodes))\n",
    "\n",
    "num_edges = mov.num_edges\n",
    "print('dataset has {} edges'.format(num_edges))\n",
    "\n",
    "num_users = mov['user'].x.shape[0]\n",
    "print('dataset has {} users'.format(num_users))\n",
    "\n",
    "num_movies = mov['item'].x.shape[0]\n",
    "print('dataset has {} items'.format(num_movies))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c00ec60",
   "metadata": {},
   "source": [
    "# Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ab6d9538",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_edge_weights = True  #@param {type: \"boolean\"}: Determine whether model uses edge weights as attention coefficients\n",
    "\n",
    "config_dict = {\n",
    "    \"num_samples_per_user\": 100,\n",
    "    \"num_users\": num_users,\n",
    "\n",
    "    \"epochs\": 50,\n",
    "    \"batch_size\": 60,\n",
    "    \"lr\": 0.001,\n",
    "    \"weight_decay\": 1,\n",
    "\n",
    "    \"embedding_size\": 64,\n",
    "    \"num_layers\": 3,\n",
    "    \"mf_rank\": 8,\n",
    "\n",
    "    \"minibatch_per_print\": 100,\n",
    "    \"epochs_per_print\": 1,\n",
    "\n",
    "    \"val_frac\": 0.2,\n",
    "    \"test_frac\": 0.1,\n",
    "\n",
    "    \"K\": 10,\n",
    "\n",
    "    \"model_name\": \"model.pth\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e6a56cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def edge_list_to_adjacency(edge_index, ratings, user_num, item_num):\n",
    "    # Create an empty adjacency matrix\n",
    "    adjacency = torch.zeros(user_num, item_num)\n",
    "    \n",
    "    # Fill the adjacency matrix using the edge list\n",
    "    for i in range(edge_index.size(1)):\n",
    "        start_node = edge_index[0, i].item()\n",
    "        end_node = edge_index[1, i].item()\n",
    "        #adjacency[start_node, end_node] = ratings[i]\n",
    "        \n",
    "        if ratings[i] > rating_threshold:\n",
    "            adjacency[start_node, end_node] = 1  # Assuming it's an unweighted graph\n",
    "    \n",
    "    return adjacency\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "global_edge_index = edge_list_to_adjacency(\n",
    "    mov[('user', 'rates', 'item')]['edge_index'],\n",
    "    mov[('user', 'rates', 'item')]['rating'],\n",
    "    num_users,\n",
    "    num_movies\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0527433",
   "metadata": {},
   "source": [
    "# Model Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b5bc295b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn, optim, Tensor\n",
    "from torch_geometric.nn import MessagePassing\n",
    "from torch_geometric.typing import Adj\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class LightGCNConv(MessagePassing):\n",
    "    r\"\"\"The neighbor aggregation operator from the `\"LightGCN: Simplifying and\n",
    "    Powering Graph Convolution Network for Recommendation\"\n",
    "    <https://arxiv.org/abs/2002.02126#>`_ paper\n",
    "\n",
    "    Args:\n",
    "        in_channels (int): Size of each input sample, or :obj:`-1` to derive\n",
    "            the size from the first input(s) to the forward method.\n",
    "        out_channels (int): Size of each output sample.\n",
    "        num_users (int): Number of users for recommendation.\n",
    "        num_items (int): Number of items to recommend.\n",
    "        **kwargs (optional): Additional arguments of\n",
    "            :class:`torch_geometric.nn.conv.MessagePassing`.\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels: int, out_channels: int,\n",
    "                 num_users: int, num_items: int, **kwargs):\n",
    "        super(LightGCNConv, self).__init__(**kwargs)\n",
    "\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "\n",
    "        self.num_users = num_users\n",
    "        self.num_items = num_items\n",
    "\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        pass  # There are no layer parameters to learn.\n",
    "\n",
    "    def forward(self, x: Tensor, edge_index: Adj) -> Tensor:\n",
    "        \"\"\"Performs neighborhood aggregation for user/item embeddings.\"\"\"\n",
    "        user_item = \\\n",
    "                torch.zeros(self.num_users, self.num_items, device=x.device)\n",
    "        user_item[edge_index[:, 0], edge_index[:, 1]] = 1 # global_edge_index[edge_index[:, 0], edge_index[:, 1]]\n",
    "\n",
    "        att = \\\n",
    "                torch.zeros(self.num_users, self.num_items, device=x.device)\n",
    "        att[edge_index[:, 0], edge_index[:, 1]] = global_edge_index[edge_index[:, 0], edge_index[:, 1]]\n",
    "\n",
    "        user_neighbor_counts = torch.sum((user_item > 0), axis=1)\n",
    "        item_neightbor_counts = torch.sum((user_item > 0), axis=0)\n",
    "\n",
    "        # Compute weight for aggregation: 1 / sqrt(N_u * N_i)\n",
    "\n",
    "        if use_edge_weights:\n",
    "            weights = att / torch.sqrt(\n",
    "                user_neighbor_counts.repeat(self.num_items, 1).T \\\n",
    "                * item_neightbor_counts.repeat(self.num_users, 1))\n",
    "        else:\n",
    "            weights = (user_item > 0) / torch.sqrt(\n",
    "                    user_neighbor_counts.repeat(self.num_items, 1).T \\\n",
    "                    * item_neightbor_counts.repeat(self.num_users, 1))\n",
    "        \n",
    "        weights = torch.nan_to_num(weights, nan=0)\n",
    "        out = torch.concat((weights.T @ x[:self.num_users],\n",
    "                            weights @ x[self.num_users:]), 0)\n",
    "        return out\n",
    "\n",
    "    def __repr__(self):\n",
    "        return '{}({}, {})'.format(self.__class__.__name__, self.in_channels,\n",
    "                                   self.out_channels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "54dfd56b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LightGCN(nn.Module):\n",
    "    def __init__(self, \n",
    "                 config: dict,\n",
    "                 device=None,\n",
    "                 **kwargs):\n",
    "        super().__init__()\n",
    "\n",
    "        self.num_users  = config[\"n_users\"]\n",
    "        self.num_items  = config[\"m_items\"]\n",
    "        self.embedding_size = config[\"embedding_size\"]\n",
    "        self.in_channels = self.embedding_size\n",
    "        self.out_channels = self.embedding_size\n",
    "        self.num_layers = config[\"num_layers\"]\n",
    "\n",
    "        # 0-th layer embedding.\n",
    "        self.embedding_user_item = torch.nn.Embedding(\n",
    "            num_embeddings=self.num_users + self.num_items,\n",
    "            embedding_dim=self.embedding_size)\n",
    "        self.alpha = None\n",
    "\n",
    "        # random normal init seems to be a better choice when lightGCN actually\n",
    "        # don't use any non-linear activation function\n",
    "        nn.init.normal_(self.embedding_user_item.weight, std=0.1)\n",
    "        print('use NORMAL distribution initilizer')\n",
    "\n",
    "        self.f = nn.Sigmoid()\n",
    "\n",
    "        self.convs = nn.ModuleList()\n",
    "        self.convs.append(LightGCNConv(\n",
    "                self.embedding_size, self.embedding_size,\n",
    "                num_users=self.num_users, num_items=self.num_items, **kwargs))\n",
    "\n",
    "        for _ in range(1, self.num_layers):\n",
    "            self.convs.append(\n",
    "                LightGCNConv(\n",
    "                        self.embedding_size, self.embedding_size, \n",
    "                        num_users=self.num_users, num_items=self.num_items,\n",
    "                        **kwargs))\n",
    "\n",
    "        self.device = None\n",
    "        if device is not None:\n",
    "            self.convs.to(device)\n",
    "            self.device = device\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        for conv in self.convs:\n",
    "            conv.reset_parameters()\n",
    "\n",
    "    def forward(self, x: Tensor, edge_index: Adj, *args, **kwargs) -> Tensor:\n",
    "        xs: List[Tensor] = []\n",
    "\n",
    "        edge_index = torch.nonzero(edge_index)\n",
    "        for i in range(self.num_layers):\n",
    "            x = self.convs[i](x, edge_index, *args, **kwargs)\n",
    "            if self.device is not None:\n",
    "                x = x.to(self.device)\n",
    "            xs.append(x)\n",
    "        xs = torch.stack(xs)\n",
    "        \n",
    "        self.alpha = 1 / (1 + self.num_layers) * torch.ones(xs.shape)\n",
    "        if self.device is not None:\n",
    "            self.alpha = self.alpha.to(self.device)\n",
    "            xs = xs.to(self.device)\n",
    "        x = (xs * self.alpha).sum(dim=0)  # Sum along K layers.\n",
    "        return x\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return (f'{self.__class__.__name__}({self.in_channels}, '\n",
    "                f'{self.out_channels}, num_layers={self.num_layers})')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4df0a3d7",
   "metadata": {},
   "source": [
    "# Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b49659ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getUsersRating(model, users, data):\n",
    "    \"\"\" Get the embedding of users\n",
    "    INPUT:\n",
    "        model: the LightGCN model you are training on\n",
    "        users: this is the user index (note: use 0-indexed and not user number,\n",
    "            which is 1-indexed)\n",
    "        data: the entire data, used to fetch all users and all items\n",
    "    \"\"\"\n",
    "    all_users_items = model(model.embedding_user_item.weight.clone(), global_edge_index)\n",
    "    #print(\"USERS: \", users)\n",
    "    #print(\"ALL USERS ITMES: \", all_users_items)\n",
    "    #print(\"ALL USERS SHAPE: \", all_users_items.shape)\n",
    "    all_users = all_users_items[:len(data[\"user\"].x)]\n",
    "    items_emb = all_users_items[len(data[\"user\"].x):]\n",
    "    users_emb = all_users[users.long()]\n",
    "    rating = model.f(torch.matmul(users_emb, items_emb.t()))\n",
    "    #print(\"RATING: \", rating)\n",
    "    return rating\n",
    "\n",
    "def getEmbedding(model, users, pos, neg, data, mask):\n",
    "    \"\"\"\n",
    "    INPUT:\n",
    "        model: the LightGCN model you are training on\n",
    "        users: this is the user index (note: use 0-indexed and not user number,\n",
    "            which is 1-indexed)\n",
    "        pos: positive index corresponding to an item that the user like\n",
    "        neg: negative index corresponding to an item that the user doesn't like\n",
    "        data: the entire data, used to fetch all users and all items\n",
    "        mask: Masking matrix indicating edges present in the current\n",
    "            train / validation / test set.\n",
    "    \"\"\"\n",
    "    # assuming we always search for users and items by their indices (instead of\n",
    "    # user/item number)\n",
    "    all_users_items = model(model.embedding_user_item.weight.clone(),\n",
    "                            global_edge_index * mask)\n",
    "    # print(all_users_items)\n",
    "    all_users = all_users_items[:len(data[\"user\"].x)]\n",
    "    all_items = all_users_items[len(data[\"user\"].x):]\n",
    "    users_emb = all_users[users]\n",
    "    pos_emb = all_items[pos]\n",
    "    neg_emb = all_items[neg]\n",
    "    n_user = len(data[\"user\"].x)\n",
    "    users_emb_ego = model.embedding_user_item(users)\n",
    "    # offset the index to fetch embedding from user_item\n",
    "    pos_emb_ego = model.embedding_user_item(pos + n_user)\n",
    "    neg_emb_ego = model.embedding_user_item(neg + n_user)\n",
    "    return users_emb, pos_emb, neg_emb, users_emb_ego, pos_emb_ego, neg_emb_ego"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96f0e5c7",
   "metadata": {},
   "source": [
    "# Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4f2f9971",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bpr_loss(model, users, pos, neg, data, mask):\n",
    "    \"\"\" \n",
    "    INPUT:\n",
    "        model: the LightGCN model you are training on\n",
    "        users: this is the user index (note: use 0-indexed and not user number,\n",
    "            which is 1-indexed)\n",
    "        pos: positive index corresponding to an item that the user like\n",
    "            (0-indexed, note to index items starting from 0)\n",
    "        neg: negative index corresponding to an item that the user doesn't like\n",
    "        data: the entire data, used to fetch all users and all items\n",
    "        mask: Masking matrix indicating edges present in the current\n",
    "            train / validation / test set.\n",
    "    OUTPUT:\n",
    "        loss, reg_loss\n",
    "    \"\"\"\n",
    "    # assuming we always sample the same number of positive and negative sample\n",
    "    # per user\n",
    "    assert len(users) == len(pos) and len(users) == len(neg)\n",
    "    (users_emb, pos_emb, neg_emb, \n",
    "    userEmb0,  posEmb0, negEmb0) = getEmbedding(model, users.long(), pos.long(),\n",
    "                                                neg.long(), data, mask)\n",
    "    reg_loss = (1/2)*(userEmb0.norm(2).pow(2) + \n",
    "                        posEmb0.norm(2).pow(2)  +\n",
    "                        negEmb0.norm(2).pow(2))/float(len(users))\n",
    "    pos_scores = torch.mul(users_emb, pos_emb)\n",
    "    pos_scores = torch.sum(pos_scores, dim=1)\n",
    "    neg_scores = torch.mul(users_emb, neg_emb)\n",
    "    neg_scores = torch.sum(neg_scores, dim=1)\n",
    "    \n",
    "    loss = torch.mean(torch.nn.functional.softplus(neg_scores - pos_scores))\n",
    "    \n",
    "    return loss, reg_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d150b0e4",
   "metadata": {},
   "source": [
    "# Personalized Top K Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8e47c6da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def personalized_topk(pred, K, user_indices, edge_index):\n",
    "    \"\"\"Computes TopK precision and recall.\n",
    "\n",
    "    Args:\n",
    "        pred: Predicted similarities between user and item.\n",
    "        K: Number of items to rank.\n",
    "        user_indices: Indices of users for each prediction in `pred`.\n",
    "        edge_index: User and item connection matrix.\n",
    "\n",
    "    Returns:\n",
    "        Average Top K precision and recall for users in `user_indices`.\n",
    "    \"\"\"\n",
    "    per_user_preds = collections.defaultdict(list)\n",
    "    for index, user in enumerate(user_indices):\n",
    "        per_user_preds[user.item()].append(pred[index].item())\n",
    "    precisions = 0.0\n",
    "    recalls = 0.0\n",
    "    for user, preds in per_user_preds.items():\n",
    "        while len(preds) < K:\n",
    "            preds.append(random.choice(range(edge_index.shape[1])))\n",
    "        top_ratings, top_items = torch.topk(torch.tensor(preds), K)\n",
    "        correct_preds = edge_index[user, top_items].sum().item()\n",
    "        total_pos = edge_index[user].sum().item()\n",
    "        precisions += correct_preds / K\n",
    "        recalls += correct_preds / total_pos if total_pos != 0 else 0\n",
    "    num_users = len(user_indices.unique())\n",
    "    return precisions / num_users, recalls / num_users\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e6d53f4",
   "metadata": {},
   "source": [
    "# Training, Validation, and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1852ec82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _sample_pos_neg(data, mask, num_samples_per_user):\n",
    "    \"\"\"Samples (user, positive item, negative item) tuples per user.\n",
    "\n",
    "    If a user does not have a postive (negative) item, we choose an item\n",
    "    with unknown liking (an item without raw rating data).\n",
    "\n",
    "    Args:\n",
    "        data: Dataset object containing edge_index and raw ratings matrix.\n",
    "        mask: Masking matrix indicating edges present in the current\n",
    "            train / validation / test set.\n",
    "        num_samples_per_user: Number of samples to generate for each user.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor object of (user, positive item, negative item) samples.\n",
    "    \"\"\"\n",
    "    print(\"=====Starting to sample=====\")\n",
    "    start = time.time()\n",
    "    samples = []\n",
    "    all_items = set(range(len(data[\"item\"].x)))\n",
    "    for user_index, user in enumerate(data[\"user\"].x):\n",
    "        #print(\"HERE: \", user_index, user)\n",
    "        pos_items = set(\n",
    "            torch.nonzero(global_edge_index[user_index])[:, 0].tolist())\n",
    "        #print(\"POSITIVE: \", pos_items)\n",
    "        unknown_items = all_items.difference(\n",
    "                set(\n",
    "                    torch.nonzero(global_edge_index[user_index])[:, 0].tolist()))\n",
    "        neg_items = all_items.difference(\n",
    "            set(pos_items)).difference(set(unknown_items))\n",
    "        unmasked_items = set(torch.nonzero(mask[user_index])[:, 0].tolist())\n",
    "        if len(unknown_items.union(pos_items)) == 0 or \\\n",
    "                len(unknown_items.union(neg_items)) == 0:\n",
    "            continue\n",
    "        for _ in range(num_samples_per_user):\n",
    "            if len(pos_items.intersection(unmasked_items)) == 0:\n",
    "                pos_item_index = random.choice(\n",
    "                    list(unknown_items.intersection(unmasked_items)))\n",
    "            else:\n",
    "                pos_item_index = random.choice(\n",
    "                    list(pos_items.intersection(unmasked_items)))\n",
    "            if len(neg_items.intersection(unmasked_items)) == 0:\n",
    "                neg_item_index = random.choice(\n",
    "                    list(unknown_items.intersection(unmasked_items)))\n",
    "            else:\n",
    "                neg_item_index = random.choice(\n",
    "                    list(neg_items.intersection(unmasked_items)))\n",
    "            samples.append((user_index, pos_item_index, neg_item_index))\n",
    "    end = time.time()\n",
    "    print(f\"=====Sampling completed (took {end - start} seconds)=====\")\n",
    "    return torch.tensor(samples, dtype=torch.int32)\n",
    "\n",
    "def sample_pos_neg(data, train_mask, val_mask, test_mask, num_samples_per_user):\n",
    "    \"\"\"Samples (user, positive item, negative item) tuples per user.\n",
    "\n",
    "    If a user does not have a postive (negative) item, we choose an item\n",
    "    with unknown liking (an item without raw rating data).\n",
    "\n",
    "    Args:\n",
    "        data: Dataset object containing edge_index and raw ratings matrix.\n",
    "        train_mask: Masking matrix indicating edges present in train set.\n",
    "        val_mask: Masking matrix indicating edges present in validation set.\n",
    "        test_mask: Masking matrix indicating edges present in test set.\n",
    "        num_samples_per_user: Number of samples to generate for each user.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor object of (user, positive item, negative item) samples for\n",
    "        train, validation and test.\n",
    "    \"\"\"\n",
    "    train_samples = _sample_pos_neg(data, train_mask, num_samples_per_user)\n",
    "    val_samples = _sample_pos_neg(data, val_mask, num_samples_per_user)\n",
    "    test_samples = _sample_pos_neg(data, test_mask, num_samples_per_user)\n",
    "    return train_samples, val_samples, test_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e7d0c451",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_users = mov['user'].x.shape[0]\n",
    "m_items = mov['item'].x.shape[0]\n",
    "\n",
    "def train_val_test_split(num_user, num_item, val_frac, test_frac):\n",
    "    \"\"\"\n",
    "    Return two mask matrices (M, N) that represents edges present in the\n",
    "    train and validation set\n",
    "    \"\"\"\n",
    "    # get number of edges masked for training and validation\n",
    "    num_train_replaced = round((test_frac+val_frac)*num_user*num_item)\n",
    "    num_val_show = round(val_frac*num_user*num_item)\n",
    "\n",
    "    # edges masked during training\n",
    "    indices_user = np.random.randint(0, num_user, num_train_replaced)\n",
    "    indices_item = np.random.randint(0, num_item, num_train_replaced)\n",
    "\n",
    "    # sample part of edges from training stage to be unmasked during\n",
    "    # validation\n",
    "    indices_val_user = np.random.choice(indices_user, num_val_show)\n",
    "    indices_val_item = np.random.choice(indices_item, num_val_show)\n",
    "\n",
    "    train_mask = torch.ones(num_user, num_item)\n",
    "    train_mask[indices_user, indices_item] = 0\n",
    "\n",
    "    val_mask = train_mask.clone()\n",
    "    val_mask[indices_val_user, indices_val_item] = 1\n",
    "\n",
    "    test_mask = torch.ones_like(train_mask)\n",
    "\n",
    "    return train_mask, val_mask, test_mask\n",
    "\n",
    "\n",
    "train_mask, val_mask, test_mask = train_val_test_split(\n",
    "    num_user = n_users,\n",
    "    num_item = m_items,\n",
    "    val_frac = config_dict[\"val_frac\"],\n",
    "    test_frac = config_dict[\"test_frac\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "47769412",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEVICE:  cuda\n",
      "use NORMAL distribution initilizer\n",
      "=====Starting to sample=====\n",
      "=====Sampling completed (took 25.21623992919922 seconds)=====\n",
      "=====Starting to sample=====\n",
      "=====Sampling completed (took 25.54411768913269 seconds)=====\n",
      "=====Starting to sample=====\n",
      "=====Sampling completed (took 25.954902172088623 seconds)=====\n",
      "#Training samples: 300000 #Validation samples: 300000 #Test samples: 300000\n",
      "Optimizer: Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    lr: 0.001\n",
      "    maximize: False\n",
      "    weight_decay: 0\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model_config = {\n",
    "    \"n_users\": n_users,\n",
    "    \"m_items\": m_items,\n",
    "    \"embedding_size\": config_dict[\"embedding_size\"],\n",
    "    \"num_layers\": config_dict[\"num_layers\"],\n",
    "}\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"DEVICE: \", device)\n",
    "lightGCN = LightGCN(model_config, device=device)\n",
    "\n",
    "num_samples_per_user = config_dict[\"num_samples_per_user\"]\n",
    "epochs = config_dict[\"epochs\"]\n",
    "batch_size = config_dict[\"batch_size\"]\n",
    "lr = config_dict[\"lr\"]\n",
    "weight_decay = config_dict[\"weight_decay\"]\n",
    "\n",
    "lightGCN.to(device)\n",
    "\n",
    "samples_train, samples_val, samples_test = sample_pos_neg(\n",
    "    mov, train_mask, val_mask, test_mask, num_samples_per_user)\n",
    "\n",
    "samples_train=samples_train.to(device)\n",
    "samples_val=samples_val.to(device)\n",
    "samples_test=samples_test.to(device)\n",
    "train_mask=train_mask.to(device)\n",
    "val_mask=val_mask.to(device)\n",
    "test_mask=test_mask.to(device)\n",
    "mov = mov.to(device)\n",
    "\n",
    "print(f\"#Training samples: {len(samples_train)}\",\n",
    "      f\"#Validation samples: {len(samples_val)}\",\n",
    "      f\"#Test samples: {len(samples_test)}\")\n",
    "\n",
    "optimizer = optim.Adam(lightGCN.parameters(), lr=lr)\n",
    "print(\"Optimizer:\", optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5467c096-bda5-465a-818e-23264197e9a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on the 0 epoch\n",
      "Training on epoch 0 minibatch 1/5000 completed\n",
      " bpr_loss on current minibatch is 1.667295, and regularization loss is 0.974147.\n",
      " Top K precision = 0.006779661016949153, recall = 0.0045907012008706925.\n",
      "Training on epoch 0 minibatch 101/5000 completed\n",
      " bpr_loss on current minibatch is 1.454394, and regularization loss is 0.761247.\n",
      " Top K precision = 0.014999999999999998, recall = 0.006167432596202912.\n",
      "Training on epoch 0 minibatch 201/5000 completed\n",
      " bpr_loss on current minibatch is 1.285263, and regularization loss is 0.592116.\n",
      " Top K precision = 0.022033898305084745, recall = 0.010828365689818537.\n",
      "Training on epoch 0 minibatch 301/5000 completed\n",
      " bpr_loss on current minibatch is 1.165184, and regularization loss is 0.472037.\n",
      " Top K precision = 0.015254237288135592, recall = 0.006295892571811815.\n",
      "Training on epoch 0 minibatch 401/5000 completed\n",
      " bpr_loss on current minibatch is 1.033731, and regularization loss is 0.340584.\n",
      " Top K precision = 0.016666666666666666, recall = 0.00823186354626517.\n",
      "Training on epoch 0 minibatch 501/5000 completed\n",
      " bpr_loss on current minibatch is 0.966777, and regularization loss is 0.27363.\n",
      " Top K precision = 0.01, recall = 0.005615436865436865.\n",
      "Training on epoch 0 minibatch 601/5000 completed\n",
      " bpr_loss on current minibatch is 0.897815, and regularization loss is 0.204668.\n",
      " Top K precision = 0.021666666666666667, recall = 0.009857966431379235.\n",
      "Training on epoch 0 minibatch 701/5000 completed\n",
      " bpr_loss on current minibatch is 0.855202, and regularization loss is 0.162055.\n",
      " Top K precision = 0.006896551724137932, recall = 0.002898681777992123.\n",
      "Training on epoch 0 minibatch 801/5000 completed\n",
      " bpr_loss on current minibatch is 0.821957, and regularization loss is 0.128809.\n",
      " Top K precision = 0.01379310344827586, recall = 0.00424795623578585.\n",
      "Training on epoch 0 minibatch 901/5000 completed\n",
      " bpr_loss on current minibatch is 0.797121, and regularization loss is 0.103974.\n",
      " Top K precision = 0.007017543859649123, recall = 0.003006983270141165.\n",
      "Training on epoch 0 minibatch 1001/5000 completed\n",
      " bpr_loss on current minibatch is 0.766096, and regularization loss is 0.072949.\n",
      " Top K precision = 0.02203389830508475, recall = 0.01036985522964971.\n",
      "Training on epoch 0 minibatch 1101/5000 completed\n",
      " bpr_loss on current minibatch is 0.751662, and regularization loss is 0.058515.\n",
      " Top K precision = 0.008333333333333333, recall = 0.0024983943843592963.\n",
      "Training on epoch 0 minibatch 1201/5000 completed\n",
      " bpr_loss on current minibatch is 0.744029, and regularization loss is 0.050882.\n",
      " Top K precision = 0.006779661016949153, recall = 0.0036319612590799025.\n",
      "Training on epoch 0 minibatch 1301/5000 completed\n",
      " bpr_loss on current minibatch is 0.731873, and regularization loss is 0.038726.\n",
      " Top K precision = 0.01833333333333333, recall = 0.009585178020800937.\n",
      "Training on epoch 0 minibatch 1401/5000 completed\n",
      " bpr_loss on current minibatch is 0.72462, and regularization loss is 0.031473.\n",
      " Top K precision = 0.014999999999999998, recall = 0.005919734606218962.\n",
      "Training on epoch 0 minibatch 1501/5000 completed\n",
      " bpr_loss on current minibatch is 0.715283, and regularization loss is 0.022136.\n",
      " Top K precision = 0.015254237288135592, recall = 0.007871549185108507.\n",
      "Training on epoch 0 minibatch 1601/5000 completed\n",
      " bpr_loss on current minibatch is 0.709673, and regularization loss is 0.016525.\n",
      " Top K precision = 0.011864406779661016, recall = 0.005767615937107463.\n",
      "Training on epoch 0 minibatch 1701/5000 completed\n",
      " bpr_loss on current minibatch is 0.707176, and regularization loss is 0.014028.\n",
      " Top K precision = 0.00847457627118644, recall = 0.004120299035553273.\n",
      "Training on epoch 0 minibatch 1801/5000 completed\n",
      " bpr_loss on current minibatch is 0.704086, and regularization loss is 0.010939.\n",
      " Top K precision = 0.01833333333333333, recall = 0.01079450520239994.\n",
      "Training on epoch 0 minibatch 1901/5000 completed\n",
      " bpr_loss on current minibatch is 0.70201, and regularization loss is 0.008862.\n",
      " Top K precision = 0.011666666666666665, recall = 0.0030784503449802127.\n",
      "Training on epoch 0 minibatch 2001/5000 completed\n",
      " bpr_loss on current minibatch is 0.699025, and regularization loss is 0.005878.\n",
      " Top K precision = 0.013559322033898305, recall = 0.006523988640140185.\n",
      "Training on epoch 0 minibatch 2101/5000 completed\n",
      " bpr_loss on current minibatch is 0.698824, and regularization loss is 0.005677.\n",
      " Top K precision = 0.008620689655172414, recall = 0.004802022689953724.\n",
      "Training on epoch 0 minibatch 2201/5000 completed\n",
      " bpr_loss on current minibatch is 0.696815, and regularization loss is 0.003668.\n",
      " Top K precision = 0.016666666666666666, recall = 0.008667600772821771.\n",
      "Training on epoch 0 minibatch 2301/5000 completed\n",
      " bpr_loss on current minibatch is 0.695803, and regularization loss is 0.002656.\n",
      " Top K precision = 0.021666666666666667, recall = 0.010291897678922666.\n",
      "Training on epoch 0 minibatch 2401/5000 completed\n",
      " bpr_loss on current minibatch is 0.695244, and regularization loss is 0.002097.\n",
      " Top K precision = 0.013333333333333332, recall = 0.005364713611485492.\n",
      "Training on epoch 0 minibatch 2501/5000 completed\n",
      " bpr_loss on current minibatch is 0.695184, and regularization loss is 0.002037.\n",
      " Top K precision = 0.001724137931034483, recall = 0.0006385696040868454.\n",
      "Training on epoch 0 minibatch 2601/5000 completed\n",
      " bpr_loss on current minibatch is 0.694712, and regularization loss is 0.001565.\n",
      " Top K precision = 0.006666666666666667, recall = 0.0017368514570007107.\n",
      "Training on epoch 0 minibatch 2701/5000 completed\n",
      " bpr_loss on current minibatch is 0.69402, and regularization loss is 0.000873.\n",
      " Top K precision = 0.011666666666666665, recall = 0.00726383922036096.\n",
      "Training on epoch 0 minibatch 2801/5000 completed\n",
      " bpr_loss on current minibatch is 0.693924, and regularization loss is 0.000777.\n",
      " Top K precision = 0.00847457627118644, recall = 0.002879511053376554.\n",
      "Training on epoch 0 minibatch 2901/5000 completed\n",
      " bpr_loss on current minibatch is 0.693964, and regularization loss is 0.000817.\n",
      " Top K precision = 0.006779661016949153, recall = 0.0018658359358242468.\n",
      "Training on epoch 0 minibatch 3001/5000 completed\n",
      " bpr_loss on current minibatch is 0.693823, and regularization loss is 0.000675.\n",
      " Top K precision = 0.01, recall = 0.003471970042421479.\n",
      "Training on epoch 0 minibatch 3101/5000 completed\n",
      " bpr_loss on current minibatch is 0.693694, and regularization loss is 0.000546.\n",
      " Top K precision = 0.005000000000000001, recall = 0.0022660818713450288.\n",
      "Training on epoch 0 minibatch 3201/5000 completed\n",
      " bpr_loss on current minibatch is 0.693652, and regularization loss is 0.000505.\n",
      " Top K precision = 0.01, recall = 0.0037400793650793646.\n",
      "Training on epoch 0 minibatch 3301/5000 completed\n",
      " bpr_loss on current minibatch is 0.693504, and regularization loss is 0.000357.\n",
      " Top K precision = 0.014999999999999998, recall = 0.006705317033573337.\n",
      "Training on epoch 0 minibatch 3401/5000 completed\n",
      " bpr_loss on current minibatch is 0.693558, and regularization loss is 0.000411.\n",
      " Top K precision = 0.006666666666666667, recall = 0.002944401277734611.\n",
      "Training on epoch 0 minibatch 3501/5000 completed\n",
      " bpr_loss on current minibatch is 0.693501, and regularization loss is 0.000354.\n",
      " Top K precision = 0.015000000000000001, recall = 0.007674372243337761.\n",
      "Training on epoch 0 minibatch 3601/5000 completed\n",
      " bpr_loss on current minibatch is 0.693379, and regularization loss is 0.000232.\n",
      " Top K precision = 0.008333333333333333, recall = 0.0030596802639813393.\n",
      "Training on epoch 0 minibatch 3701/5000 completed\n",
      " bpr_loss on current minibatch is 0.693382, and regularization loss is 0.000235.\n",
      " Top K precision = 0.006666666666666667, recall = 0.0017805207244862417.\n",
      "Training on epoch 0 minibatch 3801/5000 completed\n",
      " bpr_loss on current minibatch is 0.69341, and regularization loss is 0.000263.\n",
      " Top K precision = 0.008333333333333333, recall = 0.0035580537883169463.\n",
      "Training on epoch 0 minibatch 3901/5000 completed\n",
      " bpr_loss on current minibatch is 0.693383, and regularization loss is 0.000235.\n",
      " Top K precision = 0.015254237288135592, recall = 0.008910213559286935.\n",
      "Training on epoch 0 minibatch 4001/5000 completed\n",
      " bpr_loss on current minibatch is 0.693382, and regularization loss is 0.000235.\n",
      " Top K precision = 0.008333333333333333, recall = 0.004065351583467525.\n",
      "Training on epoch 0 minibatch 4101/5000 completed\n",
      " bpr_loss on current minibatch is 0.693451, and regularization loss is 0.000303.\n",
      " Top K precision = 0.008620689655172414, recall = 0.0024436104824035855.\n",
      "Training on epoch 0 minibatch 4201/5000 completed\n",
      " bpr_loss on current minibatch is 0.693377, and regularization loss is 0.00023.\n",
      " Top K precision = 0.013333333333333332, recall = 0.0056100372986337904.\n",
      "Training on epoch 0 minibatch 4301/5000 completed\n",
      " bpr_loss on current minibatch is 0.69342, and regularization loss is 0.000273.\n",
      " Top K precision = 0.01379310344827586, recall = 0.007054281179630484.\n",
      "Training on epoch 0 minibatch 4401/5000 completed\n",
      " bpr_loss on current minibatch is 0.693469, and regularization loss is 0.000322.\n",
      " Top K precision = 0.008333333333333333, recall = 0.003961873638344227.\n",
      "Training on epoch 0 minibatch 4501/5000 completed\n",
      " bpr_loss on current minibatch is 0.69341, and regularization loss is 0.000263.\n",
      " Top K precision = 0.00847457627118644, recall = 0.003071124633796111.\n",
      "Training on epoch 0 minibatch 4601/5000 completed\n",
      " bpr_loss on current minibatch is 0.693446, and regularization loss is 0.000299.\n",
      " Top K precision = 0.015254237288135592, recall = 0.0055688687451864735.\n",
      "Training on epoch 0 minibatch 4701/5000 completed\n",
      " bpr_loss on current minibatch is 0.693417, and regularization loss is 0.00027.\n",
      " Top K precision = 0.010344827586206896, recall = 0.0035589071466481602.\n",
      "Training on epoch 0 minibatch 4801/5000 completed\n",
      " bpr_loss on current minibatch is 0.693481, and regularization loss is 0.000333.\n",
      " Top K precision = 0.018333333333333333, recall = 0.009503272777409071.\n",
      "Training on epoch 0 minibatch 4901/5000 completed\n",
      " bpr_loss on current minibatch is 0.69345, and regularization loss is 0.000303.\n",
      " Top K precision = 0.013333333333333332, recall = 0.005769463711536882.\n",
      "\n",
      "Training on 0 epoch completed.\n",
      " Average bpr_loss on train set is 0.012841 for the current epoch.\n",
      " Training top K precision = 0.0164666666666668, recall = 0.007121323963868581.\n",
      " Average bpr_loss on the validation set is 2e-06, and regularization loss is 0.0.\n",
      " Validation top K precision = 0.013900000000000096, recall = 0.0058735504896926215.\n",
      "\n",
      "Training on the 1 epoch\n",
      "Training on epoch 1 minibatch 1/5000 completed\n",
      " bpr_loss on current minibatch is 0.693443, and regularization loss is 0.000296.\n",
      " Top K precision = 0.01379310344827586, recall = 0.004907700933773263.\n",
      "Training on epoch 1 minibatch 101/5000 completed\n",
      " bpr_loss on current minibatch is 0.693533, and regularization loss is 0.000386.\n",
      " Top K precision = 0.01, recall = 0.004500674763832659.\n",
      "Training on epoch 1 minibatch 201/5000 completed\n",
      " bpr_loss on current minibatch is 0.693497, and regularization loss is 0.00035.\n",
      " Top K precision = 0.018644067796610167, recall = 0.007581453004454594.\n",
      "Training on epoch 1 minibatch 301/5000 completed\n",
      " bpr_loss on current minibatch is 0.693472, and regularization loss is 0.000325.\n",
      " Top K precision = 0.010000000000000002, recall = 0.002870491601861211.\n",
      "Training on epoch 1 minibatch 401/5000 completed\n",
      " bpr_loss on current minibatch is 0.693441, and regularization loss is 0.000294.\n",
      " Top K precision = 0.008333333333333333, recall = 0.004094312298613374.\n",
      "Training on epoch 1 minibatch 501/5000 completed\n",
      " bpr_loss on current minibatch is 0.69347, and regularization loss is 0.000323.\n",
      " Top K precision = 0.016949152542372885, recall = 0.006773882394389295.\n",
      "Training on epoch 1 minibatch 601/5000 completed\n",
      " bpr_loss on current minibatch is 0.693474, and regularization loss is 0.000326.\n",
      " Top K precision = 0.006896551724137932, recall = 0.002389268727705113.\n",
      "Training on epoch 1 minibatch 701/5000 completed\n",
      " bpr_loss on current minibatch is 0.69352, and regularization loss is 0.000373.\n",
      " Top K precision = 0.0016949152542372883, recall = 0.0006779661016949153.\n",
      "Training on epoch 1 minibatch 801/5000 completed\n",
      " bpr_loss on current minibatch is 0.693565, and regularization loss is 0.000418.\n",
      " Top K precision = 0.018644067796610167, recall = 0.007168410476544151.\n",
      "Training on epoch 1 minibatch 901/5000 completed\n",
      " bpr_loss on current minibatch is 0.693561, and regularization loss is 0.000414.\n",
      " Top K precision = 0.015254237288135592, recall = 0.004984576836615136.\n",
      "Training on epoch 1 minibatch 1001/5000 completed\n",
      " bpr_loss on current minibatch is 0.69352, and regularization loss is 0.000372.\n",
      " Top K precision = 0.015517241379310345, recall = 0.008407540735126942.\n",
      "Training on epoch 1 minibatch 1101/5000 completed\n",
      " bpr_loss on current minibatch is 0.693608, and regularization loss is 0.000461.\n",
      " Top K precision = 0.008333333333333333, recall = 0.004660775809031623.\n",
      "Training on epoch 1 minibatch 1201/5000 completed\n",
      " bpr_loss on current minibatch is 0.693571, and regularization loss is 0.000424.\n",
      " Top K precision = 0.016666666666666666, recall = 0.007354102354102355.\n",
      "Training on epoch 1 minibatch 1301/5000 completed\n",
      " bpr_loss on current minibatch is 0.693634, and regularization loss is 0.000487.\n",
      " Top K precision = 0.016666666666666666, recall = 0.006456823706823707.\n",
      "Training on epoch 1 minibatch 1401/5000 completed\n",
      " bpr_loss on current minibatch is 0.693577, and regularization loss is 0.00043.\n",
      " Top K precision = 0.006666666666666667, recall = 0.003642429193899782.\n",
      "Training on epoch 1 minibatch 1501/5000 completed\n",
      " bpr_loss on current minibatch is 0.693567, and regularization loss is 0.00042.\n",
      " Top K precision = 0.008333333333333333, recall = 0.003592835791293014.\n",
      "Training on epoch 1 minibatch 1601/5000 completed\n",
      " bpr_loss on current minibatch is 0.693548, and regularization loss is 0.000401.\n",
      " Top K precision = 0.01833333333333333, recall = 0.006841733921239531.\n",
      "Training on epoch 1 minibatch 1701/5000 completed\n",
      " bpr_loss on current minibatch is 0.693628, and regularization loss is 0.000481.\n",
      " Top K precision = 0.010344827586206896, recall = 0.005120869960329714.\n",
      "Training on epoch 1 minibatch 1801/5000 completed\n",
      " bpr_loss on current minibatch is 0.693547, and regularization loss is 0.0004.\n",
      " Top K precision = 0.01, recall = 0.005224622932083344.\n",
      "Training on epoch 1 minibatch 1901/5000 completed\n",
      " bpr_loss on current minibatch is 0.693776, and regularization loss is 0.000628.\n",
      " Top K precision = 0.00847457627118644, recall = 0.004646220069948883.\n",
      "Training on epoch 1 minibatch 2001/5000 completed\n",
      " bpr_loss on current minibatch is 0.69358, and regularization loss is 0.000433.\n",
      " Top K precision = 0.01379310344827586, recall = 0.005909277345988609.\n",
      "Training on epoch 1 minibatch 2101/5000 completed\n",
      " bpr_loss on current minibatch is 0.693741, and regularization loss is 0.000594.\n",
      " Top K precision = 0.014999999999999998, recall = 0.005092582118317412.\n",
      "Training on epoch 1 minibatch 2201/5000 completed\n",
      " bpr_loss on current minibatch is 0.693725, and regularization loss is 0.000578.\n",
      " Top K precision = 0.006666666666666667, recall = 0.0019985569985569987.\n",
      "Training on epoch 1 minibatch 2301/5000 completed\n",
      " bpr_loss on current minibatch is 0.693693, and regularization loss is 0.000546.\n",
      " Top K precision = 0.016666666666666666, recall = 0.008310356259580305.\n",
      "Training on epoch 1 minibatch 2401/5000 completed\n",
      " bpr_loss on current minibatch is 0.693644, and regularization loss is 0.000497.\n",
      " Top K precision = 0.015254237288135592, recall = 0.006105660490332562.\n",
      "Training on epoch 1 minibatch 2501/5000 completed\n",
      " bpr_loss on current minibatch is 0.693616, and regularization loss is 0.000469.\n",
      " Top K precision = 0.020338983050847456, recall = 0.010388031807735945.\n",
      "Training on epoch 1 minibatch 2601/5000 completed\n",
      " bpr_loss on current minibatch is 0.693824, and regularization loss is 0.000677.\n",
      " Top K precision = 0.00847457627118644, recall = 0.005185405078745652.\n",
      "Training on epoch 1 minibatch 2701/5000 completed\n",
      " bpr_loss on current minibatch is 0.693647, and regularization loss is 0.0005.\n",
      " Top K precision = 0.013333333333333332, recall = 0.004366493311781104.\n",
      "Training on epoch 1 minibatch 2801/5000 completed\n",
      " bpr_loss on current minibatch is 0.693615, and regularization loss is 0.000468.\n",
      " Top K precision = 0.006666666666666667, recall = 0.0025396825396825392.\n",
      "Training on epoch 1 minibatch 2901/5000 completed\n",
      " bpr_loss on current minibatch is 0.693722, and regularization loss is 0.000575.\n",
      " Top K precision = 0.014999999999999998, recall = 0.00772821223801616.\n",
      "Training on epoch 1 minibatch 3001/5000 completed\n",
      " bpr_loss on current minibatch is 0.693796, and regularization loss is 0.000648.\n",
      " Top K precision = 0.016949152542372878, recall = 0.008270085177979915.\n",
      "Training on epoch 1 minibatch 3101/5000 completed\n",
      " bpr_loss on current minibatch is 0.693635, and regularization loss is 0.000487.\n",
      " Top K precision = 0.006779661016949153, recall = 0.0028498674167771526.\n",
      "Training on epoch 1 minibatch 3201/5000 completed\n",
      " bpr_loss on current minibatch is 0.693785, and regularization loss is 0.000638.\n",
      " Top K precision = 0.014999999999999998, recall = 0.007035921520948886.\n",
      "Training on epoch 1 minibatch 3301/5000 completed\n",
      " bpr_loss on current minibatch is 0.693687, and regularization loss is 0.00054.\n",
      " Top K precision = 0.02, recall = 0.008146716333501228.\n",
      "Training on epoch 1 minibatch 3401/5000 completed\n",
      " bpr_loss on current minibatch is 0.693775, and regularization loss is 0.000628.\n",
      " Top K precision = 0.013559322033898305, recall = 0.0077427475408532245.\n",
      "Training on epoch 1 minibatch 3501/5000 completed\n",
      " bpr_loss on current minibatch is 0.693711, and regularization loss is 0.000563.\n",
      " Top K precision = 0.016666666666666666, recall = 0.009493803582038877.\n",
      "Training on epoch 1 minibatch 3601/5000 completed\n",
      " bpr_loss on current minibatch is 0.693836, and regularization loss is 0.000689.\n",
      " Top K precision = 0.013333333333333332, recall = 0.006735008493201226.\n",
      "Training on epoch 1 minibatch 3701/5000 completed\n",
      " bpr_loss on current minibatch is 0.693806, and regularization loss is 0.000659.\n",
      " Top K precision = 0.011864406779661016, recall = 0.004278352299812114.\n",
      "Training on epoch 1 minibatch 3801/5000 completed\n",
      " bpr_loss on current minibatch is 0.693794, and regularization loss is 0.000647.\n",
      " Top K precision = 0.01833333333333333, recall = 0.006996589318178136.\n",
      "Training on epoch 1 minibatch 3901/5000 completed\n",
      " bpr_loss on current minibatch is 0.69374, and regularization loss is 0.000593.\n",
      " Top K precision = 0.01, recall = 0.004490699661507115.\n",
      "Training on epoch 1 minibatch 4001/5000 completed\n",
      " bpr_loss on current minibatch is 0.693757, and regularization loss is 0.000609.\n",
      " Top K precision = 0.008333333333333333, recall = 0.002897851003114161.\n",
      "Training on epoch 1 minibatch 4101/5000 completed\n",
      " bpr_loss on current minibatch is 0.693736, and regularization loss is 0.000588.\n",
      " Top K precision = 0.006779661016949153, recall = 0.002007174844315596.\n",
      "Training on epoch 1 minibatch 4201/5000 completed\n",
      " bpr_loss on current minibatch is 0.693855, and regularization loss is 0.000708.\n",
      " Top K precision = 0.011666666666666667, recall = 0.005711941567204725.\n",
      "Training on epoch 1 minibatch 4301/5000 completed\n",
      " bpr_loss on current minibatch is 0.693851, and regularization loss is 0.000704.\n",
      " Top K precision = 0.015254237288135592, recall = 0.005227009388302682.\n",
      "Training on epoch 1 minibatch 4401/5000 completed\n",
      " bpr_loss on current minibatch is 0.693776, and regularization loss is 0.000629.\n",
      " Top K precision = 0.017241379310344827, recall = 0.008910699691164575.\n",
      "Training on epoch 1 minibatch 4501/5000 completed\n",
      " bpr_loss on current minibatch is 0.693818, and regularization loss is 0.000671.\n",
      " Top K precision = 0.011666666666666665, recall = 0.004987519790151369.\n",
      "Training on epoch 1 minibatch 4601/5000 completed\n",
      " bpr_loss on current minibatch is 0.693743, and regularization loss is 0.000596.\n",
      " Top K precision = 0.010169491525423728, recall = 0.004155640785154418.\n",
      "Training on epoch 1 minibatch 4701/5000 completed\n",
      " bpr_loss on current minibatch is 0.693646, and regularization loss is 0.000498.\n",
      " Top K precision = 0.01, recall = 0.005152603076831752.\n",
      "Training on epoch 1 minibatch 4801/5000 completed\n",
      " bpr_loss on current minibatch is 0.693937, and regularization loss is 0.00079.\n",
      " Top K precision = 0.00847457627118644, recall = 0.0026772535247111522.\n",
      "Training on epoch 1 minibatch 4901/5000 completed\n",
      " bpr_loss on current minibatch is 0.693902, and regularization loss is 0.000754.\n",
      " Top K precision = 0.005084745762711865, recall = 0.003018178003566665.\n",
      "\n",
      "Training on 1 epoch completed.\n",
      " Average bpr_loss on train set is 0.011561 for the current epoch.\n",
      " Training top K precision = 0.01546666666666678, recall = 0.006904797075272039.\n",
      " Average bpr_loss on the validation set is 2e-06, and regularization loss is 0.0.\n",
      " Validation top K precision = 0.015500000000000118, recall = 0.006630592847299211.\n",
      "\n",
      "Training on the 2 epoch\n",
      "Training on epoch 2 minibatch 1/5000 completed\n",
      " bpr_loss on current minibatch is 0.693927, and regularization loss is 0.00078.\n",
      " Top K precision = 0.005084745762711865, recall = 0.0013628704529685795.\n",
      "Training on epoch 2 minibatch 101/5000 completed\n",
      " bpr_loss on current minibatch is 0.693656, and regularization loss is 0.000509.\n",
      " Top K precision = 0.01833333333333333, recall = 0.008346049813640143.\n",
      "Training on epoch 2 minibatch 201/5000 completed\n",
      " bpr_loss on current minibatch is 0.693887, and regularization loss is 0.00074.\n",
      " Top K precision = 0.011864406779661017, recall = 0.005191858405698396.\n",
      "Training on epoch 2 minibatch 301/5000 completed\n",
      " bpr_loss on current minibatch is 0.693699, and regularization loss is 0.000552.\n",
      " Top K precision = 0.011666666666666665, recall = 0.005193355119825708.\n",
      "Training on epoch 2 minibatch 401/5000 completed\n",
      " bpr_loss on current minibatch is 0.69382, and regularization loss is 0.000673.\n",
      " Top K precision = 0.02, recall = 0.007861713328512014.\n",
      "Training on epoch 2 minibatch 501/5000 completed\n",
      " bpr_loss on current minibatch is 0.693926, and regularization loss is 0.000779.\n",
      " Top K precision = 0.005000000000000001, recall = 0.0031469298245614037.\n",
      "Training on epoch 2 minibatch 601/5000 completed\n",
      " bpr_loss on current minibatch is 0.693758, and regularization loss is 0.000611.\n",
      " Top K precision = 0.006666666666666667, recall = 0.0037894570707070704.\n",
      "Training on epoch 2 minibatch 701/5000 completed\n",
      " bpr_loss on current minibatch is 0.693791, and regularization loss is 0.000644.\n",
      " Top K precision = 0.013333333333333332, recall = 0.0049748073290068725.\n",
      "Training on epoch 2 minibatch 801/5000 completed\n",
      " bpr_loss on current minibatch is 0.693716, and regularization loss is 0.000569.\n",
      " Top K precision = 0.016666666666666666, recall = 0.00844756455587201.\n",
      "Training on epoch 2 minibatch 901/5000 completed\n",
      " bpr_loss on current minibatch is 0.693844, and regularization loss is 0.000696.\n",
      " Top K precision = 0.013333333333333332, recall = 0.00712452959434069.\n",
      "Training on epoch 2 minibatch 1001/5000 completed\n",
      " bpr_loss on current minibatch is 0.69382, and regularization loss is 0.000673.\n",
      " Top K precision = 0.00847457627118644, recall = 0.005056251107305261.\n",
      "Training on epoch 2 minibatch 1101/5000 completed\n",
      " bpr_loss on current minibatch is 0.693836, and regularization loss is 0.000689.\n",
      " Top K precision = 0.00847457627118644, recall = 0.003002438000789627.\n",
      "Training on epoch 2 minibatch 1201/5000 completed\n",
      " bpr_loss on current minibatch is 0.693798, and regularization loss is 0.000651.\n",
      " Top K precision = 0.017241379310344827, recall = 0.007908028385502497.\n",
      "Training on epoch 2 minibatch 1301/5000 completed\n",
      " bpr_loss on current minibatch is 0.693727, and regularization loss is 0.00058.\n",
      " Top K precision = 0.011666666666666665, recall = 0.004852960612764534.\n",
      "Training on epoch 2 minibatch 1401/5000 completed\n",
      " bpr_loss on current minibatch is 0.693896, and regularization loss is 0.000749.\n",
      " Top K precision = 0.010169491525423728, recall = 0.003980573109782788.\n",
      "Training on epoch 2 minibatch 1501/5000 completed\n",
      " bpr_loss on current minibatch is 0.693753, and regularization loss is 0.000606.\n",
      " Top K precision = 0.011666666666666665, recall = 0.00652241009125067.\n",
      "Training on epoch 2 minibatch 1601/5000 completed\n",
      " bpr_loss on current minibatch is 0.693879, and regularization loss is 0.000732.\n",
      " Top K precision = 0.005084745762711865, recall = 0.0027988403211418374.\n",
      "Training on epoch 2 minibatch 1701/5000 completed\n",
      " bpr_loss on current minibatch is 0.693718, and regularization loss is 0.000571.\n",
      " Top K precision = 0.013333333333333332, recall = 0.006343109612265959.\n",
      "Training on epoch 2 minibatch 1801/5000 completed\n",
      " bpr_loss on current minibatch is 0.693865, and regularization loss is 0.000718.\n",
      " Top K precision = 0.01, recall = 0.005287815629819958.\n",
      "Training on epoch 2 minibatch 1901/5000 completed\n",
      " bpr_loss on current minibatch is 0.693784, and regularization loss is 0.000637.\n",
      " Top K precision = 0.013333333333333332, recall = 0.004119258090560168.\n",
      "Training on epoch 2 minibatch 2001/5000 completed\n",
      " bpr_loss on current minibatch is 0.693814, and regularization loss is 0.000667.\n",
      " Top K precision = 0.011864406779661016, recall = 0.006373381797110611.\n",
      "Training on epoch 2 minibatch 2101/5000 completed\n",
      " bpr_loss on current minibatch is 0.693871, and regularization loss is 0.000724.\n",
      " Top K precision = 0.010169491525423728, recall = 0.004666240171030149.\n",
      "Training on epoch 2 minibatch 2201/5000 completed\n",
      " bpr_loss on current minibatch is 0.693675, and regularization loss is 0.000528.\n",
      " Top K precision = 0.006666666666666667, recall = 0.002607515940849274.\n",
      "Training on epoch 2 minibatch 2301/5000 completed\n",
      " bpr_loss on current minibatch is 0.69377, and regularization loss is 0.000623.\n",
      " Top K precision = 0.013333333333333332, recall = 0.00498510186010186.\n",
      "Training on epoch 2 minibatch 2401/5000 completed\n",
      " bpr_loss on current minibatch is 0.693818, and regularization loss is 0.00067.\n",
      " Top K precision = 0.015254237288135592, recall = 0.007308510698341208.\n",
      "Training on epoch 2 minibatch 2501/5000 completed\n",
      " bpr_loss on current minibatch is 0.693802, and regularization loss is 0.000655.\n",
      " Top K precision = 0.013333333333333332, recall = 0.00952191401788176.\n",
      "Training on epoch 2 minibatch 2601/5000 completed\n",
      " bpr_loss on current minibatch is 0.693885, and regularization loss is 0.000738.\n",
      " Top K precision = 0.010344827586206896, recall = 0.0031373781925105094.\n",
      "Training on epoch 2 minibatch 2701/5000 completed\n",
      " bpr_loss on current minibatch is 0.693767, and regularization loss is 0.00062.\n",
      " Top K precision = 0.010000000000000002, recall = 0.004646927146927147.\n",
      "Training on epoch 2 minibatch 2801/5000 completed\n",
      " bpr_loss on current minibatch is 0.693975, and regularization loss is 0.000827.\n",
      " Top K precision = 0.013333333333333332, recall = 0.004798334048334048.\n",
      "Training on epoch 2 minibatch 2901/5000 completed\n",
      " bpr_loss on current minibatch is 0.693745, and regularization loss is 0.000597.\n",
      " Top K precision = 0.013333333333333332, recall = 0.006988925464264409.\n",
      "Training on epoch 2 minibatch 3001/5000 completed\n",
      " bpr_loss on current minibatch is 0.69393, and regularization loss is 0.000783.\n",
      " Top K precision = 0.010169491525423728, recall = 0.0024180362053239806.\n",
      "Training on epoch 2 minibatch 3101/5000 completed\n",
      " bpr_loss on current minibatch is 0.693801, and regularization loss is 0.000654.\n",
      " Top K precision = 0.005084745762711865, recall = 0.0016481257980444633.\n",
      "Training on epoch 2 minibatch 3201/5000 completed\n",
      " bpr_loss on current minibatch is 0.693685, and regularization loss is 0.000538.\n",
      " Top K precision = 0.01379310344827586, recall = 0.006429016720478241.\n",
      "Training on epoch 2 minibatch 3301/5000 completed\n",
      " bpr_loss on current minibatch is 0.693599, and regularization loss is 0.000452.\n",
      " Top K precision = 0.011864406779661016, recall = 0.005248764888595396.\n",
      "Training on epoch 2 minibatch 3401/5000 completed\n",
      " bpr_loss on current minibatch is 0.693751, and regularization loss is 0.000603.\n",
      " Top K precision = 0.013333333333333332, recall = 0.004970402751392575.\n",
      "Training on epoch 2 minibatch 3501/5000 completed\n",
      " bpr_loss on current minibatch is 0.693698, and regularization loss is 0.000551.\n",
      " Top K precision = 0.010169491525423728, recall = 0.0032493955107681894.\n",
      "Training on epoch 2 minibatch 3601/5000 completed\n",
      " bpr_loss on current minibatch is 0.693766, and regularization loss is 0.000619.\n",
      " Top K precision = 0.014999999999999998, recall = 0.006737158538629126.\n",
      "Training on epoch 2 minibatch 3701/5000 completed\n",
      " bpr_loss on current minibatch is 0.693725, and regularization loss is 0.000578.\n",
      " Top K precision = 0.01864406779661017, recall = 0.005487587325757027.\n",
      "Training on epoch 2 minibatch 3801/5000 completed\n",
      " bpr_loss on current minibatch is 0.693872, and regularization loss is 0.000725.\n",
      " Top K precision = 0.016949152542372878, recall = 0.007408553417301366.\n",
      "Training on epoch 2 minibatch 3901/5000 completed\n",
      " bpr_loss on current minibatch is 0.69384, and regularization loss is 0.000693.\n",
      " Top K precision = 0.010000000000000002, recall = 0.0034288455121788456.\n",
      "Training on epoch 2 minibatch 4001/5000 completed\n",
      " bpr_loss on current minibatch is 0.693713, and regularization loss is 0.000566.\n",
      " Top K precision = 0.011864406779661016, recall = 0.0067126094244738315.\n",
      "Training on epoch 2 minibatch 4101/5000 completed\n",
      " bpr_loss on current minibatch is 0.693666, and regularization loss is 0.000519.\n",
      " Top K precision = 0.011864406779661016, recall = 0.004690252772061359.\n",
      "Training on epoch 2 minibatch 4201/5000 completed\n",
      " bpr_loss on current minibatch is 0.693955, and regularization loss is 0.000808.\n",
      " Top K precision = 0.011666666666666665, recall = 0.0036415744749078087.\n",
      "Training on epoch 2 minibatch 4301/5000 completed\n",
      " bpr_loss on current minibatch is 0.693761, and regularization loss is 0.000613.\n",
      " Top K precision = 0.013333333333333332, recall = 0.004973806788447832.\n",
      "Training on epoch 2 minibatch 4401/5000 completed\n",
      " bpr_loss on current minibatch is 0.693601, and regularization loss is 0.000454.\n",
      " Top K precision = 0.016666666666666666, recall = 0.00605850678375741.\n",
      "Training on epoch 2 minibatch 4501/5000 completed\n",
      " bpr_loss on current minibatch is 0.693849, and regularization loss is 0.000702.\n",
      " Top K precision = 0.015254237288135592, recall = 0.005972963975207246.\n",
      "Training on epoch 2 minibatch 4601/5000 completed\n",
      " bpr_loss on current minibatch is 0.693774, and regularization loss is 0.000627.\n",
      " Top K precision = 0.013333333333333332, recall = 0.006791991152338551.\n",
      "Training on epoch 2 minibatch 4701/5000 completed\n",
      " bpr_loss on current minibatch is 0.693638, and regularization loss is 0.000491.\n",
      " Top K precision = 0.01, recall = 0.0039785938963570544.\n",
      "Training on epoch 2 minibatch 4801/5000 completed\n",
      " bpr_loss on current minibatch is 0.693783, and regularization loss is 0.000636.\n",
      " Top K precision = 0.011864406779661016, recall = 0.006191042230292899.\n",
      "Training on epoch 2 minibatch 4901/5000 completed\n",
      " bpr_loss on current minibatch is 0.693952, and regularization loss is 0.000805.\n",
      " Top K precision = 0.016949152542372878, recall = 0.009674913912202047.\n",
      "\n",
      "Training on 2 epoch completed.\n",
      " Average bpr_loss on train set is 0.011563 for the current epoch.\n",
      " Training top K precision = 0.01403333333333343, recall = 0.006322953972261102.\n",
      " Average bpr_loss on the validation set is 2e-06, and regularization loss is 0.0.\n",
      " Validation top K precision = 0.0144000000000001, recall = 0.006426315415074086.\n",
      "\n",
      "Training on the 3 epoch\n",
      "Training on epoch 3 minibatch 1/5000 completed\n",
      " bpr_loss on current minibatch is 0.693759, and regularization loss is 0.000612.\n",
      " Top K precision = 0.008333333333333333, recall = 0.0035469791685762645.\n",
      "Training on epoch 3 minibatch 101/5000 completed\n",
      " bpr_loss on current minibatch is 0.693901, and regularization loss is 0.000754.\n",
      " Top K precision = 0.013559322033898305, recall = 0.004824755735952536.\n",
      "Training on epoch 3 minibatch 201/5000 completed\n",
      " bpr_loss on current minibatch is 0.693867, and regularization loss is 0.00072.\n",
      " Top K precision = 0.011864406779661016, recall = 0.005446452019233674.\n",
      "Training on epoch 3 minibatch 301/5000 completed\n",
      " bpr_loss on current minibatch is 0.693827, and regularization loss is 0.00068.\n",
      " Top K precision = 0.02, recall = 0.008356957868626667.\n",
      "Training on epoch 3 minibatch 401/5000 completed\n",
      " bpr_loss on current minibatch is 0.693879, and regularization loss is 0.000731.\n",
      " Top K precision = 0.00847457627118644, recall = 0.0044934432445583195.\n",
      "Training on epoch 3 minibatch 501/5000 completed\n",
      " bpr_loss on current minibatch is 0.693814, and regularization loss is 0.000667.\n",
      " Top K precision = 0.013559322033898305, recall = 0.004390231954906353.\n",
      "Training on epoch 3 minibatch 601/5000 completed\n",
      " bpr_loss on current minibatch is 0.693824, and regularization loss is 0.000677.\n",
      " Top K precision = 0.01, recall = 0.0041258736141290995.\n",
      "Training on epoch 3 minibatch 701/5000 completed\n",
      " bpr_loss on current minibatch is 0.693816, and regularization loss is 0.000669.\n",
      " Top K precision = 0.011666666666666665, recall = 0.003321608063499128.\n",
      "Training on epoch 3 minibatch 801/5000 completed\n",
      " bpr_loss on current minibatch is 0.693661, and regularization loss is 0.000514.\n",
      " Top K precision = 0.01833333333333333, recall = 0.005940957190957191.\n",
      "Training on epoch 3 minibatch 901/5000 completed\n",
      " bpr_loss on current minibatch is 0.693721, and regularization loss is 0.000574.\n",
      " Top K precision = 0.01, recall = 0.0037960434465307024.\n",
      "Training on epoch 3 minibatch 1001/5000 completed\n",
      " bpr_loss on current minibatch is 0.693934, and regularization loss is 0.000787.\n",
      " Top K precision = 0.020338983050847456, recall = 0.0104270572656985.\n",
      "Training on epoch 3 minibatch 1101/5000 completed\n",
      " bpr_loss on current minibatch is 0.693699, and regularization loss is 0.000552.\n",
      " Top K precision = 0.02, recall = 0.008678047855614934.\n",
      "Training on epoch 3 minibatch 1201/5000 completed\n",
      " bpr_loss on current minibatch is 0.693908, and regularization loss is 0.000761.\n",
      " Top K precision = 0.010169491525423728, recall = 0.0073483014160980265.\n",
      "Training on epoch 3 minibatch 1301/5000 completed\n",
      " bpr_loss on current minibatch is 0.693777, and regularization loss is 0.00063.\n",
      " Top K precision = 0.017241379310344827, recall = 0.007233663354353009.\n",
      "Training on epoch 3 minibatch 1401/5000 completed\n",
      " bpr_loss on current minibatch is 0.693777, and regularization loss is 0.000629.\n",
      " Top K precision = 0.014999999999999998, recall = 0.0055723914050096355.\n",
      "Training on epoch 3 minibatch 1501/5000 completed\n",
      " bpr_loss on current minibatch is 0.693833, and regularization loss is 0.000686.\n",
      " Top K precision = 0.011666666666666665, recall = 0.004138537003120336.\n",
      "Training on epoch 3 minibatch 1601/5000 completed\n",
      " bpr_loss on current minibatch is 0.693761, and regularization loss is 0.000613.\n",
      " Top K precision = 0.01, recall = 0.00283103233607892.\n",
      "Training on epoch 3 minibatch 1701/5000 completed\n",
      " bpr_loss on current minibatch is 0.693843, and regularization loss is 0.000696.\n",
      " Top K precision = 0.013559322033898305, recall = 0.006164470450184735.\n",
      "Training on epoch 3 minibatch 1801/5000 completed\n",
      " bpr_loss on current minibatch is 0.693738, and regularization loss is 0.00059.\n",
      " Top K precision = 0.01, recall = 0.0027044444115081456.\n",
      "Training on epoch 3 minibatch 1901/5000 completed\n",
      " bpr_loss on current minibatch is 0.693876, and regularization loss is 0.000729.\n",
      " Top K precision = 0.010169491525423728, recall = 0.005170737786640079.\n",
      "Training on epoch 3 minibatch 2001/5000 completed\n",
      " bpr_loss on current minibatch is 0.693875, and regularization loss is 0.000728.\n",
      " Top K precision = 0.013333333333333332, recall = 0.005205749354005168.\n",
      "Training on epoch 3 minibatch 2101/5000 completed\n",
      " bpr_loss on current minibatch is 0.69384, and regularization loss is 0.000693.\n",
      " Top K precision = 0.006666666666666667, recall = 0.003437494999279896.\n",
      "Training on epoch 3 minibatch 2201/5000 completed\n",
      " bpr_loss on current minibatch is 0.693702, and regularization loss is 0.000555.\n",
      " Top K precision = 0.014999999999999998, recall = 0.003998186449747616.\n",
      "Training on epoch 3 minibatch 2301/5000 completed\n",
      " bpr_loss on current minibatch is 0.693725, and regularization loss is 0.000577.\n",
      " Top K precision = 0.010169491525423728, recall = 0.006876513317191283.\n",
      "Training on epoch 3 minibatch 2401/5000 completed\n",
      " bpr_loss on current minibatch is 0.693806, and regularization loss is 0.000659.\n",
      " Top K precision = 0.011864406779661016, recall = 0.005192053709002862.\n",
      "Training on epoch 3 minibatch 2501/5000 completed\n",
      " bpr_loss on current minibatch is 0.693886, and regularization loss is 0.000739.\n",
      " Top K precision = 0.013333333333333332, recall = 0.008853365854644628.\n",
      "Training on epoch 3 minibatch 2601/5000 completed\n",
      " bpr_loss on current minibatch is 0.693612, and regularization loss is 0.000465.\n",
      " Top K precision = 0.01379310344827586, recall = 0.005846301876063364.\n",
      "Training on epoch 3 minibatch 2701/5000 completed\n",
      " bpr_loss on current minibatch is 0.693839, and regularization loss is 0.000692.\n",
      " Top K precision = 0.021666666666666667, recall = 0.009048158364589687.\n",
      "Training on epoch 3 minibatch 2801/5000 completed\n",
      " bpr_loss on current minibatch is 0.69366, and regularization loss is 0.000513.\n",
      " Top K precision = 0.013333333333333332, recall = 0.005104113135348884.\n",
      "Training on epoch 3 minibatch 2901/5000 completed\n",
      " bpr_loss on current minibatch is 0.693761, and regularization loss is 0.000614.\n",
      " Top K precision = 0.005000000000000001, recall = 0.002183641975308642.\n",
      "Training on epoch 3 minibatch 3001/5000 completed\n",
      " bpr_loss on current minibatch is 0.693755, and regularization loss is 0.000608.\n",
      " Top K precision = 0.00847457627118644, recall = 0.003907109839313229.\n",
      "Training on epoch 3 minibatch 3101/5000 completed\n",
      " bpr_loss on current minibatch is 0.693759, and regularization loss is 0.000612.\n",
      " Top K precision = 0.011666666666666665, recall = 0.007562913117348601.\n",
      "Training on epoch 3 minibatch 3201/5000 completed\n",
      " bpr_loss on current minibatch is 0.693836, and regularization loss is 0.000689.\n",
      " Top K precision = 0.015254237288135594, recall = 0.005852451064315471.\n",
      "Training on epoch 3 minibatch 3301/5000 completed\n",
      " bpr_loss on current minibatch is 0.693862, and regularization loss is 0.000715.\n",
      " Top K precision = 0.01206896551724138, recall = 0.0065319003370326555.\n",
      "Training on epoch 3 minibatch 3401/5000 completed\n",
      " bpr_loss on current minibatch is 0.693922, and regularization loss is 0.000775.\n",
      " Top K precision = 0.014035087719298244, recall = 0.005375132811195427.\n",
      "Training on epoch 3 minibatch 3501/5000 completed\n",
      " bpr_loss on current minibatch is 0.693761, and regularization loss is 0.000613.\n",
      " Top K precision = 0.008333333333333333, recall = 0.003938250096786683.\n",
      "Training on epoch 3 minibatch 3601/5000 completed\n",
      " bpr_loss on current minibatch is 0.693874, and regularization loss is 0.000727.\n",
      " Top K precision = 0.005172413793103449, recall = 0.0012921561197423268.\n",
      "Training on epoch 3 minibatch 3701/5000 completed\n",
      " bpr_loss on current minibatch is 0.693726, and regularization loss is 0.000579.\n",
      " Top K precision = 0.018965517241379314, recall = 0.008278072502210434.\n",
      "Training on epoch 3 minibatch 3801/5000 completed\n",
      " bpr_loss on current minibatch is 0.693748, and regularization loss is 0.000601.\n",
      " Top K precision = 0.013559322033898305, recall = 0.007537735581892584.\n",
      "Training on epoch 3 minibatch 3901/5000 completed\n",
      " bpr_loss on current minibatch is 0.6938, and regularization loss is 0.000653.\n",
      " Top K precision = 0.02372881355932204, recall = 0.00910788476565991.\n",
      "Training on epoch 3 minibatch 4001/5000 completed\n",
      " bpr_loss on current minibatch is 0.693781, and regularization loss is 0.000634.\n",
      " Top K precision = 0.025000000000000005, recall = 0.00984130100726106.\n",
      "Training on epoch 3 minibatch 4101/5000 completed\n",
      " bpr_loss on current minibatch is 0.693768, and regularization loss is 0.000621.\n",
      " Top K precision = 0.010169491525423728, recall = 0.004530701549988516.\n",
      "Training on epoch 3 minibatch 4201/5000 completed\n",
      " bpr_loss on current minibatch is 0.693789, and regularization loss is 0.000642.\n",
      " Top K precision = 0.01833333333333333, recall = 0.006452151651610746.\n",
      "Training on epoch 3 minibatch 4301/5000 completed\n",
      " bpr_loss on current minibatch is 0.693933, and regularization loss is 0.000786.\n",
      " Top K precision = 0.011864406779661016, recall = 0.006119496999217331.\n",
      "Training on epoch 3 minibatch 4401/5000 completed\n",
      " bpr_loss on current minibatch is 0.693815, and regularization loss is 0.000668.\n",
      " Top K precision = 0.014999999999999998, recall = 0.0073237561552778946.\n",
      "Training on epoch 3 minibatch 4501/5000 completed\n",
      " bpr_loss on current minibatch is 0.693862, and regularization loss is 0.000715.\n",
      " Top K precision = 0.014999999999999998, recall = 0.004804949229399558.\n",
      "Training on epoch 3 minibatch 4601/5000 completed\n",
      " bpr_loss on current minibatch is 0.693866, and regularization loss is 0.000718.\n",
      " Top K precision = 0.013559322033898305, recall = 0.006550058202600575.\n",
      "Training on epoch 3 minibatch 4701/5000 completed\n",
      " bpr_loss on current minibatch is 0.693807, and regularization loss is 0.00066.\n",
      " Top K precision = 0.008333333333333333, recall = 0.003163610745132484.\n",
      "Training on epoch 3 minibatch 4801/5000 completed\n",
      " bpr_loss on current minibatch is 0.693877, and regularization loss is 0.00073.\n",
      " Top K precision = 0.01, recall = 0.003489933134553369.\n",
      "Training on epoch 3 minibatch 4901/5000 completed\n",
      " bpr_loss on current minibatch is 0.693886, and regularization loss is 0.000739.\n",
      " Top K precision = 0.0033898305084745766, recall = 0.0014955134596211365.\n",
      "\n",
      "Training on 3 epoch completed.\n",
      " Average bpr_loss on train set is 0.011563 for the current epoch.\n",
      " Training top K precision = 0.014266666666666768, recall = 0.006412891590067068.\n",
      " Average bpr_loss on the validation set is 2e-06, and regularization loss is 0.0.\n",
      " Validation top K precision = 0.01413333333333343, recall = 0.006389159368438462.\n",
      "\n",
      "Training on the 4 epoch\n",
      "Training on epoch 4 minibatch 1/5000 completed\n",
      " bpr_loss on current minibatch is 0.693726, and regularization loss is 0.000579.\n",
      " Top K precision = 0.011666666666666665, recall = 0.004256253006253006.\n",
      "Training on epoch 4 minibatch 101/5000 completed\n",
      " bpr_loss on current minibatch is 0.693691, and regularization loss is 0.000544.\n",
      " Top K precision = 0.007017543859649123, recall = 0.002484555687464275.\n",
      "Training on epoch 4 minibatch 201/5000 completed\n",
      " bpr_loss on current minibatch is 0.69384, and regularization loss is 0.000693.\n",
      " Top K precision = 0.016666666666666666, recall = 0.008485174157030853.\n",
      "Training on epoch 4 minibatch 301/5000 completed\n",
      " bpr_loss on current minibatch is 0.693748, and regularization loss is 0.000601.\n",
      " Top K precision = 0.014999999999999998, recall = 0.006981032039855569.\n",
      "Training on epoch 4 minibatch 401/5000 completed\n",
      " bpr_loss on current minibatch is 0.693834, and regularization loss is 0.000687.\n",
      " Top K precision = 0.013333333333333332, recall = 0.004594293964263005.\n",
      "Training on epoch 4 minibatch 501/5000 completed\n",
      " bpr_loss on current minibatch is 0.693805, and regularization loss is 0.000658.\n",
      " Top K precision = 0.013333333333333332, recall = 0.0067302890941951824.\n",
      "Training on epoch 4 minibatch 601/5000 completed\n",
      " bpr_loss on current minibatch is 0.69375, and regularization loss is 0.000602.\n",
      " Top K precision = 0.01833333333333333, recall = 0.007853914483760358.\n",
      "Training on epoch 4 minibatch 701/5000 completed\n",
      " bpr_loss on current minibatch is 0.693859, and regularization loss is 0.000712.\n",
      " Top K precision = 0.011666666666666665, recall = 0.005393745461147422.\n",
      "Training on epoch 4 minibatch 801/5000 completed\n",
      " bpr_loss on current minibatch is 0.693825, and regularization loss is 0.000678.\n",
      " Top K precision = 0.010169491525423728, recall = 0.004786342032104743.\n",
      "Training on epoch 4 minibatch 901/5000 completed\n",
      " bpr_loss on current minibatch is 0.693841, and regularization loss is 0.000694.\n",
      " Top K precision = 0.006779661016949153, recall = 0.003983116694981102.\n",
      "Training on epoch 4 minibatch 1001/5000 completed\n",
      " bpr_loss on current minibatch is 0.693779, and regularization loss is 0.000632.\n",
      " Top K precision = 0.011666666666666665, recall = 0.006834173892282319.\n",
      "Training on epoch 4 minibatch 1101/5000 completed\n",
      " bpr_loss on current minibatch is 0.693697, and regularization loss is 0.00055.\n",
      " Top K precision = 0.008333333333333333, recall = 0.002958311825181743.\n",
      "Training on epoch 4 minibatch 1201/5000 completed\n",
      " bpr_loss on current minibatch is 0.693877, and regularization loss is 0.00073.\n",
      " Top K precision = 0.01, recall = 0.004068302201294529.\n",
      "Training on epoch 4 minibatch 1301/5000 completed\n",
      " bpr_loss on current minibatch is 0.693651, and regularization loss is 0.000504.\n",
      " Top K precision = 0.01379310344827586, recall = 0.005608025745604015.\n",
      "Training on epoch 4 minibatch 1401/5000 completed\n",
      " bpr_loss on current minibatch is 0.69385, and regularization loss is 0.000703.\n",
      " Top K precision = 0.016666666666666666, recall = 0.009130270963604296.\n",
      "Training on epoch 4 minibatch 1501/5000 completed\n",
      " bpr_loss on current minibatch is 0.69375, and regularization loss is 0.000603.\n",
      " Top K precision = 0.01, recall = 0.0036383442265795207.\n",
      "Training on epoch 4 minibatch 1601/5000 completed\n",
      " bpr_loss on current minibatch is 0.693828, and regularization loss is 0.000681.\n",
      " Top K precision = 0.018644067796610167, recall = 0.010941596393086749.\n",
      "Training on epoch 4 minibatch 1701/5000 completed\n",
      " bpr_loss on current minibatch is 0.693795, and regularization loss is 0.000648.\n",
      " Top K precision = 0.02203389830508475, recall = 0.008414457675571791.\n",
      "Training on epoch 4 minibatch 1801/5000 completed\n",
      " bpr_loss on current minibatch is 0.69374, and regularization loss is 0.000593.\n",
      " Top K precision = 0.013333333333333332, recall = 0.0075703732341041345.\n",
      "Training on epoch 4 minibatch 1901/5000 completed\n",
      " bpr_loss on current minibatch is 0.693699, and regularization loss is 0.000552.\n",
      " Top K precision = 0.01, recall = 0.004425970228601807.\n",
      "Training on epoch 4 minibatch 2001/5000 completed\n",
      " bpr_loss on current minibatch is 0.693833, and regularization loss is 0.000686.\n",
      " Top K precision = 0.013333333333333332, recall = 0.004450546215252098.\n",
      "Training on epoch 4 minibatch 2101/5000 completed\n",
      " bpr_loss on current minibatch is 0.693713, and regularization loss is 0.000566.\n",
      " Top K precision = 0.00847457627118644, recall = 0.0052525252525252525.\n",
      "Training on epoch 4 minibatch 2201/5000 completed\n",
      " bpr_loss on current minibatch is 0.693775, and regularization loss is 0.000628.\n",
      " Top K precision = 0.014999999999999998, recall = 0.006810260280655017.\n",
      "Training on epoch 4 minibatch 2301/5000 completed\n",
      " bpr_loss on current minibatch is 0.693644, and regularization loss is 0.000497.\n",
      " Top K precision = 0.01833333333333333, recall = 0.009203423890923889.\n",
      "Training on epoch 4 minibatch 2401/5000 completed\n",
      " bpr_loss on current minibatch is 0.693839, and regularization loss is 0.000691.\n",
      " Top K precision = 0.005000000000000001, recall = 0.0013989929106208176.\n",
      "Training on epoch 4 minibatch 2501/5000 completed\n",
      " bpr_loss on current minibatch is 0.693694, and regularization loss is 0.000547.\n",
      " Top K precision = 0.02, recall = 0.01079267711312855.\n",
      "Training on epoch 4 minibatch 2601/5000 completed\n",
      " bpr_loss on current minibatch is 0.693823, and regularization loss is 0.000676.\n",
      " Top K precision = 0.011666666666666665, recall = 0.0051592681197944355.\n",
      "Training on epoch 4 minibatch 2701/5000 completed\n",
      " bpr_loss on current minibatch is 0.693713, and regularization loss is 0.000565.\n",
      " Top K precision = 0.010169491525423728, recall = 0.005059774472208086.\n",
      "Training on epoch 4 minibatch 2801/5000 completed\n",
      " bpr_loss on current minibatch is 0.693735, and regularization loss is 0.000588.\n",
      " Top K precision = 0.027118644067796613, recall = 0.00968323384927583.\n",
      "Training on epoch 4 minibatch 2901/5000 completed\n",
      " bpr_loss on current minibatch is 0.693782, and regularization loss is 0.000635.\n",
      " Top K precision = 0.013559322033898305, recall = 0.008037135155779224.\n",
      "Training on epoch 4 minibatch 3001/5000 completed\n",
      " bpr_loss on current minibatch is 0.693836, and regularization loss is 0.000689.\n",
      " Top K precision = 0.016666666666666666, recall = 0.006767584501807729.\n",
      "Training on epoch 4 minibatch 3101/5000 completed\n",
      " bpr_loss on current minibatch is 0.694009, and regularization loss is 0.000862.\n",
      " Top K precision = 0.006779661016949153, recall = 0.0035841979467624266.\n",
      "Training on epoch 4 minibatch 3201/5000 completed\n",
      " bpr_loss on current minibatch is 0.693726, and regularization loss is 0.000579.\n",
      " Top K precision = 0.011666666666666665, recall = 0.004619222396923885.\n",
      "Training on epoch 4 minibatch 3301/5000 completed\n",
      " bpr_loss on current minibatch is 0.693842, and regularization loss is 0.000695.\n",
      " Top K precision = 0.011864406779661016, recall = 0.005128463814904493.\n",
      "Training on epoch 4 minibatch 3401/5000 completed\n",
      " bpr_loss on current minibatch is 0.693734, and regularization loss is 0.000587.\n",
      " Top K precision = 0.013559322033898305, recall = 0.005870029465033924.\n",
      "Training on epoch 4 minibatch 3501/5000 completed\n",
      " bpr_loss on current minibatch is 0.693798, and regularization loss is 0.000651.\n",
      " Top K precision = 0.010169491525423728, recall = 0.004956278642719321.\n",
      "Training on epoch 4 minibatch 3601/5000 completed\n",
      " bpr_loss on current minibatch is 0.693661, and regularization loss is 0.000514.\n",
      " Top K precision = 0.011864406779661017, recall = 0.004249452599140378.\n",
      "Training on epoch 4 minibatch 3701/5000 completed\n",
      " bpr_loss on current minibatch is 0.693809, and regularization loss is 0.000662.\n",
      " Top K precision = 0.006779661016949153, recall = 0.003061148634297608.\n",
      "Training on epoch 4 minibatch 3801/5000 completed\n",
      " bpr_loss on current minibatch is 0.693783, and regularization loss is 0.000636.\n",
      " Top K precision = 0.01, recall = 0.0044597605123920915.\n",
      "Training on epoch 4 minibatch 3901/5000 completed\n",
      " bpr_loss on current minibatch is 0.693864, and regularization loss is 0.000717.\n",
      " Top K precision = 0.016666666666666666, recall = 0.007794770624071699.\n",
      "Training on epoch 4 minibatch 4001/5000 completed\n",
      " bpr_loss on current minibatch is 0.69392, and regularization loss is 0.000773.\n",
      " Top K precision = 0.006666666666666667, recall = 0.0033955778520995913.\n",
      "Training on epoch 4 minibatch 4101/5000 completed\n",
      " bpr_loss on current minibatch is 0.693857, and regularization loss is 0.00071.\n",
      " Top K precision = 0.01, recall = 0.0027298273673584364.\n",
      "Training on epoch 4 minibatch 4201/5000 completed\n",
      " bpr_loss on current minibatch is 0.693563, and regularization loss is 0.000416.\n",
      " Top K precision = 0.010344827586206896, recall = 0.0038716935208205705.\n",
      "Training on epoch 4 minibatch 4301/5000 completed\n",
      " bpr_loss on current minibatch is 0.69379, and regularization loss is 0.000643.\n",
      " Top K precision = 0.0033333333333333335, recall = 0.0011223344556677889.\n",
      "Training on epoch 4 minibatch 4401/5000 completed\n",
      " bpr_loss on current minibatch is 0.693714, and regularization loss is 0.000567.\n",
      " Top K precision = 0.02, recall = 0.009032077837673246.\n",
      "Training on epoch 4 minibatch 4501/5000 completed\n",
      " bpr_loss on current minibatch is 0.693778, and regularization loss is 0.000631.\n",
      " Top K precision = 0.015254237288135592, recall = 0.005392094815684511.\n",
      "Training on epoch 4 minibatch 4601/5000 completed\n",
      " bpr_loss on current minibatch is 0.693654, and regularization loss is 0.000507.\n",
      " Top K precision = 0.016666666666666666, recall = 0.008227095729528988.\n",
      "Training on epoch 4 minibatch 4701/5000 completed\n",
      " bpr_loss on current minibatch is 0.693748, and regularization loss is 0.000601.\n",
      " Top K precision = 0.01833333333333333, recall = 0.00888646466661433.\n",
      "Training on epoch 4 minibatch 4801/5000 completed\n",
      " bpr_loss on current minibatch is 0.693733, and regularization loss is 0.000585.\n",
      " Top K precision = 0.020000000000000004, recall = 0.011714344622239359.\n",
      "Training on epoch 4 minibatch 4901/5000 completed\n",
      " bpr_loss on current minibatch is 0.69375, and regularization loss is 0.000602.\n",
      " Top K precision = 0.014999999999999998, recall = 0.006072790227201992.\n",
      "\n",
      "Training on 4 epoch completed.\n",
      " Average bpr_loss on train set is 0.011563 for the current epoch.\n",
      " Training top K precision = 0.015133333333333446, recall = 0.006902770470683388.\n",
      " Average bpr_loss on the validation set is 2e-06, and regularization loss is 0.0.\n",
      " Validation top K precision = 0.013733333333333424, recall = 0.006221258930043501.\n",
      "\n",
      "Training on the 5 epoch\n",
      "Training on epoch 5 minibatch 1/5000 completed\n",
      " bpr_loss on current minibatch is 0.693687, and regularization loss is 0.00054.\n",
      " Top K precision = 0.013333333333333332, recall = 0.005400903628873934.\n",
      "Training on epoch 5 minibatch 101/5000 completed\n",
      " bpr_loss on current minibatch is 0.693754, and regularization loss is 0.000607.\n",
      " Top K precision = 0.01, recall = 0.005260860748925539.\n",
      "Training on epoch 5 minibatch 201/5000 completed\n",
      " bpr_loss on current minibatch is 0.693852, and regularization loss is 0.000705.\n",
      " Top K precision = 0.013559322033898305, recall = 0.008068509055101517.\n",
      "Training on epoch 5 minibatch 301/5000 completed\n",
      " bpr_loss on current minibatch is 0.693776, and regularization loss is 0.000629.\n",
      " Top K precision = 0.01379310344827586, recall = 0.006467581359082976.\n",
      "Training on epoch 5 minibatch 401/5000 completed\n",
      " bpr_loss on current minibatch is 0.693882, and regularization loss is 0.000735.\n",
      " Top K precision = 0.006779661016949153, recall = 0.003056204948373271.\n",
      "Training on epoch 5 minibatch 501/5000 completed\n",
      " bpr_loss on current minibatch is 0.693723, and regularization loss is 0.000576.\n",
      " Top K precision = 0.018644067796610167, recall = 0.0068508854310104774.\n",
      "Training on epoch 5 minibatch 601/5000 completed\n",
      " bpr_loss on current minibatch is 0.693843, and regularization loss is 0.000696.\n",
      " Top K precision = 0.008333333333333333, recall = 0.005650628306878307.\n",
      "Training on epoch 5 minibatch 701/5000 completed\n",
      " bpr_loss on current minibatch is 0.693725, and regularization loss is 0.000578.\n",
      " Top K precision = 0.008333333333333333, recall = 0.005542564852027767.\n",
      "Training on epoch 5 minibatch 801/5000 completed\n",
      " bpr_loss on current minibatch is 0.693737, and regularization loss is 0.00059.\n",
      " Top K precision = 0.01, recall = 0.004261298627002289.\n",
      "Training on epoch 5 minibatch 901/5000 completed\n",
      " bpr_loss on current minibatch is 0.693721, and regularization loss is 0.000574.\n",
      " Top K precision = 0.011666666666666665, recall = 0.006901714572522025.\n",
      "Training on epoch 5 minibatch 1001/5000 completed\n",
      " bpr_loss on current minibatch is 0.693673, and regularization loss is 0.000526.\n",
      " Top K precision = 0.005084745762711865, recall = 0.002354048964218456.\n",
      "Training on epoch 5 minibatch 1101/5000 completed\n",
      " bpr_loss on current minibatch is 0.693728, and regularization loss is 0.000581.\n",
      " Top K precision = 0.011864406779661016, recall = 0.004259443828822078.\n",
      "Training on epoch 5 minibatch 1201/5000 completed\n",
      " bpr_loss on current minibatch is 0.693813, and regularization loss is 0.000666.\n",
      " Top K precision = 0.014999999999999998, recall = 0.011321398508898508.\n",
      "Training on epoch 5 minibatch 1301/5000 completed\n",
      " bpr_loss on current minibatch is 0.693732, and regularization loss is 0.000585.\n",
      " Top K precision = 0.011864406779661016, recall = 0.0041548242618715415.\n",
      "Training on epoch 5 minibatch 1401/5000 completed\n",
      " bpr_loss on current minibatch is 0.693761, and regularization loss is 0.000613.\n",
      " Top K precision = 0.006779661016949153, recall = 0.0030472045402254776.\n",
      "Training on epoch 5 minibatch 1501/5000 completed\n",
      " bpr_loss on current minibatch is 0.693674, and regularization loss is 0.000527.\n",
      " Top K precision = 0.013333333333333332, recall = 0.008186068880034399.\n",
      "Training on epoch 5 minibatch 1601/5000 completed\n",
      " bpr_loss on current minibatch is 0.693847, and regularization loss is 0.0007.\n",
      " Top K precision = 0.02, recall = 0.007714708809839598.\n",
      "Training on epoch 5 minibatch 1701/5000 completed\n",
      " bpr_loss on current minibatch is 0.693793, and regularization loss is 0.000646.\n",
      " Top K precision = 0.011864406779661016, recall = 0.0041011549269908834.\n",
      "Training on epoch 5 minibatch 1801/5000 completed\n",
      " bpr_loss on current minibatch is 0.69371, and regularization loss is 0.000563.\n",
      " Top K precision = 0.01864406779661017, recall = 0.006812871743302919.\n",
      "Training on epoch 5 minibatch 1901/5000 completed\n",
      " bpr_loss on current minibatch is 0.693851, and regularization loss is 0.000703.\n",
      " Top K precision = 0.005263157894736843, recall = 0.0017772926941008436.\n",
      "Training on epoch 5 minibatch 2001/5000 completed\n",
      " bpr_loss on current minibatch is 0.693827, and regularization loss is 0.00068.\n",
      " Top K precision = 0.01, recall = 0.005042540280795766.\n",
      "Training on epoch 5 minibatch 2101/5000 completed\n",
      " bpr_loss on current minibatch is 0.693802, and regularization loss is 0.000655.\n",
      " Top K precision = 0.013333333333333332, recall = 0.006386477901183784.\n",
      "Training on epoch 5 minibatch 2201/5000 completed\n",
      " bpr_loss on current minibatch is 0.693923, and regularization loss is 0.000776.\n",
      " Top K precision = 0.013333333333333332, recall = 0.007224867724867723.\n",
      "Training on epoch 5 minibatch 2301/5000 completed\n",
      " bpr_loss on current minibatch is 0.693744, and regularization loss is 0.000596.\n",
      " Top K precision = 0.018965517241379307, recall = 0.008120906162339346.\n",
      "Training on epoch 5 minibatch 2401/5000 completed\n",
      " bpr_loss on current minibatch is 0.693722, and regularization loss is 0.000575.\n",
      " Top K precision = 0.010169491525423728, recall = 0.004953828989222808.\n",
      "Training on epoch 5 minibatch 2501/5000 completed\n",
      " bpr_loss on current minibatch is 0.693714, and regularization loss is 0.000567.\n",
      " Top K precision = 0.01, recall = 0.004047847306890054.\n",
      "Training on epoch 5 minibatch 2601/5000 completed\n",
      " bpr_loss on current minibatch is 0.693724, and regularization loss is 0.000577.\n",
      " Top K precision = 0.008333333333333333, recall = 0.002882936507936508.\n",
      "Training on epoch 5 minibatch 2701/5000 completed\n",
      " bpr_loss on current minibatch is 0.693757, and regularization loss is 0.00061.\n",
      " Top K precision = 0.013333333333333332, recall = 0.006245539953000366.\n",
      "Training on epoch 5 minibatch 2801/5000 completed\n",
      " bpr_loss on current minibatch is 0.693807, and regularization loss is 0.00066.\n",
      " Top K precision = 0.006666666666666667, recall = 0.0016388888888888887.\n",
      "Training on epoch 5 minibatch 2901/5000 completed\n",
      " bpr_loss on current minibatch is 0.693772, and regularization loss is 0.000625.\n",
      " Top K precision = 0.01833333333333333, recall = 0.007317373997721369.\n",
      "Training on epoch 5 minibatch 3001/5000 completed\n",
      " bpr_loss on current minibatch is 0.693781, and regularization loss is 0.000634.\n",
      " Top K precision = 0.016666666666666666, recall = 0.006195919538393718.\n",
      "Training on epoch 5 minibatch 3101/5000 completed\n",
      " bpr_loss on current minibatch is 0.693816, and regularization loss is 0.000668.\n",
      " Top K precision = 0.016666666666666666, recall = 0.008385918022545928.\n",
      "Training on epoch 5 minibatch 3201/5000 completed\n",
      " bpr_loss on current minibatch is 0.694035, and regularization loss is 0.000887.\n",
      " Top K precision = 0.013333333333333332, recall = 0.0044595588526931676.\n",
      "Training on epoch 5 minibatch 3301/5000 completed\n",
      " bpr_loss on current minibatch is 0.693853, and regularization loss is 0.000706.\n",
      " Top K precision = 0.021666666666666667, recall = 0.008032088890847581.\n",
      "Training on epoch 5 minibatch 3401/5000 completed\n",
      " bpr_loss on current minibatch is 0.693931, and regularization loss is 0.000784.\n",
      " Top K precision = 0.01, recall = 0.006095653200916359.\n",
      "Training on epoch 5 minibatch 3501/5000 completed\n",
      " bpr_loss on current minibatch is 0.693784, and regularization loss is 0.000637.\n",
      " Top K precision = 0.015517241379310343, recall = 0.011179439627715488.\n",
      "Training on epoch 5 minibatch 3601/5000 completed\n",
      " bpr_loss on current minibatch is 0.69398, and regularization loss is 0.000832.\n",
      " Top K precision = 0.011666666666666665, recall = 0.0041726583148151775.\n",
      "Training on epoch 5 minibatch 3701/5000 completed\n",
      " bpr_loss on current minibatch is 0.693826, and regularization loss is 0.000679.\n",
      " Top K precision = 0.011666666666666665, recall = 0.0035109708124414006.\n",
      "Training on epoch 5 minibatch 3801/5000 completed\n",
      " bpr_loss on current minibatch is 0.693778, and regularization loss is 0.000631.\n",
      " Top K precision = 0.01, recall = 0.0037953092280618664.\n",
      "Training on epoch 5 minibatch 3901/5000 completed\n",
      " bpr_loss on current minibatch is 0.693743, and regularization loss is 0.000596.\n",
      " Top K precision = 0.015000000000000001, recall = 0.00642094017094017.\n",
      "Training on epoch 5 minibatch 4001/5000 completed\n",
      " bpr_loss on current minibatch is 0.694049, and regularization loss is 0.000902.\n",
      " Top K precision = 0.008333333333333333, recall = 0.002894042232277526.\n",
      "Training on epoch 5 minibatch 4101/5000 completed\n",
      " bpr_loss on current minibatch is 0.693841, and regularization loss is 0.000693.\n",
      " Top K precision = 0.016949152542372878, recall = 0.005762341054850622.\n",
      "Training on epoch 5 minibatch 4201/5000 completed\n",
      " bpr_loss on current minibatch is 0.693721, and regularization loss is 0.000574.\n",
      " Top K precision = 0.006779661016949153, recall = 0.002837455674596426.\n",
      "Training on epoch 5 minibatch 4301/5000 completed\n",
      " bpr_loss on current minibatch is 0.693833, and regularization loss is 0.000686.\n",
      " Top K precision = 0.014999999999999998, recall = 0.006470172533769025.\n",
      "Training on epoch 5 minibatch 4401/5000 completed\n",
      " bpr_loss on current minibatch is 0.693887, and regularization loss is 0.00074.\n",
      " Top K precision = 0.006779661016949153, recall = 0.003540652693195066.\n",
      "Training on epoch 5 minibatch 4501/5000 completed\n",
      " bpr_loss on current minibatch is 0.693809, and regularization loss is 0.000661.\n",
      " Top K precision = 0.011666666666666665, recall = 0.005902289656037781.\n",
      "Training on epoch 5 minibatch 4601/5000 completed\n",
      " bpr_loss on current minibatch is 0.693776, and regularization loss is 0.000629.\n",
      " Top K precision = 0.013559322033898305, recall = 0.006469004755124656.\n",
      "Training on epoch 5 minibatch 4701/5000 completed\n",
      " bpr_loss on current minibatch is 0.693684, and regularization loss is 0.000537.\n",
      " Top K precision = 0.016949152542372878, recall = 0.005934737152806548.\n",
      "Training on epoch 5 minibatch 4801/5000 completed\n",
      " bpr_loss on current minibatch is 0.693854, and regularization loss is 0.000707.\n",
      " Top K precision = 0.015254237288135592, recall = 0.006427783919728745.\n",
      "Training on epoch 5 minibatch 4901/5000 completed\n",
      " bpr_loss on current minibatch is 0.693749, and regularization loss is 0.000602.\n",
      " Top K precision = 0.00847457627118644, recall = 0.005026337029013211.\n",
      "\n",
      "Training on 5 epoch completed.\n",
      " Average bpr_loss on train set is 0.011563 for the current epoch.\n",
      " Training top K precision = 0.0144000000000001, recall = 0.006333105697105202.\n",
      " Average bpr_loss on the validation set is 2e-06, and regularization loss is 0.0.\n",
      " Validation top K precision = 0.015333333333333435, recall = 0.006832761600335294.\n",
      "\n",
      "Training on the 6 epoch\n",
      "Training on epoch 6 minibatch 1/5000 completed\n",
      " bpr_loss on current minibatch is 0.693941, and regularization loss is 0.000794.\n",
      " Top K precision = 0.01206896551724138, recall = 0.0035919540229885053.\n",
      "Training on epoch 6 minibatch 101/5000 completed\n",
      " bpr_loss on current minibatch is 0.693864, and regularization loss is 0.000717.\n",
      " Top K precision = 0.011864406779661016, recall = 0.005109516566553149.\n",
      "Training on epoch 6 minibatch 201/5000 completed\n",
      " bpr_loss on current minibatch is 0.693785, and regularization loss is 0.000638.\n",
      " Top K precision = 0.013333333333333332, recall = 0.005163535775490234.\n",
      "Training on epoch 6 minibatch 301/5000 completed\n",
      " bpr_loss on current minibatch is 0.693696, and regularization loss is 0.000549.\n",
      " Top K precision = 0.01206896551724138, recall = 0.004043740725674901.\n",
      "Training on epoch 6 minibatch 401/5000 completed\n",
      " bpr_loss on current minibatch is 0.693699, and regularization loss is 0.000552.\n",
      " Top K precision = 0.011666666666666665, recall = 0.0059971424774056354.\n",
      "Training on epoch 6 minibatch 501/5000 completed\n",
      " bpr_loss on current minibatch is 0.693937, and regularization loss is 0.00079.\n",
      " Top K precision = 0.013333333333333332, recall = 0.007029520280799053.\n",
      "Training on epoch 6 minibatch 601/5000 completed\n",
      " bpr_loss on current minibatch is 0.693735, and regularization loss is 0.000588.\n",
      " Top K precision = 0.006779661016949153, recall = 0.0024618530944162174.\n",
      "Training on epoch 6 minibatch 701/5000 completed\n",
      " bpr_loss on current minibatch is 0.693701, and regularization loss is 0.000554.\n",
      " Top K precision = 0.013559322033898305, recall = 0.0068221314065303835.\n",
      "Training on epoch 6 minibatch 801/5000 completed\n",
      " bpr_loss on current minibatch is 0.693938, and regularization loss is 0.000791.\n",
      " Top K precision = 0.013559322033898305, recall = 0.004372688322133091.\n",
      "Training on epoch 6 minibatch 901/5000 completed\n",
      " bpr_loss on current minibatch is 0.693999, and regularization loss is 0.000852.\n",
      " Top K precision = 0.016666666666666666, recall = 0.008037043536123898.\n",
      "Training on epoch 6 minibatch 1001/5000 completed\n",
      " bpr_loss on current minibatch is 0.693793, and regularization loss is 0.000646.\n",
      " Top K precision = 0.015254237288135592, recall = 0.005856617601664151.\n",
      "Training on epoch 6 minibatch 1101/5000 completed\n",
      " bpr_loss on current minibatch is 0.693758, and regularization loss is 0.00061.\n",
      " Top K precision = 0.008333333333333333, recall = 0.0024777108800097306.\n",
      "Training on epoch 6 minibatch 1201/5000 completed\n",
      " bpr_loss on current minibatch is 0.693678, and regularization loss is 0.000531.\n",
      " Top K precision = 0.013559322033898305, recall = 0.005908836822239398.\n",
      "Training on epoch 6 minibatch 1301/5000 completed\n",
      " bpr_loss on current minibatch is 0.693731, and regularization loss is 0.000583.\n",
      " Top K precision = 0.01206896551724138, recall = 0.007488842575049471.\n",
      "Training on epoch 6 minibatch 1401/5000 completed\n",
      " bpr_loss on current minibatch is 0.693852, and regularization loss is 0.000705.\n",
      " Top K precision = 0.011864406779661016, recall = 0.007082633961864691.\n",
      "Training on epoch 6 minibatch 1501/5000 completed\n",
      " bpr_loss on current minibatch is 0.693646, and regularization loss is 0.000499.\n",
      " Top K precision = 0.017241379310344827, recall = 0.0073534300670732465.\n",
      "Training on epoch 6 minibatch 1601/5000 completed\n",
      " bpr_loss on current minibatch is 0.693633, and regularization loss is 0.000486.\n",
      " Top K precision = 0.01, recall = 0.005467172563209149.\n",
      "Training on epoch 6 minibatch 1701/5000 completed\n",
      " bpr_loss on current minibatch is 0.693765, and regularization loss is 0.000618.\n",
      " Top K precision = 0.014999999999999998, recall = 0.009058520751295686.\n",
      "Training on epoch 6 minibatch 1801/5000 completed\n",
      " bpr_loss on current minibatch is 0.693719, and regularization loss is 0.000572.\n",
      " Top K precision = 0.010169491525423728, recall = 0.0041659769161136034.\n",
      "Training on epoch 6 minibatch 1901/5000 completed\n",
      " bpr_loss on current minibatch is 0.693718, and regularization loss is 0.000571.\n",
      " Top K precision = 0.023333333333333334, recall = 0.012194970588992328.\n",
      "Training on epoch 6 minibatch 2001/5000 completed\n",
      " bpr_loss on current minibatch is 0.69376, and regularization loss is 0.000613.\n",
      " Top K precision = 0.011666666666666665, recall = 0.006205484330484331.\n",
      "Training on epoch 6 minibatch 2101/5000 completed\n",
      " bpr_loss on current minibatch is 0.693771, and regularization loss is 0.000624.\n",
      " Top K precision = 0.013333333333333332, recall = 0.005761661858475584.\n",
      "Training on epoch 6 minibatch 2201/5000 completed\n",
      " bpr_loss on current minibatch is 0.693817, and regularization loss is 0.00067.\n",
      " Top K precision = 0.008333333333333333, recall = 0.0033461214711214705.\n",
      "Training on epoch 6 minibatch 2301/5000 completed\n",
      " bpr_loss on current minibatch is 0.693819, and regularization loss is 0.000672.\n",
      " Top K precision = 0.0033333333333333335, recall = 0.0019444444444444444.\n",
      "Training on epoch 6 minibatch 2401/5000 completed\n",
      " bpr_loss on current minibatch is 0.693734, and regularization loss is 0.000586.\n",
      " Top K precision = 0.016666666666666666, recall = 0.005999055401900146.\n",
      "Training on epoch 6 minibatch 2501/5000 completed\n",
      " bpr_loss on current minibatch is 0.693745, and regularization loss is 0.000597.\n",
      " Top K precision = 0.005084745762711865, recall = 0.0017196856635063752.\n",
      "Training on epoch 6 minibatch 2601/5000 completed\n",
      " bpr_loss on current minibatch is 0.69392, and regularization loss is 0.000773.\n",
      " Top K precision = 0.013333333333333332, recall = 0.006800047221953915.\n",
      "Training on epoch 6 minibatch 2701/5000 completed\n",
      " bpr_loss on current minibatch is 0.693882, and regularization loss is 0.000734.\n",
      " Top K precision = 0.01, recall = 0.004748353044921673.\n",
      "Training on epoch 6 minibatch 2801/5000 completed\n",
      " bpr_loss on current minibatch is 0.693799, and regularization loss is 0.000652.\n",
      " Top K precision = 0.018965517241379314, recall = 0.007944572072477347.\n",
      "Training on epoch 6 minibatch 2901/5000 completed\n",
      " bpr_loss on current minibatch is 0.693876, and regularization loss is 0.000728.\n",
      " Top K precision = 0.011666666666666665, recall = 0.0045172882672882666.\n",
      "Training on epoch 6 minibatch 3001/5000 completed\n",
      " bpr_loss on current minibatch is 0.693925, and regularization loss is 0.000778.\n",
      " Top K precision = 0.008333333333333333, recall = 0.005420066045066046.\n",
      "Training on epoch 6 minibatch 3101/5000 completed\n",
      " bpr_loss on current minibatch is 0.693721, and regularization loss is 0.000574.\n",
      " Top K precision = 0.013333333333333332, recall = 0.005634269320193003.\n",
      "Training on epoch 6 minibatch 3201/5000 completed\n",
      " bpr_loss on current minibatch is 0.693812, and regularization loss is 0.000665.\n",
      " Top K precision = 0.011666666666666665, recall = 0.005600141808475142.\n",
      "Training on epoch 6 minibatch 3301/5000 completed\n",
      " bpr_loss on current minibatch is 0.693747, and regularization loss is 0.0006.\n",
      " Top K precision = 0.013333333333333332, recall = 0.004516574474907808.\n",
      "Training on epoch 6 minibatch 3401/5000 completed\n",
      " bpr_loss on current minibatch is 0.693805, and regularization loss is 0.000658.\n",
      " Top K precision = 0.008771929824561403, recall = 0.00446345331928856.\n",
      "Training on epoch 6 minibatch 3501/5000 completed\n",
      " bpr_loss on current minibatch is 0.693814, and regularization loss is 0.000667.\n",
      " Top K precision = 0.00847457627118644, recall = 0.0030413163513861416.\n",
      "Training on epoch 6 minibatch 3601/5000 completed\n",
      " bpr_loss on current minibatch is 0.693902, and regularization loss is 0.000755.\n",
      " Top K precision = 0.016666666666666666, recall = 0.007695473599489955.\n",
      "Training on epoch 6 minibatch 3701/5000 completed\n",
      " bpr_loss on current minibatch is 0.693846, and regularization loss is 0.000699.\n",
      " Top K precision = 0.015254237288135594, recall = 0.0056248881560446865.\n",
      "Training on epoch 6 minibatch 3801/5000 completed\n",
      " bpr_loss on current minibatch is 0.693732, and regularization loss is 0.000585.\n",
      " Top K precision = 0.005000000000000001, recall = 0.001790824915824916.\n",
      "Training on epoch 6 minibatch 3901/5000 completed\n",
      " bpr_loss on current minibatch is 0.693982, and regularization loss is 0.000835.\n",
      " Top K precision = 0.005084745762711865, recall = 0.002870688633400498.\n",
      "Training on epoch 6 minibatch 4001/5000 completed\n",
      " bpr_loss on current minibatch is 0.693846, and regularization loss is 0.000698.\n",
      " Top K precision = 0.020689655172413796, recall = 0.011843873200694788.\n",
      "Training on epoch 6 minibatch 4101/5000 completed\n",
      " bpr_loss on current minibatch is 0.693747, and regularization loss is 0.000599.\n",
      " Top K precision = 0.015000000000000001, recall = 0.005793818419199807.\n",
      "Training on epoch 6 minibatch 4201/5000 completed\n",
      " bpr_loss on current minibatch is 0.693793, and regularization loss is 0.000646.\n",
      " Top K precision = 0.011666666666666665, recall = 0.004957146670701657.\n",
      "Training on epoch 6 minibatch 4301/5000 completed\n",
      " bpr_loss on current minibatch is 0.693754, and regularization loss is 0.000607.\n",
      " Top K precision = 0.013333333333333332, recall = 0.004906933615699177.\n",
      "Training on epoch 6 minibatch 4401/5000 completed\n",
      " bpr_loss on current minibatch is 0.693798, and regularization loss is 0.000651.\n",
      " Top K precision = 0.01, recall = 0.005621235809334306.\n",
      "Training on epoch 6 minibatch 4501/5000 completed\n",
      " bpr_loss on current minibatch is 0.693933, and regularization loss is 0.000786.\n",
      " Top K precision = 0.02, recall = 0.008368321976776817.\n",
      "Training on epoch 6 minibatch 4601/5000 completed\n",
      " bpr_loss on current minibatch is 0.693782, and regularization loss is 0.000635.\n",
      " Top K precision = 0.016666666666666666, recall = 0.0078077721288928184.\n",
      "Training on epoch 6 minibatch 4701/5000 completed\n",
      " bpr_loss on current minibatch is 0.693846, and regularization loss is 0.000698.\n",
      " Top K precision = 0.013559322033898305, recall = 0.006757590103205431.\n",
      "Training on epoch 6 minibatch 4801/5000 completed\n",
      " bpr_loss on current minibatch is 0.69372, and regularization loss is 0.000573.\n",
      " Top K precision = 0.006666666666666667, recall = 0.0027688172043010754.\n",
      "Training on epoch 6 minibatch 4901/5000 completed\n",
      " bpr_loss on current minibatch is 0.693648, and regularization loss is 0.000501.\n",
      " Top K precision = 0.011666666666666667, recall = 0.005006536338058077.\n",
      "\n",
      "Training on 6 epoch completed.\n",
      " Average bpr_loss on train set is 0.011563 for the current epoch.\n",
      " Training top K precision = 0.014066666666666765, recall = 0.005921148914636921.\n",
      " Average bpr_loss on the validation set is 2e-06, and regularization loss is 0.0.\n",
      " Validation top K precision = 0.014233333333333431, recall = 0.006388114248832996.\n",
      "\n",
      "Training on the 7 epoch\n",
      "Training on epoch 7 minibatch 1/5000 completed\n",
      " bpr_loss on current minibatch is 0.693906, and regularization loss is 0.000759.\n",
      " Top K precision = 0.010169491525423728, recall = 0.005776658042686045.\n",
      "Training on epoch 7 minibatch 101/5000 completed\n",
      " bpr_loss on current minibatch is 0.693788, and regularization loss is 0.000641.\n",
      " Top K precision = 0.014999999999999998, recall = 0.006384765797809276.\n",
      "Training on epoch 7 minibatch 201/5000 completed\n",
      " bpr_loss on current minibatch is 0.693727, and regularization loss is 0.00058.\n",
      " Top K precision = 0.006666666666666667, recall = 0.002800074510600826.\n",
      "Training on epoch 7 minibatch 301/5000 completed\n",
      " bpr_loss on current minibatch is 0.693668, and regularization loss is 0.000521.\n",
      " Top K precision = 0.010000000000000002, recall = 0.0036989038133202895.\n",
      "Training on epoch 7 minibatch 401/5000 completed\n",
      " bpr_loss on current minibatch is 0.693952, and regularization loss is 0.000805.\n",
      " Top K precision = 0.014999999999999998, recall = 0.009664824196557944.\n",
      "Training on epoch 7 minibatch 501/5000 completed\n",
      " bpr_loss on current minibatch is 0.693754, and regularization loss is 0.000606.\n",
      " Top K precision = 0.011666666666666665, recall = 0.006961009597637504.\n",
      "Training on epoch 7 minibatch 601/5000 completed\n",
      " bpr_loss on current minibatch is 0.693677, and regularization loss is 0.000529.\n",
      " Top K precision = 0.01379310344827586, recall = 0.00472977801346285.\n",
      "Training on epoch 7 minibatch 701/5000 completed\n",
      " bpr_loss on current minibatch is 0.693827, and regularization loss is 0.00068.\n",
      " Top K precision = 0.011864406779661016, recall = 0.0036161406758311696.\n",
      "Training on epoch 7 minibatch 801/5000 completed\n",
      " bpr_loss on current minibatch is 0.69371, and regularization loss is 0.000563.\n",
      " Top K precision = 0.013559322033898305, recall = 0.004599194384944189.\n",
      "Training on epoch 7 minibatch 901/5000 completed\n",
      " bpr_loss on current minibatch is 0.693823, and regularization loss is 0.000676.\n",
      " Top K precision = 0.01833333333333333, recall = 0.009288709768862357.\n",
      "Training on epoch 7 minibatch 1001/5000 completed\n",
      " bpr_loss on current minibatch is 0.693832, and regularization loss is 0.000685.\n",
      " Top K precision = 0.011864406779661016, recall = 0.007345538171809359.\n",
      "Training on epoch 7 minibatch 1101/5000 completed\n",
      " bpr_loss on current minibatch is 0.693862, and regularization loss is 0.000715.\n",
      " Top K precision = 0.011666666666666665, recall = 0.006204351204351204.\n",
      "Training on epoch 7 minibatch 1201/5000 completed\n",
      " bpr_loss on current minibatch is 0.693951, and regularization loss is 0.000804.\n",
      " Top K precision = 0.021666666666666667, recall = 0.008109334472877086.\n",
      "Training on epoch 7 minibatch 1301/5000 completed\n",
      " bpr_loss on current minibatch is 0.693806, and regularization loss is 0.000658.\n",
      " Top K precision = 0.016666666666666666, recall = 0.006770884650917394.\n",
      "Training on epoch 7 minibatch 1401/5000 completed\n",
      " bpr_loss on current minibatch is 0.693693, and regularization loss is 0.000546.\n",
      " Top K precision = 0.00847457627118644, recall = 0.005039670739938358.\n",
      "Training on epoch 7 minibatch 1501/5000 completed\n",
      " bpr_loss on current minibatch is 0.693867, and regularization loss is 0.00072.\n",
      " Top K precision = 0.006779661016949153, recall = 0.004470313114380911.\n",
      "Training on epoch 7 minibatch 1601/5000 completed\n",
      " bpr_loss on current minibatch is 0.693852, and regularization loss is 0.000705.\n",
      " Top K precision = 0.011864406779661016, recall = 0.005150322841000807.\n",
      "Training on epoch 7 minibatch 1701/5000 completed\n",
      " bpr_loss on current minibatch is 0.693766, and regularization loss is 0.000619.\n",
      " Top K precision = 0.006779661016949153, recall = 0.0021199258698891632.\n",
      "Training on epoch 7 minibatch 1801/5000 completed\n",
      " bpr_loss on current minibatch is 0.69398, and regularization loss is 0.000833.\n",
      " Top K precision = 0.013333333333333332, recall = 0.005906618365821402.\n",
      "Training on epoch 7 minibatch 1901/5000 completed\n",
      " bpr_loss on current minibatch is 0.693702, and regularization loss is 0.000555.\n",
      " Top K precision = 0.005084745762711865, recall = 0.0031297641467132992.\n",
      "Training on epoch 7 minibatch 2001/5000 completed\n",
      " bpr_loss on current minibatch is 0.693668, and regularization loss is 0.000521.\n",
      " Top K precision = 0.011666666666666665, recall = 0.008068112107967181.\n",
      "Training on epoch 7 minibatch 2101/5000 completed\n",
      " bpr_loss on current minibatch is 0.693954, and regularization loss is 0.000807.\n",
      " Top K precision = 0.013333333333333332, recall = 0.004973930180586528.\n",
      "Training on epoch 7 minibatch 2201/5000 completed\n",
      " bpr_loss on current minibatch is 0.693818, and regularization loss is 0.000671.\n",
      " Top K precision = 0.013333333333333332, recall = 0.007124608911937288.\n",
      "Training on epoch 7 minibatch 2301/5000 completed\n",
      " bpr_loss on current minibatch is 0.693811, and regularization loss is 0.000664.\n",
      " Top K precision = 0.013559322033898305, recall = 0.007245305962175948.\n",
      "Training on epoch 7 minibatch 2401/5000 completed\n",
      " bpr_loss on current minibatch is 0.693716, and regularization loss is 0.000569.\n",
      " Top K precision = 0.008333333333333333, recall = 0.0037204048968754845.\n",
      "Training on epoch 7 minibatch 2501/5000 completed\n",
      " bpr_loss on current minibatch is 0.693773, and regularization loss is 0.000626.\n",
      " Top K precision = 0.01016949152542373, recall = 0.0028539874849755806.\n",
      "Training on epoch 7 minibatch 2601/5000 completed\n",
      " bpr_loss on current minibatch is 0.693711, and regularization loss is 0.000564.\n",
      " Top K precision = 0.011864406779661016, recall = 0.004597848453780657.\n",
      "Training on epoch 7 minibatch 2701/5000 completed\n",
      " bpr_loss on current minibatch is 0.693763, and regularization loss is 0.000615.\n",
      " Top K precision = 0.005000000000000001, recall = 0.0018820450885668276.\n",
      "Training on epoch 7 minibatch 2801/5000 completed\n",
      " bpr_loss on current minibatch is 0.693734, and regularization loss is 0.000586.\n",
      " Top K precision = 0.0033898305084745766, recall = 0.0020177562550443904.\n",
      "Training on epoch 7 minibatch 2901/5000 completed\n",
      " bpr_loss on current minibatch is 0.69395, and regularization loss is 0.000803.\n",
      " Top K precision = 0.01, recall = 0.0056788597043469615.\n",
      "Training on epoch 7 minibatch 3001/5000 completed\n",
      " bpr_loss on current minibatch is 0.693703, and regularization loss is 0.000556.\n",
      " Top K precision = 0.011864406779661016, recall = 0.005072202622715896.\n",
      "Training on epoch 7 minibatch 3101/5000 completed\n",
      " bpr_loss on current minibatch is 0.693821, and regularization loss is 0.000674.\n",
      " Top K precision = 0.011666666666666665, recall = 0.008077481887550537.\n",
      "Training on epoch 7 minibatch 3201/5000 completed\n",
      " bpr_loss on current minibatch is 0.69367, and regularization loss is 0.000523.\n",
      " Top K precision = 0.010169491525423728, recall = 0.005390693397325674.\n",
      "Training on epoch 7 minibatch 3301/5000 completed\n",
      " bpr_loss on current minibatch is 0.693689, and regularization loss is 0.000542.\n",
      " Top K precision = 0.014999999999999998, recall = 0.00633038562314878.\n",
      "Training on epoch 7 minibatch 3401/5000 completed\n",
      " bpr_loss on current minibatch is 0.693925, and regularization loss is 0.000777.\n",
      " Top K precision = 0.01, recall = 0.0027333970042303373.\n",
      "Training on epoch 7 minibatch 3501/5000 completed\n",
      " bpr_loss on current minibatch is 0.693719, and regularization loss is 0.000572.\n",
      " Top K precision = 0.011864406779661016, recall = 0.004386326305912374.\n",
      "Training on epoch 7 minibatch 3601/5000 completed\n",
      " bpr_loss on current minibatch is 0.693894, and regularization loss is 0.000747.\n",
      " Top K precision = 0.011864406779661016, recall = 0.0047144718424243694.\n",
      "Training on epoch 7 minibatch 3701/5000 completed\n",
      " bpr_loss on current minibatch is 0.693827, and regularization loss is 0.000679.\n",
      " Top K precision = 0.005000000000000001, recall = 0.0014564178484234584.\n",
      "Training on epoch 7 minibatch 3801/5000 completed\n",
      " bpr_loss on current minibatch is 0.693943, and regularization loss is 0.000796.\n",
      " Top K precision = 0.01, recall = 0.004588271693534851.\n",
      "Training on epoch 7 minibatch 3901/5000 completed\n",
      " bpr_loss on current minibatch is 0.693749, and regularization loss is 0.000602.\n",
      " Top K precision = 0.013559322033898305, recall = 0.009610912924088406.\n",
      "Training on epoch 7 minibatch 4001/5000 completed\n",
      " bpr_loss on current minibatch is 0.693862, and regularization loss is 0.000714.\n",
      " Top K precision = 0.013333333333333332, recall = 0.003221638534138534.\n",
      "Training on epoch 7 minibatch 4101/5000 completed\n",
      " bpr_loss on current minibatch is 0.693756, and regularization loss is 0.000608.\n",
      " Top K precision = 0.006779661016949153, recall = 0.0024376275316817532.\n",
      "Training on epoch 7 minibatch 4201/5000 completed\n",
      " bpr_loss on current minibatch is 0.693721, and regularization loss is 0.000574.\n",
      " Top K precision = 0.01379310344827586, recall = 0.005531247011720644.\n",
      "Training on epoch 7 minibatch 4301/5000 completed\n",
      " bpr_loss on current minibatch is 0.693915, and regularization loss is 0.000768.\n",
      " Top K precision = 0.01833333333333333, recall = 0.008539933518971187.\n",
      "Training on epoch 7 minibatch 4401/5000 completed\n",
      " bpr_loss on current minibatch is 0.693743, and regularization loss is 0.000596.\n",
      " Top K precision = 0.00847457627118644, recall = 0.005276537479927311.\n",
      "Training on epoch 7 minibatch 4501/5000 completed\n",
      " bpr_loss on current minibatch is 0.693689, and regularization loss is 0.000542.\n",
      " Top K precision = 0.011666666666666665, recall = 0.0042282030834662416.\n",
      "Training on epoch 7 minibatch 4601/5000 completed\n",
      " bpr_loss on current minibatch is 0.693754, and regularization loss is 0.000607.\n",
      " Top K precision = 0.016949152542372878, recall = 0.006860122718056323.\n",
      "Training on epoch 7 minibatch 4701/5000 completed\n",
      " bpr_loss on current minibatch is 0.693907, and regularization loss is 0.00076.\n",
      " Top K precision = 0.03000000000000001, recall = 0.011538916178622061.\n",
      "Training on epoch 7 minibatch 4801/5000 completed\n",
      " bpr_loss on current minibatch is 0.693952, and regularization loss is 0.000805.\n",
      " Top K precision = 0.011666666666666665, recall = 0.005597222222222223.\n",
      "Training on epoch 7 minibatch 4901/5000 completed\n",
      " bpr_loss on current minibatch is 0.69383, and regularization loss is 0.000683.\n",
      " Top K precision = 0.0033333333333333335, recall = 0.001984126984126984.\n",
      "\n",
      "Training on 7 epoch completed.\n",
      " Average bpr_loss on train set is 0.011563 for the current epoch.\n",
      " Training top K precision = 0.013533333333333416, recall = 0.005789954424547948.\n",
      " Average bpr_loss on the validation set is 2e-06, and regularization loss is 0.0.\n",
      " Validation top K precision = 0.015133333333333445, recall = 0.006304760526180744.\n",
      "\n",
      "Training on the 8 epoch\n",
      "Training on epoch 8 minibatch 1/5000 completed\n",
      " bpr_loss on current minibatch is 0.693836, and regularization loss is 0.000689.\n",
      " Top K precision = 0.01379310344827586, recall = 0.006129193660900191.\n",
      "Training on epoch 8 minibatch 101/5000 completed\n",
      " bpr_loss on current minibatch is 0.693817, and regularization loss is 0.00067.\n",
      " Top K precision = 0.016666666666666666, recall = 0.006741578116505928.\n",
      "Training on epoch 8 minibatch 201/5000 completed\n",
      " bpr_loss on current minibatch is 0.693844, and regularization loss is 0.000697.\n",
      " Top K precision = 0.006666666666666667, recall = 0.00364225235548765.\n",
      "Training on epoch 8 minibatch 301/5000 completed\n",
      " bpr_loss on current minibatch is 0.693745, and regularization loss is 0.000598.\n",
      " Top K precision = 0.005084745762711865, recall = 0.0016398952693517275.\n",
      "Training on epoch 8 minibatch 401/5000 completed\n",
      " bpr_loss on current minibatch is 0.693826, and regularization loss is 0.000679.\n",
      " Top K precision = 0.022033898305084745, recall = 0.00971537259157625.\n",
      "Training on epoch 8 minibatch 501/5000 completed\n",
      " bpr_loss on current minibatch is 0.693811, and regularization loss is 0.000663.\n",
      " Top K precision = 0.011666666666666665, recall = 0.0037478639781271363.\n",
      "Training on epoch 8 minibatch 601/5000 completed\n",
      " bpr_loss on current minibatch is 0.693671, and regularization loss is 0.000524.\n",
      " Top K precision = 0.010169491525423728, recall = 0.0034709208831895945.\n",
      "Training on epoch 8 minibatch 701/5000 completed\n",
      " bpr_loss on current minibatch is 0.693913, and regularization loss is 0.000766.\n",
      " Top K precision = 0.02, recall = 0.010357181338021845.\n",
      "Training on epoch 8 minibatch 801/5000 completed\n",
      " bpr_loss on current minibatch is 0.693957, and regularization loss is 0.00081.\n",
      " Top K precision = 0.011666666666666665, recall = 0.004460683399279891.\n",
      "Training on epoch 8 minibatch 901/5000 completed\n",
      " bpr_loss on current minibatch is 0.69375, and regularization loss is 0.000603.\n",
      " Top K precision = 0.0071428571428571435, recall = 0.0037019858448429878.\n",
      "Training on epoch 8 minibatch 1001/5000 completed\n",
      " bpr_loss on current minibatch is 0.693638, and regularization loss is 0.000491.\n",
      " Top K precision = 0.013559322033898305, recall = 0.0061993605366379755.\n",
      "Training on epoch 8 minibatch 1101/5000 completed\n",
      " bpr_loss on current minibatch is 0.693713, and regularization loss is 0.000566.\n",
      " Top K precision = 0.016666666666666666, recall = 0.006546032215599278.\n",
      "Training on epoch 8 minibatch 1201/5000 completed\n",
      " bpr_loss on current minibatch is 0.693836, and regularization loss is 0.000689.\n",
      " Top K precision = 0.013333333333333332, recall = 0.0062241761506467395.\n",
      "Training on epoch 8 minibatch 1301/5000 completed\n",
      " bpr_loss on current minibatch is 0.693812, and regularization loss is 0.000665.\n",
      " Top K precision = 0.010169491525423728, recall = 0.005395562794019596.\n",
      "Training on epoch 8 minibatch 1401/5000 completed\n",
      " bpr_loss on current minibatch is 0.693779, and regularization loss is 0.000632.\n",
      " Top K precision = 0.011666666666666665, recall = 0.00399313234065556.\n",
      "Training on epoch 8 minibatch 1501/5000 completed\n",
      " bpr_loss on current minibatch is 0.693833, and regularization loss is 0.000686.\n",
      " Top K precision = 0.014999999999999998, recall = 0.004887366133333875.\n",
      "Training on epoch 8 minibatch 1601/5000 completed\n",
      " bpr_loss on current minibatch is 0.693825, and regularization loss is 0.000677.\n",
      " Top K precision = 0.011864406779661016, recall = 0.004351552315030302.\n",
      "Training on epoch 8 minibatch 1701/5000 completed\n",
      " bpr_loss on current minibatch is 0.693872, and regularization loss is 0.000725.\n",
      " Top K precision = 0.014999999999999998, recall = 0.0061562616127833515.\n",
      "Training on epoch 8 minibatch 1801/5000 completed\n",
      " bpr_loss on current minibatch is 0.693809, and regularization loss is 0.000662.\n",
      " Top K precision = 0.02, recall = 0.0064855699512024086.\n",
      "Training on epoch 8 minibatch 1901/5000 completed\n",
      " bpr_loss on current minibatch is 0.693852, and regularization loss is 0.000705.\n",
      " Top K precision = 0.005000000000000001, recall = 0.004282407407407407.\n",
      "Training on epoch 8 minibatch 2001/5000 completed\n",
      " bpr_loss on current minibatch is 0.693808, and regularization loss is 0.000661.\n",
      " Top K precision = 0.008333333333333333, recall = 0.002949913931922927.\n",
      "Training on epoch 8 minibatch 2101/5000 completed\n",
      " bpr_loss on current minibatch is 0.693919, and regularization loss is 0.000772.\n",
      " Top K precision = 0.01, recall = 0.004498847587082881.\n",
      "Training on epoch 8 minibatch 2201/5000 completed\n",
      " bpr_loss on current minibatch is 0.693668, and regularization loss is 0.00052.\n",
      " Top K precision = 0.02033898305084746, recall = 0.00932160193750423.\n",
      "Training on epoch 8 minibatch 2301/5000 completed\n",
      " bpr_loss on current minibatch is 0.693977, and regularization loss is 0.000829.\n",
      " Top K precision = 0.006779661016949153, recall = 0.002868882529899479.\n",
      "Training on epoch 8 minibatch 2401/5000 completed\n",
      " bpr_loss on current minibatch is 0.693835, and regularization loss is 0.000688.\n",
      " Top K precision = 0.011666666666666665, recall = 0.005206179217807125.\n",
      "Training on epoch 8 minibatch 2501/5000 completed\n",
      " bpr_loss on current minibatch is 0.693889, and regularization loss is 0.000742.\n",
      " Top K precision = 0.014999999999999998, recall = 0.0066048061024600755.\n",
      "Training on epoch 8 minibatch 2601/5000 completed\n",
      " bpr_loss on current minibatch is 0.694141, and regularization loss is 0.000994.\n",
      " Top K precision = 0.013333333333333334, recall = 0.005768589101922435.\n",
      "Training on epoch 8 minibatch 2701/5000 completed\n",
      " bpr_loss on current minibatch is 0.693885, and regularization loss is 0.000738.\n",
      " Top K precision = 0.005172413793103449, recall = 0.0023471310903252825.\n",
      "Training on epoch 8 minibatch 2801/5000 completed\n",
      " bpr_loss on current minibatch is 0.693857, and regularization loss is 0.00071.\n",
      " Top K precision = 0.010344827586206896, recall = 0.004249516363853931.\n",
      "Training on epoch 8 minibatch 2901/5000 completed\n",
      " bpr_loss on current minibatch is 0.693712, and regularization loss is 0.000565.\n",
      " Top K precision = 0.008333333333333333, recall = 0.0028755735005735.\n",
      "Training on epoch 8 minibatch 3001/5000 completed\n",
      " bpr_loss on current minibatch is 0.693712, and regularization loss is 0.000565.\n",
      " Top K precision = 0.011864406779661016, recall = 0.0036189003773749538.\n",
      "Training on epoch 8 minibatch 3101/5000 completed\n",
      " bpr_loss on current minibatch is 0.693853, and regularization loss is 0.000706.\n",
      " Top K precision = 0.013333333333333332, recall = 0.006316290826094747.\n",
      "Training on epoch 8 minibatch 3201/5000 completed\n",
      " bpr_loss on current minibatch is 0.693799, and regularization loss is 0.000652.\n",
      " Top K precision = 0.011666666666666665, recall = 0.005354914693149988.\n",
      "Training on epoch 8 minibatch 3301/5000 completed\n",
      " bpr_loss on current minibatch is 0.693793, and regularization loss is 0.000646.\n",
      " Top K precision = 0.013333333333333332, recall = 0.00401853026396637.\n",
      "Training on epoch 8 minibatch 3401/5000 completed\n",
      " bpr_loss on current minibatch is 0.693812, and regularization loss is 0.000664.\n",
      " Top K precision = 0.006779661016949153, recall = 0.003886198547215496.\n",
      "Training on epoch 8 minibatch 3501/5000 completed\n",
      " bpr_loss on current minibatch is 0.693616, and regularization loss is 0.000469.\n",
      " Top K precision = 0.013333333333333332, recall = 0.006597814988356559.\n",
      "Training on epoch 8 minibatch 3601/5000 completed\n",
      " bpr_loss on current minibatch is 0.69381, and regularization loss is 0.000662.\n",
      " Top K precision = 0.015000000000000001, recall = 0.004666057706804736.\n",
      "Training on epoch 8 minibatch 3701/5000 completed\n",
      " bpr_loss on current minibatch is 0.693763, and regularization loss is 0.000616.\n",
      " Top K precision = 0.008620689655172414, recall = 0.0028082700723354084.\n",
      "Training on epoch 8 minibatch 3801/5000 completed\n",
      " bpr_loss on current minibatch is 0.693833, and regularization loss is 0.000686.\n",
      " Top K precision = 0.010169491525423728, recall = 0.004848435462842242.\n",
      "Training on epoch 8 minibatch 3901/5000 completed\n",
      " bpr_loss on current minibatch is 0.693799, and regularization loss is 0.000652.\n",
      " Top K precision = 0.013333333333333332, recall = 0.006473194203457362.\n",
      "Training on epoch 8 minibatch 4001/5000 completed\n",
      " bpr_loss on current minibatch is 0.693903, and regularization loss is 0.000756.\n",
      " Top K precision = 0.013333333333333332, recall = 0.004573789142287594.\n",
      "Training on epoch 8 minibatch 4101/5000 completed\n",
      " bpr_loss on current minibatch is 0.693801, and regularization loss is 0.000654.\n",
      " Top K precision = 0.01206896551724138, recall = 0.006120814807293936.\n",
      "Training on epoch 8 minibatch 4201/5000 completed\n",
      " bpr_loss on current minibatch is 0.693862, and regularization loss is 0.000715.\n",
      " Top K precision = 0.014999999999999998, recall = 0.009521637948108536.\n",
      "Training on epoch 8 minibatch 4301/5000 completed\n",
      " bpr_loss on current minibatch is 0.693828, and regularization loss is 0.000681.\n",
      " Top K precision = 0.01, recall = 0.004380182561103614.\n",
      "Training on epoch 8 minibatch 4401/5000 completed\n",
      " bpr_loss on current minibatch is 0.693851, and regularization loss is 0.000704.\n",
      " Top K precision = 0.013333333333333332, recall = 0.004624853070345397.\n",
      "Training on epoch 8 minibatch 4501/5000 completed\n",
      " bpr_loss on current minibatch is 0.693772, and regularization loss is 0.000625.\n",
      " Top K precision = 0.013559322033898305, recall = 0.006602285772275803.\n",
      "Training on epoch 8 minibatch 4601/5000 completed\n",
      " bpr_loss on current minibatch is 0.693784, and regularization loss is 0.000636.\n",
      " Top K precision = 0.014999999999999998, recall = 0.006803150553150553.\n",
      "Training on epoch 8 minibatch 4701/5000 completed\n",
      " bpr_loss on current minibatch is 0.693811, and regularization loss is 0.000664.\n",
      " Top K precision = 0.005172413793103449, recall = 0.003033877797943134.\n",
      "Training on epoch 8 minibatch 4801/5000 completed\n",
      " bpr_loss on current minibatch is 0.693734, and regularization loss is 0.000587.\n",
      " Top K precision = 0.011864406779661016, recall = 0.0042736250709246165.\n",
      "Training on epoch 8 minibatch 4901/5000 completed\n",
      " bpr_loss on current minibatch is 0.69374, and regularization loss is 0.000593.\n",
      " Top K precision = 0.008333333333333333, recall = 0.007471108326371484.\n",
      "\n",
      "Training on 8 epoch completed.\n",
      " Average bpr_loss on train set is 0.011563 for the current epoch.\n",
      " Training top K precision = 0.01333333333333342, recall = 0.005600620588455112.\n",
      " Average bpr_loss on the validation set is 2e-06, and regularization loss is 0.0.\n",
      " Validation top K precision = 0.01366666666666676, recall = 0.005969743031513755.\n",
      "\n",
      "Training on the 9 epoch\n",
      "Training on epoch 9 minibatch 1/5000 completed\n",
      " bpr_loss on current minibatch is 0.69384, and regularization loss is 0.000692.\n",
      " Top K precision = 0.0033333333333333335, recall = 0.001953748006379585.\n",
      "Training on epoch 9 minibatch 101/5000 completed\n",
      " bpr_loss on current minibatch is 0.693811, and regularization loss is 0.000664.\n",
      " Top K precision = 0.01833333333333333, recall = 0.006908984127133771.\n",
      "Training on epoch 9 minibatch 201/5000 completed\n",
      " bpr_loss on current minibatch is 0.693938, and regularization loss is 0.000791.\n",
      " Top K precision = 0.020338983050847456, recall = 0.01019083709761676.\n",
      "Training on epoch 9 minibatch 301/5000 completed\n",
      " bpr_loss on current minibatch is 0.693904, and regularization loss is 0.000757.\n",
      " Top K precision = 0.02, recall = 0.007438932814958462.\n",
      "Training on epoch 9 minibatch 401/5000 completed\n",
      " bpr_loss on current minibatch is 0.693878, and regularization loss is 0.000731.\n",
      " Top K precision = 0.02, recall = 0.007989027307475825.\n",
      "Training on epoch 9 minibatch 501/5000 completed\n",
      " bpr_loss on current minibatch is 0.693776, and regularization loss is 0.000629.\n",
      " Top K precision = 0.01833333333333333, recall = 0.007090782309299959.\n",
      "Training on epoch 9 minibatch 601/5000 completed\n",
      " bpr_loss on current minibatch is 0.693801, and regularization loss is 0.000653.\n",
      " Top K precision = 0.013559322033898305, recall = 0.007309276671841152.\n",
      "Training on epoch 9 minibatch 701/5000 completed\n",
      " bpr_loss on current minibatch is 0.693739, and regularization loss is 0.000592.\n",
      " Top K precision = 0.011666666666666665, recall = 0.007728797260531006.\n",
      "Training on epoch 9 minibatch 801/5000 completed\n",
      " bpr_loss on current minibatch is 0.693663, and regularization loss is 0.000516.\n",
      " Top K precision = 0.006896551724137932, recall = 0.0038026819923371643.\n",
      "Training on epoch 9 minibatch 901/5000 completed\n",
      " bpr_loss on current minibatch is 0.693809, and regularization loss is 0.000662.\n",
      " Top K precision = 0.016666666666666666, recall = 0.007183853166110199.\n",
      "Training on epoch 9 minibatch 1001/5000 completed\n",
      " bpr_loss on current minibatch is 0.693816, and regularization loss is 0.000669.\n",
      " Top K precision = 0.006779661016949153, recall = 0.0024881183517117818.\n",
      "Training on epoch 9 minibatch 1101/5000 completed\n",
      " bpr_loss on current minibatch is 0.693667, and regularization loss is 0.00052.\n",
      " Top K precision = 0.010169491525423728, recall = 0.004106603904722189.\n",
      "Training on epoch 9 minibatch 1201/5000 completed\n",
      " bpr_loss on current minibatch is 0.693646, and regularization loss is 0.000499.\n",
      " Top K precision = 0.006779661016949153, recall = 0.002065567019093536.\n",
      "Training on epoch 9 minibatch 1301/5000 completed\n",
      " bpr_loss on current minibatch is 0.693774, and regularization loss is 0.000627.\n",
      " Top K precision = 0.011666666666666665, recall = 0.005151586432236078.\n",
      "Training on epoch 9 minibatch 1401/5000 completed\n",
      " bpr_loss on current minibatch is 0.693643, and regularization loss is 0.000496.\n",
      " Top K precision = 0.005084745762711865, recall = 0.0031497175141242937.\n",
      "Training on epoch 9 minibatch 1501/5000 completed\n",
      " bpr_loss on current minibatch is 0.693871, and regularization loss is 0.000724.\n",
      " Top K precision = 0.006666666666666667, recall = 0.0036621376811594203.\n",
      "Training on epoch 9 minibatch 1601/5000 completed\n",
      " bpr_loss on current minibatch is 0.693745, and regularization loss is 0.000598.\n",
      " Top K precision = 0.015254237288135592, recall = 0.006259623006881232.\n",
      "Training on epoch 9 minibatch 1701/5000 completed\n",
      " bpr_loss on current minibatch is 0.693862, and regularization loss is 0.000715.\n",
      " Top K precision = 0.00847457627118644, recall = 0.003871705416265285.\n",
      "Training on epoch 9 minibatch 1801/5000 completed\n",
      " bpr_loss on current minibatch is 0.693738, and regularization loss is 0.000591.\n",
      " Top K precision = 0.010344827586206896, recall = 0.003591448368324636.\n",
      "Training on epoch 9 minibatch 1901/5000 completed\n",
      " bpr_loss on current minibatch is 0.693815, and regularization loss is 0.000668.\n",
      " Top K precision = 0.011666666666666665, recall = 0.005414939592571171.\n",
      "Training on epoch 9 minibatch 2001/5000 completed\n",
      " bpr_loss on current minibatch is 0.693787, and regularization loss is 0.000639.\n",
      " Top K precision = 0.012280701754385965, recall = 0.005966829777323504.\n",
      "Training on epoch 9 minibatch 2101/5000 completed\n",
      " bpr_loss on current minibatch is 0.693812, and regularization loss is 0.000665.\n",
      " Top K precision = 0.011666666666666665, recall = 0.004981005709266579.\n",
      "Training on epoch 9 minibatch 2201/5000 completed\n",
      " bpr_loss on current minibatch is 0.693791, and regularization loss is 0.000644.\n",
      " Top K precision = 0.005084745762711865, recall = 0.0026065742167437084.\n",
      "Training on epoch 9 minibatch 2301/5000 completed\n",
      " bpr_loss on current minibatch is 0.693778, and regularization loss is 0.00063.\n",
      " Top K precision = 0.01, recall = 0.00479732190258506.\n",
      "Training on epoch 9 minibatch 2401/5000 completed\n",
      " bpr_loss on current minibatch is 0.693896, and regularization loss is 0.000748.\n",
      " Top K precision = 0.013559322033898305, recall = 0.007367880898863688.\n",
      "Training on epoch 9 minibatch 2501/5000 completed\n",
      " bpr_loss on current minibatch is 0.693796, and regularization loss is 0.000649.\n",
      " Top K precision = 0.0, recall = 0.0.\n",
      "Training on epoch 9 minibatch 2601/5000 completed\n",
      " bpr_loss on current minibatch is 0.693706, and regularization loss is 0.000559.\n",
      " Top K precision = 0.015254237288135594, recall = 0.00736148973437109.\n",
      "Training on epoch 9 minibatch 2701/5000 completed\n",
      " bpr_loss on current minibatch is 0.693821, and regularization loss is 0.000674.\n",
      " Top K precision = 0.008333333333333333, recall = 0.0048080237237484984.\n",
      "Training on epoch 9 minibatch 2801/5000 completed\n",
      " bpr_loss on current minibatch is 0.693889, and regularization loss is 0.000742.\n",
      " Top K precision = 0.016666666666666666, recall = 0.009138611707577226.\n",
      "Training on epoch 9 minibatch 2901/5000 completed\n",
      " bpr_loss on current minibatch is 0.693838, and regularization loss is 0.000691.\n",
      " Top K precision = 0.008620689655172414, recall = 0.00416664590092582.\n",
      "Training on epoch 9 minibatch 3001/5000 completed\n",
      " bpr_loss on current minibatch is 0.693771, and regularization loss is 0.000624.\n",
      " Top K precision = 0.01, recall = 0.003047721008383534.\n",
      "Training on epoch 9 minibatch 3101/5000 completed\n",
      " bpr_loss on current minibatch is 0.693777, and regularization loss is 0.00063.\n",
      " Top K precision = 0.016666666666666666, recall = 0.010665828872350614.\n",
      "Training on epoch 9 minibatch 3201/5000 completed\n",
      " bpr_loss on current minibatch is 0.693657, and regularization loss is 0.00051.\n",
      " Top K precision = 0.01833333333333333, recall = 0.012044362709217781.\n",
      "Training on epoch 9 minibatch 3301/5000 completed\n",
      " bpr_loss on current minibatch is 0.693685, and regularization loss is 0.000538.\n",
      " Top K precision = 0.008333333333333333, recall = 0.00458943833943834.\n",
      "Training on epoch 9 minibatch 3401/5000 completed\n",
      " bpr_loss on current minibatch is 0.693801, and regularization loss is 0.000654.\n",
      " Top K precision = 0.014999999999999998, recall = 0.008440617235374268.\n",
      "Training on epoch 9 minibatch 3501/5000 completed\n",
      " bpr_loss on current minibatch is 0.693788, and regularization loss is 0.000641.\n",
      " Top K precision = 0.014999999999999998, recall = 0.005921436152948685.\n",
      "Training on epoch 9 minibatch 3601/5000 completed\n",
      " bpr_loss on current minibatch is 0.69384, and regularization loss is 0.000693.\n",
      " Top K precision = 0.00847457627118644, recall = 0.0031864475490120297.\n",
      "Training on epoch 9 minibatch 3701/5000 completed\n",
      " bpr_loss on current minibatch is 0.693758, and regularization loss is 0.000611.\n",
      " Top K precision = 0.011666666666666665, recall = 0.0047379540394246284.\n",
      "Training on epoch 9 minibatch 3801/5000 completed\n",
      " bpr_loss on current minibatch is 0.693692, and regularization loss is 0.000545.\n",
      " Top K precision = 0.013333333333333332, recall = 0.005826100873539204.\n",
      "Training on epoch 9 minibatch 3901/5000 completed\n",
      " bpr_loss on current minibatch is 0.693687, and regularization loss is 0.000539.\n",
      " Top K precision = 0.013333333333333332, recall = 0.005477400750509994.\n",
      "Training on epoch 9 minibatch 4001/5000 completed\n",
      " bpr_loss on current minibatch is 0.693784, and regularization loss is 0.000637.\n",
      " Top K precision = 0.011666666666666665, recall = 0.005332297894684464.\n",
      "Training on epoch 9 minibatch 4101/5000 completed\n",
      " bpr_loss on current minibatch is 0.693819, and regularization loss is 0.000671.\n",
      " Top K precision = 0.01016949152542373, recall = 0.0035753339061157536.\n",
      "Training on epoch 9 minibatch 4201/5000 completed\n",
      " bpr_loss on current minibatch is 0.693709, and regularization loss is 0.000562.\n",
      " Top K precision = 0.020338983050847456, recall = 0.009685040650696313.\n",
      "Training on epoch 9 minibatch 4301/5000 completed\n",
      " bpr_loss on current minibatch is 0.693832, and regularization loss is 0.000685.\n",
      " Top K precision = 0.006779661016949153, recall = 0.002738651214276968.\n",
      "Training on epoch 9 minibatch 4401/5000 completed\n",
      " bpr_loss on current minibatch is 0.693759, and regularization loss is 0.000612.\n",
      " Top K precision = 0.00847457627118644, recall = 0.004541208463174489.\n",
      "Training on epoch 9 minibatch 4501/5000 completed\n",
      " bpr_loss on current minibatch is 0.693733, and regularization loss is 0.000585.\n",
      " Top K precision = 0.013559322033898305, recall = 0.008186094707052428.\n",
      "Training on epoch 9 minibatch 4601/5000 completed\n",
      " bpr_loss on current minibatch is 0.693809, and regularization loss is 0.000661.\n",
      " Top K precision = 0.00847457627118644, recall = 0.005328963649653753.\n",
      "Training on epoch 9 minibatch 4701/5000 completed\n",
      " bpr_loss on current minibatch is 0.693968, and regularization loss is 0.000821.\n",
      " Top K precision = 0.013333333333333332, recall = 0.004723839356531143.\n",
      "Training on epoch 9 minibatch 4801/5000 completed\n",
      " bpr_loss on current minibatch is 0.693638, and regularization loss is 0.000491.\n",
      " Top K precision = 0.016949152542372878, recall = 0.0072681122119278305.\n",
      "Training on epoch 9 minibatch 4901/5000 completed\n",
      " bpr_loss on current minibatch is 0.693713, and regularization loss is 0.000566.\n",
      " Top K precision = 0.010169491525423728, recall = 0.003921399978879713.\n",
      "\n",
      "Training on 9 epoch completed.\n",
      " Average bpr_loss on train set is 0.011563 for the current epoch.\n",
      " Training top K precision = 0.013800000000000092, recall = 0.006342030210607279.\n",
      " Average bpr_loss on the validation set is 2e-06, and regularization loss is 0.0.\n",
      " Validation top K precision = 0.014300000000000099, recall = 0.006249176031723059.\n",
      "\n",
      "Training on the 10 epoch\n",
      "Training on epoch 10 minibatch 1/5000 completed\n",
      " bpr_loss on current minibatch is 0.693743, and regularization loss is 0.000596.\n",
      " Top K precision = 0.006779661016949153, recall = 0.0038622228552437927.\n",
      "Training on epoch 10 minibatch 101/5000 completed\n",
      " bpr_loss on current minibatch is 0.693985, and regularization loss is 0.000838.\n",
      " Top K precision = 0.006666666666666667, recall = 0.002758169934640523.\n",
      "Training on epoch 10 minibatch 201/5000 completed\n",
      " bpr_loss on current minibatch is 0.693762, and regularization loss is 0.000615.\n",
      " Top K precision = 0.014999999999999998, recall = 0.0069517471907177796.\n",
      "Training on epoch 10 minibatch 301/5000 completed\n",
      " bpr_loss on current minibatch is 0.693805, and regularization loss is 0.000658.\n",
      " Top K precision = 0.013333333333333334, recall = 0.005910667827525188.\n",
      "Training on epoch 10 minibatch 401/5000 completed\n",
      " bpr_loss on current minibatch is 0.693805, and regularization loss is 0.000657.\n",
      " Top K precision = 0.016666666666666666, recall = 0.01015429979941803.\n",
      "Training on epoch 10 minibatch 501/5000 completed\n",
      " bpr_loss on current minibatch is 0.693803, and regularization loss is 0.000656.\n",
      " Top K precision = 0.018644067796610167, recall = 0.007462184569612287.\n",
      "Training on epoch 10 minibatch 601/5000 completed\n",
      " bpr_loss on current minibatch is 0.693734, and regularization loss is 0.000587.\n",
      " Top K precision = 0.013559322033898305, recall = 0.006256668254641726.\n",
      "Training on epoch 10 minibatch 701/5000 completed\n",
      " bpr_loss on current minibatch is 0.693918, and regularization loss is 0.000771.\n",
      " Top K precision = 0.015517241379310343, recall = 0.006709710498092675.\n",
      "Training on epoch 10 minibatch 801/5000 completed\n",
      " bpr_loss on current minibatch is 0.693781, and regularization loss is 0.000634.\n",
      " Top K precision = 0.022807017543859647, recall = 0.01131120355503657.\n",
      "Training on epoch 10 minibatch 901/5000 completed\n",
      " bpr_loss on current minibatch is 0.69389, and regularization loss is 0.000743.\n",
      " Top K precision = 0.01, recall = 0.0036040409417140164.\n",
      "Training on epoch 10 minibatch 1001/5000 completed\n",
      " bpr_loss on current minibatch is 0.693846, and regularization loss is 0.000699.\n",
      " Top K precision = 0.01206896551724138, recall = 0.004391764844351051.\n",
      "Training on epoch 10 minibatch 1101/5000 completed\n",
      " bpr_loss on current minibatch is 0.693947, and regularization loss is 0.0008.\n",
      " Top K precision = 0.008333333333333333, recall = 0.002861023098437286.\n",
      "Training on epoch 10 minibatch 1201/5000 completed\n",
      " bpr_loss on current minibatch is 0.693723, and regularization loss is 0.000576.\n",
      " Top K precision = 0.016949152542372878, recall = 0.005719870195194223.\n",
      "Training on epoch 10 minibatch 1301/5000 completed\n",
      " bpr_loss on current minibatch is 0.693615, and regularization loss is 0.000467.\n",
      " Top K precision = 0.013559322033898305, recall = 0.004906981005367739.\n",
      "Training on epoch 10 minibatch 1401/5000 completed\n",
      " bpr_loss on current minibatch is 0.693822, and regularization loss is 0.000675.\n",
      " Top K precision = 0.011864406779661016, recall = 0.006504581724573922.\n",
      "Training on epoch 10 minibatch 1501/5000 completed\n",
      " bpr_loss on current minibatch is 0.693825, and regularization loss is 0.000678.\n",
      " Top K precision = 0.011666666666666665, recall = 0.00552310719589785.\n",
      "Training on epoch 10 minibatch 1601/5000 completed\n",
      " bpr_loss on current minibatch is 0.693915, and regularization loss is 0.000768.\n",
      " Top K precision = 0.01, recall = 0.0028078297595841455.\n",
      "Training on epoch 10 minibatch 1701/5000 completed\n",
      " bpr_loss on current minibatch is 0.69385, and regularization loss is 0.000703.\n",
      " Top K precision = 0.014285714285714285, recall = 0.005850259440160504.\n",
      "Training on epoch 10 minibatch 1801/5000 completed\n",
      " bpr_loss on current minibatch is 0.693899, and regularization loss is 0.000751.\n",
      " Top K precision = 0.008333333333333333, recall = 0.0036317734847146612.\n",
      "Training on epoch 10 minibatch 1901/5000 completed\n",
      " bpr_loss on current minibatch is 0.693943, and regularization loss is 0.000796.\n",
      " Top K precision = 0.015254237288135592, recall = 0.00581428174736958.\n",
      "Training on epoch 10 minibatch 2001/5000 completed\n",
      " bpr_loss on current minibatch is 0.693684, and regularization loss is 0.000537.\n",
      " Top K precision = 0.011666666666666665, recall = 0.00400991587277468.\n",
      "Training on epoch 10 minibatch 2101/5000 completed\n",
      " bpr_loss on current minibatch is 0.693773, and regularization loss is 0.000626.\n",
      " Top K precision = 0.016949152542372878, recall = 0.006117340081396188.\n",
      "Training on epoch 10 minibatch 2201/5000 completed\n",
      " bpr_loss on current minibatch is 0.693723, and regularization loss is 0.000576.\n",
      " Top K precision = 0.015517241379310343, recall = 0.009355888327799431.\n",
      "Training on epoch 10 minibatch 2301/5000 completed\n",
      " bpr_loss on current minibatch is 0.693712, and regularization loss is 0.000565.\n",
      " Top K precision = 0.006666666666666667, recall = 0.003130374957000344.\n",
      "Training on epoch 10 minibatch 2401/5000 completed\n",
      " bpr_loss on current minibatch is 0.693679, and regularization loss is 0.000532.\n",
      " Top K precision = 0.02, recall = 0.00851933161525477.\n",
      "Training on epoch 10 minibatch 2501/5000 completed\n",
      " bpr_loss on current minibatch is 0.693851, and regularization loss is 0.000704.\n",
      " Top K precision = 0.011864406779661016, recall = 0.005536560998978095.\n",
      "Training on epoch 10 minibatch 2601/5000 completed\n",
      " bpr_loss on current minibatch is 0.69377, and regularization loss is 0.000623.\n",
      " Top K precision = 0.015789473684210523, recall = 0.006367095716006787.\n",
      "Training on epoch 10 minibatch 2701/5000 completed\n",
      " bpr_loss on current minibatch is 0.693724, and regularization loss is 0.000577.\n",
      " Top K precision = 0.00847457627118644, recall = 0.0038326177881214283.\n",
      "Training on epoch 10 minibatch 2801/5000 completed\n",
      " bpr_loss on current minibatch is 0.693931, and regularization loss is 0.000784.\n",
      " Top K precision = 0.0033898305084745766, recall = 0.0014589929844167132.\n",
      "Training on epoch 10 minibatch 2901/5000 completed\n",
      " bpr_loss on current minibatch is 0.693815, and regularization loss is 0.000667.\n",
      " Top K precision = 0.01, recall = 0.0041991480386621045.\n",
      "Training on epoch 10 minibatch 3001/5000 completed\n",
      " bpr_loss on current minibatch is 0.693872, and regularization loss is 0.000725.\n",
      " Top K precision = 0.005000000000000001, recall = 0.0022222222222222222.\n",
      "Training on epoch 10 minibatch 3101/5000 completed\n",
      " bpr_loss on current minibatch is 0.693942, and regularization loss is 0.000794.\n",
      " Top K precision = 0.025423728813559327, recall = 0.012310517407088158.\n",
      "Training on epoch 10 minibatch 3201/5000 completed\n",
      " bpr_loss on current minibatch is 0.693827, and regularization loss is 0.00068.\n",
      " Top K precision = 0.01833333333333333, recall = 0.006317035050087253.\n",
      "Training on epoch 10 minibatch 3301/5000 completed\n",
      " bpr_loss on current minibatch is 0.693754, and regularization loss is 0.000607.\n",
      " Top K precision = 0.01, recall = 0.003966089149624431.\n",
      "Training on epoch 10 minibatch 3401/5000 completed\n",
      " bpr_loss on current minibatch is 0.693822, and regularization loss is 0.000675.\n",
      " Top K precision = 0.011864406779661016, recall = 0.004928818853027737.\n",
      "Training on epoch 10 minibatch 3501/5000 completed\n",
      " bpr_loss on current minibatch is 0.69384, and regularization loss is 0.000693.\n",
      " Top K precision = 0.016949152542372878, recall = 0.005009163729776087.\n",
      "Training on epoch 10 minibatch 3601/5000 completed\n",
      " bpr_loss on current minibatch is 0.693831, and regularization loss is 0.000684.\n",
      " Top K precision = 0.010344827586206896, recall = 0.006150433555152248.\n",
      "Training on epoch 10 minibatch 3701/5000 completed\n",
      " bpr_loss on current minibatch is 0.693961, and regularization loss is 0.000813.\n",
      " Top K precision = 0.015254237288135592, recall = 0.006779173991786928.\n",
      "Training on epoch 10 minibatch 3801/5000 completed\n",
      " bpr_loss on current minibatch is 0.693767, and regularization loss is 0.00062.\n",
      " Top K precision = 0.005084745762711865, recall = 0.001340719876665852.\n",
      "Training on epoch 10 minibatch 3901/5000 completed\n",
      " bpr_loss on current minibatch is 0.693674, and regularization loss is 0.000527.\n",
      " Top K precision = 0.008333333333333333, recall = 0.0029343434343434348.\n",
      "Training on epoch 10 minibatch 4001/5000 completed\n",
      " bpr_loss on current minibatch is 0.693744, and regularization loss is 0.000597.\n",
      " Top K precision = 0.023333333333333334, recall = 0.010361086809551723.\n",
      "Training on epoch 10 minibatch 4101/5000 completed\n",
      " bpr_loss on current minibatch is 0.693873, and regularization loss is 0.000726.\n",
      " Top K precision = 0.013559322033898305, recall = 0.0067413488580194405.\n",
      "Training on epoch 10 minibatch 4201/5000 completed\n",
      " bpr_loss on current minibatch is 0.69376, and regularization loss is 0.000613.\n",
      " Top K precision = 0.014999999999999998, recall = 0.005181212494744487.\n",
      "Training on epoch 10 minibatch 4301/5000 completed\n",
      " bpr_loss on current minibatch is 0.693739, and regularization loss is 0.000592.\n",
      " Top K precision = 0.02, recall = 0.009069941632441632.\n",
      "Training on epoch 10 minibatch 4401/5000 completed\n",
      " bpr_loss on current minibatch is 0.693782, and regularization loss is 0.000635.\n",
      " Top K precision = 0.010344827586206896, recall = 0.003942499843500955.\n",
      "Training on epoch 10 minibatch 4501/5000 completed\n",
      " bpr_loss on current minibatch is 0.693782, and regularization loss is 0.000635.\n",
      " Top K precision = 0.011666666666666665, recall = 0.005453088578088578.\n",
      "Training on epoch 10 minibatch 4601/5000 completed\n",
      " bpr_loss on current minibatch is 0.693903, and regularization loss is 0.000756.\n",
      " Top K precision = 0.00847457627118644, recall = 0.0039011096231723213.\n",
      "Training on epoch 10 minibatch 4701/5000 completed\n",
      " bpr_loss on current minibatch is 0.693782, and regularization loss is 0.000634.\n",
      " Top K precision = 0.010169491525423728, recall = 0.005793708767938254.\n",
      "Training on epoch 10 minibatch 4801/5000 completed\n",
      " bpr_loss on current minibatch is 0.693872, and regularization loss is 0.000725.\n",
      " Top K precision = 0.013559322033898305, recall = 0.005581631650936374.\n",
      "Training on epoch 10 minibatch 4901/5000 completed\n",
      " bpr_loss on current minibatch is 0.693653, and regularization loss is 0.000506.\n",
      " Top K precision = 0.013333333333333332, recall = 0.0061687158362522055.\n",
      "\n",
      "Training on 10 epoch completed.\n",
      " Average bpr_loss on train set is 0.011563 for the current epoch.\n",
      " Training top K precision = 0.014366666666666767, recall = 0.006389374977058928.\n",
      " Average bpr_loss on the validation set is 2e-06, and regularization loss is 0.0.\n",
      " Validation top K precision = 0.015133333333333445, recall = 0.006690908938942382.\n",
      "\n",
      "Training on the 11 epoch\n",
      "Training on epoch 11 minibatch 1/5000 completed\n",
      " bpr_loss on current minibatch is 0.693833, and regularization loss is 0.000685.\n",
      " Top K precision = 0.016949152542372878, recall = 0.006306468941419163.\n",
      "Training on epoch 11 minibatch 101/5000 completed\n",
      " bpr_loss on current minibatch is 0.693727, and regularization loss is 0.00058.\n",
      " Top K precision = 0.008333333333333333, recall = 0.0037603780250839076.\n",
      "Training on epoch 11 minibatch 201/5000 completed\n",
      " bpr_loss on current minibatch is 0.693748, and regularization loss is 0.000601.\n",
      " Top K precision = 0.023333333333333338, recall = 0.01015750635608905.\n",
      "Training on epoch 11 minibatch 301/5000 completed\n",
      " bpr_loss on current minibatch is 0.69388, and regularization loss is 0.000733.\n",
      " Top K precision = 0.00847457627118644, recall = 0.00274129502089786.\n",
      "Training on epoch 11 minibatch 401/5000 completed\n",
      " bpr_loss on current minibatch is 0.693637, and regularization loss is 0.00049.\n",
      " Top K precision = 0.015254237288135592, recall = 0.0079927126274925.\n",
      "Training on epoch 11 minibatch 501/5000 completed\n",
      " bpr_loss on current minibatch is 0.693783, and regularization loss is 0.000636.\n",
      " Top K precision = 0.014999999999999998, recall = 0.0064521173271173266.\n",
      "Training on epoch 11 minibatch 601/5000 completed\n",
      " bpr_loss on current minibatch is 0.69373, and regularization loss is 0.000582.\n",
      " Top K precision = 0.010169491525423728, recall = 0.003792606050384953.\n",
      "Training on epoch 11 minibatch 701/5000 completed\n",
      " bpr_loss on current minibatch is 0.693856, and regularization loss is 0.000708.\n",
      " Top K precision = 0.015254237288135592, recall = 0.007625722017415359.\n",
      "Training on epoch 11 minibatch 801/5000 completed\n",
      " bpr_loss on current minibatch is 0.693867, and regularization loss is 0.00072.\n",
      " Top K precision = 0.013333333333333332, recall = 0.009026307756570913.\n",
      "Training on epoch 11 minibatch 901/5000 completed\n",
      " bpr_loss on current minibatch is 0.693687, and regularization loss is 0.00054.\n",
      " Top K precision = 0.014999999999999998, recall = 0.005529281710801259.\n",
      "Training on epoch 11 minibatch 1001/5000 completed\n",
      " bpr_loss on current minibatch is 0.693803, and regularization loss is 0.000655.\n",
      " Top K precision = 0.01833333333333333, recall = 0.008538769976269978.\n",
      "Training on epoch 11 minibatch 1101/5000 completed\n",
      " bpr_loss on current minibatch is 0.693699, and regularization loss is 0.000552.\n",
      " Top K precision = 0.01, recall = 0.003950281953210042.\n",
      "Training on epoch 11 minibatch 1201/5000 completed\n",
      " bpr_loss on current minibatch is 0.69377, and regularization loss is 0.000623.\n",
      " Top K precision = 0.00847457627118644, recall = 0.0033452669122791246.\n",
      "Training on epoch 11 minibatch 1301/5000 completed\n",
      " bpr_loss on current minibatch is 0.693724, and regularization loss is 0.000577.\n",
      " Top K precision = 0.013559322033898305, recall = 0.008987680214651475.\n",
      "Training on epoch 11 minibatch 1401/5000 completed\n",
      " bpr_loss on current minibatch is 0.693777, and regularization loss is 0.00063.\n",
      " Top K precision = 0.005000000000000001, recall = 0.003022486772486773.\n",
      "Training on epoch 11 minibatch 1501/5000 completed\n",
      " bpr_loss on current minibatch is 0.693803, and regularization loss is 0.000656.\n",
      " Top K precision = 0.015517241379310343, recall = 0.00614111209952995.\n",
      "Training on epoch 11 minibatch 1601/5000 completed\n",
      " bpr_loss on current minibatch is 0.693797, and regularization loss is 0.00065.\n",
      " Top K precision = 0.01833333333333333, recall = 0.007219154241661416.\n",
      "Training on epoch 11 minibatch 1701/5000 completed\n",
      " bpr_loss on current minibatch is 0.693809, and regularization loss is 0.000662.\n",
      " Top K precision = 0.008333333333333333, recall = 0.004655067155067155.\n",
      "Training on epoch 11 minibatch 1801/5000 completed\n",
      " bpr_loss on current minibatch is 0.693709, and regularization loss is 0.000562.\n",
      " Top K precision = 0.011864406779661016, recall = 0.0030236760181324984.\n",
      "Training on epoch 11 minibatch 1901/5000 completed\n",
      " bpr_loss on current minibatch is 0.693892, and regularization loss is 0.000745.\n",
      " Top K precision = 0.017543859649122806, recall = 0.005747662242114191.\n",
      "Training on epoch 11 minibatch 2001/5000 completed\n",
      " bpr_loss on current minibatch is 0.69379, and regularization loss is 0.000643.\n",
      " Top K precision = 0.016666666666666666, recall = 0.007598581506615585.\n",
      "Training on epoch 11 minibatch 2101/5000 completed\n",
      " bpr_loss on current minibatch is 0.693647, and regularization loss is 0.0005.\n",
      " Top K precision = 0.014999999999999998, recall = 0.008753053544533282.\n",
      "Training on epoch 11 minibatch 2201/5000 completed\n",
      " bpr_loss on current minibatch is 0.693671, and regularization loss is 0.000524.\n",
      " Top K precision = 0.016666666666666666, recall = 0.007519028091002873.\n",
      "Training on epoch 11 minibatch 2301/5000 completed\n",
      " bpr_loss on current minibatch is 0.693599, and regularization loss is 0.000452.\n",
      " Top K precision = 0.017241379310344827, recall = 0.006235431677069411.\n",
      "Training on epoch 11 minibatch 2401/5000 completed\n",
      " bpr_loss on current minibatch is 0.693824, and regularization loss is 0.000676.\n",
      " Top K precision = 0.018965517241379314, recall = 0.007307627103642191.\n",
      "Training on epoch 11 minibatch 2501/5000 completed\n",
      " bpr_loss on current minibatch is 0.693728, and regularization loss is 0.000581.\n",
      " Top K precision = 0.017241379310344827, recall = 0.008166113468232145.\n",
      "Training on epoch 11 minibatch 2601/5000 completed\n",
      " bpr_loss on current minibatch is 0.693985, and regularization loss is 0.000838.\n",
      " Top K precision = 0.013559322033898305, recall = 0.005319257167875132.\n",
      "Training on epoch 11 minibatch 2701/5000 completed\n",
      " bpr_loss on current minibatch is 0.693865, and regularization loss is 0.000718.\n",
      " Top K precision = 0.01833333333333333, recall = 0.01079631288763855.\n",
      "Training on epoch 11 minibatch 2801/5000 completed\n",
      " bpr_loss on current minibatch is 0.693731, and regularization loss is 0.000584.\n",
      " Top K precision = 0.014999999999999998, recall = 0.00810411150449101.\n",
      "Training on epoch 11 minibatch 2901/5000 completed\n",
      " bpr_loss on current minibatch is 0.693723, and regularization loss is 0.000576.\n",
      " Top K precision = 0.010169491525423728, recall = 0.0041141751429492855.\n",
      "Training on epoch 11 minibatch 3001/5000 completed\n",
      " bpr_loss on current minibatch is 0.693759, and regularization loss is 0.000612.\n",
      " Top K precision = 0.005172413793103449, recall = 0.002067838629704755.\n",
      "Training on epoch 11 minibatch 3101/5000 completed\n",
      " bpr_loss on current minibatch is 0.693719, and regularization loss is 0.000572.\n",
      " Top K precision = 0.005084745762711865, recall = 0.001095937663875674.\n",
      "Training on epoch 11 minibatch 3201/5000 completed\n",
      " bpr_loss on current minibatch is 0.693843, and regularization loss is 0.000695.\n",
      " Top K precision = 0.011864406779661016, recall = 0.003916388349093314.\n",
      "Training on epoch 11 minibatch 3301/5000 completed\n",
      " bpr_loss on current minibatch is 0.693731, and regularization loss is 0.000584.\n",
      " Top K precision = 0.016666666666666666, recall = 0.00691542934189993.\n",
      "Training on epoch 11 minibatch 3401/5000 completed\n",
      " bpr_loss on current minibatch is 0.693851, and regularization loss is 0.000704.\n",
      " Top K precision = 0.013333333333333332, recall = 0.005012137805741003.\n",
      "Training on epoch 11 minibatch 3501/5000 completed\n",
      " bpr_loss on current minibatch is 0.693855, and regularization loss is 0.000708.\n",
      " Top K precision = 0.013559322033898305, recall = 0.006571758872522837.\n",
      "Training on epoch 11 minibatch 3601/5000 completed\n",
      " bpr_loss on current minibatch is 0.693768, and regularization loss is 0.000621.\n",
      " Top K precision = 0.008333333333333333, recall = 0.0020384668625947695.\n",
      "Training on epoch 11 minibatch 3701/5000 completed\n",
      " bpr_loss on current minibatch is 0.693754, and regularization loss is 0.000607.\n",
      " Top K precision = 0.01, recall = 0.0037106045578031996.\n",
      "Training on epoch 11 minibatch 3801/5000 completed\n",
      " bpr_loss on current minibatch is 0.693827, and regularization loss is 0.00068.\n",
      " Top K precision = 0.010169491525423728, recall = 0.0033631677234739017.\n",
      "Training on epoch 11 minibatch 3901/5000 completed\n",
      " bpr_loss on current minibatch is 0.693879, and regularization loss is 0.000732.\n",
      " Top K precision = 0.020338983050847456, recall = 0.0074982645496646985.\n",
      "Training on epoch 11 minibatch 4001/5000 completed\n",
      " bpr_loss on current minibatch is 0.693773, and regularization loss is 0.000626.\n",
      " Top K precision = 0.016666666666666666, recall = 0.005780146810497249.\n",
      "Training on epoch 11 minibatch 4101/5000 completed\n",
      " bpr_loss on current minibatch is 0.693971, and regularization loss is 0.000824.\n",
      " Top K precision = 0.013333333333333332, recall = 0.005817264525597859.\n",
      "Training on epoch 11 minibatch 4201/5000 completed\n",
      " bpr_loss on current minibatch is 0.693832, and regularization loss is 0.000685.\n",
      " Top K precision = 0.013559322033898306, recall = 0.004947399683844712.\n",
      "Training on epoch 11 minibatch 4301/5000 completed\n",
      " bpr_loss on current minibatch is 0.693787, and regularization loss is 0.00064.\n",
      " Top K precision = 0.008333333333333333, recall = 0.0027075702075702074.\n",
      "Training on epoch 11 minibatch 4401/5000 completed\n",
      " bpr_loss on current minibatch is 0.693755, and regularization loss is 0.000608.\n",
      " Top K precision = 0.011666666666666665, recall = 0.006504329734592893.\n",
      "Training on epoch 11 minibatch 4501/5000 completed\n",
      " bpr_loss on current minibatch is 0.693582, and regularization loss is 0.000435.\n",
      " Top K precision = 0.011666666666666667, recall = 0.004959531955499697.\n",
      "Training on epoch 11 minibatch 4601/5000 completed\n",
      " bpr_loss on current minibatch is 0.693862, and regularization loss is 0.000715.\n",
      " Top K precision = 0.013333333333333332, recall = 0.004439116272449606.\n",
      "Training on epoch 11 minibatch 4701/5000 completed\n",
      " bpr_loss on current minibatch is 0.693869, and regularization loss is 0.000721.\n",
      " Top K precision = 0.02, recall = 0.010514214319644976.\n",
      "Training on epoch 11 minibatch 4801/5000 completed\n",
      " bpr_loss on current minibatch is 0.693878, and regularization loss is 0.000731.\n",
      " Top K precision = 0.010169491525423728, recall = 0.003259652685568486.\n",
      "Training on epoch 11 minibatch 4901/5000 completed\n",
      " bpr_loss on current minibatch is 0.693785, and regularization loss is 0.000638.\n",
      " Top K precision = 0.010344827586206896, recall = 0.004046514234802443.\n",
      "\n",
      "Training on 11 epoch completed.\n",
      " Average bpr_loss on train set is 0.011563 for the current epoch.\n",
      " Training top K precision = 0.016033333333333455, recall = 0.007823719405419404.\n",
      " Average bpr_loss on the validation set is 2e-06, and regularization loss is 0.0.\n",
      " Validation top K precision = 0.01386666666666676, recall = 0.005838010446524614.\n",
      "\n",
      "Training on the 12 epoch\n",
      "Training on epoch 12 minibatch 1/5000 completed\n",
      " bpr_loss on current minibatch is 0.693731, and regularization loss is 0.000583.\n",
      " Top K precision = 0.013333333333333332, recall = 0.005090170931496591.\n",
      "Training on epoch 12 minibatch 101/5000 completed\n",
      " bpr_loss on current minibatch is 0.693945, and regularization loss is 0.000798.\n",
      " Top K precision = 0.013333333333333334, recall = 0.006223731022959698.\n",
      "Training on epoch 12 minibatch 201/5000 completed\n",
      " bpr_loss on current minibatch is 0.693875, and regularization loss is 0.000728.\n",
      " Top K precision = 0.008333333333333333, recall = 0.00275477340694732.\n",
      "Training on epoch 12 minibatch 301/5000 completed\n",
      " bpr_loss on current minibatch is 0.693822, and regularization loss is 0.000675.\n",
      " Top K precision = 0.01833333333333333, recall = 0.009456967262454818.\n",
      "Training on epoch 12 minibatch 401/5000 completed\n",
      " bpr_loss on current minibatch is 0.693716, and regularization loss is 0.000568.\n",
      " Top K precision = 0.014999999999999998, recall = 0.006538753548557471.\n",
      "Training on epoch 12 minibatch 501/5000 completed\n",
      " bpr_loss on current minibatch is 0.693664, and regularization loss is 0.000517.\n",
      " Top K precision = 0.010169491525423728, recall = 0.004411202482777233.\n",
      "Training on epoch 12 minibatch 601/5000 completed\n",
      " bpr_loss on current minibatch is 0.693831, and regularization loss is 0.000684.\n",
      " Top K precision = 0.013333333333333334, recall = 0.005341978856684739.\n",
      "Training on epoch 12 minibatch 701/5000 completed\n",
      " bpr_loss on current minibatch is 0.693934, and regularization loss is 0.000786.\n",
      " Top K precision = 0.010169491525423728, recall = 0.003509274073040092.\n",
      "Training on epoch 12 minibatch 801/5000 completed\n",
      " bpr_loss on current minibatch is 0.693888, and regularization loss is 0.000741.\n",
      " Top K precision = 0.00847457627118644, recall = 0.0049292928427390565.\n",
      "Training on epoch 12 minibatch 901/5000 completed\n",
      " bpr_loss on current minibatch is 0.693796, and regularization loss is 0.000648.\n",
      " Top K precision = 0.005000000000000001, recall = 0.0023237179487179487.\n",
      "Training on epoch 12 minibatch 1001/5000 completed\n",
      " bpr_loss on current minibatch is 0.693893, and regularization loss is 0.000746.\n",
      " Top K precision = 0.01, recall = 0.0036361363199906137.\n",
      "Training on epoch 12 minibatch 1101/5000 completed\n",
      " bpr_loss on current minibatch is 0.693666, and regularization loss is 0.000519.\n",
      " Top K precision = 0.013559322033898305, recall = 0.006092317873093966.\n",
      "Training on epoch 12 minibatch 1201/5000 completed\n",
      " bpr_loss on current minibatch is 0.69377, and regularization loss is 0.000623.\n",
      " Top K precision = 0.01, recall = 0.0030633212592317926.\n",
      "Training on epoch 12 minibatch 1301/5000 completed\n",
      " bpr_loss on current minibatch is 0.693725, and regularization loss is 0.000578.\n",
      " Top K precision = 0.01016949152542373, recall = 0.00392035183541671.\n",
      "Training on epoch 12 minibatch 1401/5000 completed\n",
      " bpr_loss on current minibatch is 0.693758, and regularization loss is 0.000611.\n",
      " Top K precision = 0.013559322033898305, recall = 0.007001800700066367.\n",
      "Training on epoch 12 minibatch 1501/5000 completed\n",
      " bpr_loss on current minibatch is 0.693841, and regularization loss is 0.000694.\n",
      " Top K precision = 0.016666666666666666, recall = 0.007877804611873238.\n",
      "Training on epoch 12 minibatch 1601/5000 completed\n",
      " bpr_loss on current minibatch is 0.693803, and regularization loss is 0.000656.\n",
      " Top K precision = 0.016949152542372878, recall = 0.005985282866448899.\n",
      "Training on epoch 12 minibatch 1701/5000 completed\n",
      " bpr_loss on current minibatch is 0.693824, and regularization loss is 0.000677.\n",
      " Top K precision = 0.006779661016949153, recall = 0.00207785733707967.\n",
      "Training on epoch 12 minibatch 1801/5000 completed\n",
      " bpr_loss on current minibatch is 0.693881, and regularization loss is 0.000733.\n",
      " Top K precision = 0.018644067796610167, recall = 0.011082153294151957.\n",
      "Training on epoch 12 minibatch 1901/5000 completed\n",
      " bpr_loss on current minibatch is 0.693736, and regularization loss is 0.000588.\n",
      " Top K precision = 0.017241379310344827, recall = 0.00828670656431301.\n",
      "Training on epoch 12 minibatch 2001/5000 completed\n",
      " bpr_loss on current minibatch is 0.694031, and regularization loss is 0.000884.\n",
      " Top K precision = 0.01, recall = 0.0030432098765432103.\n",
      "Training on epoch 12 minibatch 2101/5000 completed\n",
      " bpr_loss on current minibatch is 0.693872, and regularization loss is 0.000725.\n",
      " Top K precision = 0.010169491525423728, recall = 0.003879764277143567.\n",
      "Training on epoch 12 minibatch 2201/5000 completed\n",
      " bpr_loss on current minibatch is 0.693679, and regularization loss is 0.000532.\n",
      " Top K precision = 0.02, recall = 0.00914833103237378.\n",
      "Training on epoch 12 minibatch 2301/5000 completed\n",
      " bpr_loss on current minibatch is 0.693843, and regularization loss is 0.000696.\n",
      " Top K precision = 0.013333333333333332, recall = 0.005852113767874637.\n",
      "Training on epoch 12 minibatch 2401/5000 completed\n",
      " bpr_loss on current minibatch is 0.693754, and regularization loss is 0.000607.\n",
      " Top K precision = 0.013559322033898305, recall = 0.0040868173622386605.\n",
      "Training on epoch 12 minibatch 2501/5000 completed\n",
      " bpr_loss on current minibatch is 0.693819, and regularization loss is 0.000671.\n",
      " Top K precision = 0.015789473684210523, recall = 0.006127335097787544.\n",
      "Training on epoch 12 minibatch 2601/5000 completed\n",
      " bpr_loss on current minibatch is 0.6939, and regularization loss is 0.000753.\n",
      " Top K precision = 0.023333333333333338, recall = 0.007847185576733633.\n",
      "Training on epoch 12 minibatch 2701/5000 completed\n",
      " bpr_loss on current minibatch is 0.693673, and regularization loss is 0.000525.\n",
      " Top K precision = 0.016666666666666666, recall = 0.006734487327636974.\n",
      "Training on epoch 12 minibatch 2801/5000 completed\n",
      " bpr_loss on current minibatch is 0.693667, and regularization loss is 0.000519.\n",
      " Top K precision = 0.006666666666666667, recall = 0.005909822866344605.\n",
      "Training on epoch 12 minibatch 2901/5000 completed\n",
      " bpr_loss on current minibatch is 0.693748, and regularization loss is 0.0006.\n",
      " Top K precision = 0.0033333333333333335, recall = 0.002094017094017094.\n",
      "Training on epoch 12 minibatch 3001/5000 completed\n",
      " bpr_loss on current minibatch is 0.693868, and regularization loss is 0.000721.\n",
      " Top K precision = 0.011666666666666665, recall = 0.0040743221932071335.\n",
      "Training on epoch 12 minibatch 3101/5000 completed\n",
      " bpr_loss on current minibatch is 0.693776, and regularization loss is 0.000629.\n",
      " Top K precision = 0.014035087719298244, recall = 0.007760728064166341.\n",
      "Training on epoch 12 minibatch 3201/5000 completed\n",
      " bpr_loss on current minibatch is 0.693703, and regularization loss is 0.000556.\n",
      " Top K precision = 0.010526315789473684, recall = 0.0068628567854574045.\n",
      "Training on epoch 12 minibatch 3301/5000 completed\n",
      " bpr_loss on current minibatch is 0.693695, and regularization loss is 0.000547.\n",
      " Top K precision = 0.01864406779661017, recall = 0.0070767794748970905.\n",
      "Training on epoch 12 minibatch 3401/5000 completed\n",
      " bpr_loss on current minibatch is 0.69385, and regularization loss is 0.000702.\n",
      " Top K precision = 0.011666666666666665, recall = 0.005635247800994831.\n",
      "Training on epoch 12 minibatch 3501/5000 completed\n",
      " bpr_loss on current minibatch is 0.69373, and regularization loss is 0.000583.\n",
      " Top K precision = 0.005000000000000001, recall = 0.0031944444444444446.\n",
      "Training on epoch 12 minibatch 3601/5000 completed\n",
      " bpr_loss on current minibatch is 0.693689, and regularization loss is 0.000541.\n",
      " Top K precision = 0.016666666666666666, recall = 0.006096731401245979.\n",
      "Training on epoch 12 minibatch 3701/5000 completed\n",
      " bpr_loss on current minibatch is 0.693726, and regularization loss is 0.000579.\n",
      " Top K precision = 0.001724137931034483, recall = 0.0009074410163339383.\n",
      "Training on epoch 12 minibatch 3801/5000 completed\n",
      " bpr_loss on current minibatch is 0.693761, and regularization loss is 0.000614.\n",
      " Top K precision = 0.008333333333333333, recall = 0.006209436991170738.\n",
      "Training on epoch 12 minibatch 3901/5000 completed\n",
      " bpr_loss on current minibatch is 0.693821, and regularization loss is 0.000674.\n",
      " Top K precision = 0.008333333333333333, recall = 0.005141178266178266.\n",
      "Training on epoch 12 minibatch 4001/5000 completed\n",
      " bpr_loss on current minibatch is 0.69366, and regularization loss is 0.000512.\n",
      " Top K precision = 0.008620689655172414, recall = 0.003219301410090884.\n",
      "Training on epoch 12 minibatch 4101/5000 completed\n",
      " bpr_loss on current minibatch is 0.693871, and regularization loss is 0.000724.\n",
      " Top K precision = 0.015254237288135592, recall = 0.00856570922722169.\n",
      "Training on epoch 12 minibatch 4201/5000 completed\n",
      " bpr_loss on current minibatch is 0.693679, and regularization loss is 0.000531.\n",
      " Top K precision = 0.008333333333333333, recall = 0.003566287878787879.\n",
      "Training on epoch 12 minibatch 4301/5000 completed\n",
      " bpr_loss on current minibatch is 0.693625, and regularization loss is 0.000478.\n",
      " Top K precision = 0.00847457627118644, recall = 0.004314813387595043.\n",
      "Training on epoch 12 minibatch 4401/5000 completed\n",
      " bpr_loss on current minibatch is 0.693747, and regularization loss is 0.0006.\n",
      " Top K precision = 0.006666666666666667, recall = 0.002602988310708899.\n",
      "Training on epoch 12 minibatch 4501/5000 completed\n",
      " bpr_loss on current minibatch is 0.693877, and regularization loss is 0.00073.\n",
      " Top K precision = 0.008620689655172414, recall = 0.004358076365252569.\n",
      "Training on epoch 12 minibatch 4601/5000 completed\n",
      " bpr_loss on current minibatch is 0.69389, and regularization loss is 0.000742.\n",
      " Top K precision = 0.02033898305084746, recall = 0.007790325898320782.\n",
      "Training on epoch 12 minibatch 4701/5000 completed\n",
      " bpr_loss on current minibatch is 0.693656, and regularization loss is 0.000508.\n",
      " Top K precision = 0.01, recall = 0.005192683365121695.\n",
      "Training on epoch 12 minibatch 4801/5000 completed\n",
      " bpr_loss on current minibatch is 0.693926, and regularization loss is 0.000779.\n",
      " Top K precision = 0.016666666666666666, recall = 0.006190476498858492.\n",
      "Training on epoch 12 minibatch 4901/5000 completed\n",
      " bpr_loss on current minibatch is 0.693707, and regularization loss is 0.00056.\n",
      " Top K precision = 0.01, recall = 0.004728798795046921.\n",
      "\n",
      "Training on 12 epoch completed.\n",
      " Average bpr_loss on train set is 0.011563 for the current epoch.\n",
      " Training top K precision = 0.015000000000000107, recall = 0.006335242627855764.\n",
      " Average bpr_loss on the validation set is 2e-06, and regularization loss is 0.0.\n",
      " Validation top K precision = 0.014866666666666774, recall = 0.006358290422864261.\n",
      "\n",
      "Training on the 13 epoch\n",
      "Training on epoch 13 minibatch 1/5000 completed\n",
      " bpr_loss on current minibatch is 0.693765, and regularization loss is 0.000618.\n",
      " Top K precision = 0.01, recall = 0.006307419432419433.\n",
      "Training on epoch 13 minibatch 101/5000 completed\n",
      " bpr_loss on current minibatch is 0.693651, and regularization loss is 0.000504.\n",
      " Top K precision = 0.01833333333333333, recall = 0.0056173956762192055.\n",
      "Training on epoch 13 minibatch 201/5000 completed\n",
      " bpr_loss on current minibatch is 0.693772, and regularization loss is 0.000625.\n",
      " Top K precision = 0.013333333333333334, recall = 0.0038551413255360624.\n",
      "Training on epoch 13 minibatch 301/5000 completed\n",
      " bpr_loss on current minibatch is 0.693864, and regularization loss is 0.000717.\n",
      " Top K precision = 0.020338983050847456, recall = 0.008418089610758395.\n",
      "Training on epoch 13 minibatch 401/5000 completed\n",
      " bpr_loss on current minibatch is 0.693761, and regularization loss is 0.000614.\n",
      " Top K precision = 0.01, recall = 0.0071385524001803076.\n",
      "Training on epoch 13 minibatch 501/5000 completed\n",
      " bpr_loss on current minibatch is 0.693695, and regularization loss is 0.000547.\n",
      " Top K precision = 0.013333333333333332, recall = 0.005652779469275632.\n",
      "Training on epoch 13 minibatch 601/5000 completed\n",
      " bpr_loss on current minibatch is 0.693766, and regularization loss is 0.000618.\n",
      " Top K precision = 0.022033898305084745, recall = 0.007978516270579808.\n",
      "Training on epoch 13 minibatch 701/5000 completed\n",
      " bpr_loss on current minibatch is 0.693909, and regularization loss is 0.000762.\n",
      " Top K precision = 0.01, recall = 0.003805000469087156.\n",
      "Training on epoch 13 minibatch 801/5000 completed\n",
      " bpr_loss on current minibatch is 0.693795, and regularization loss is 0.000647.\n",
      " Top K precision = 0.008333333333333333, recall = 0.0042236467236467234.\n",
      "Training on epoch 13 minibatch 901/5000 completed\n",
      " bpr_loss on current minibatch is 0.693864, and regularization loss is 0.000717.\n",
      " Top K precision = 0.011666666666666665, recall = 0.007679706046641531.\n",
      "Training on epoch 13 minibatch 1001/5000 completed\n",
      " bpr_loss on current minibatch is 0.69385, and regularization loss is 0.000703.\n",
      " Top K precision = 0.011666666666666665, recall = 0.004449672191607675.\n",
      "Training on epoch 13 minibatch 1101/5000 completed\n",
      " bpr_loss on current minibatch is 0.693845, and regularization loss is 0.000698.\n",
      " Top K precision = 0.013559322033898306, recall = 0.00561183577897554.\n",
      "Training on epoch 13 minibatch 1201/5000 completed\n",
      " bpr_loss on current minibatch is 0.69396, and regularization loss is 0.000813.\n",
      " Top K precision = 0.016666666666666666, recall = 0.007650678628939497.\n",
      "Training on epoch 13 minibatch 1301/5000 completed\n",
      " bpr_loss on current minibatch is 0.693894, and regularization loss is 0.000747.\n",
      " Top K precision = 0.011666666666666665, recall = 0.005422557029566026.\n",
      "Training on epoch 13 minibatch 1401/5000 completed\n",
      " bpr_loss on current minibatch is 0.693755, and regularization loss is 0.000608.\n",
      " Top K precision = 0.005172413793103449, recall = 0.0011550474762618691.\n",
      "Training on epoch 13 minibatch 1501/5000 completed\n",
      " bpr_loss on current minibatch is 0.693684, and regularization loss is 0.000537.\n",
      " Top K precision = 0.018644067796610167, recall = 0.006688653990889897.\n",
      "Training on epoch 13 minibatch 1601/5000 completed\n",
      " bpr_loss on current minibatch is 0.694011, and regularization loss is 0.000864.\n",
      " Top K precision = 0.01, recall = 0.0035799592672208997.\n",
      "Training on epoch 13 minibatch 1701/5000 completed\n",
      " bpr_loss on current minibatch is 0.693697, and regularization loss is 0.00055.\n",
      " Top K precision = 0.008333333333333333, recall = 0.0032595598845598845.\n",
      "Training on epoch 13 minibatch 1801/5000 completed\n",
      " bpr_loss on current minibatch is 0.69378, and regularization loss is 0.000632.\n",
      " Top K precision = 0.01694915254237288, recall = 0.006700145537083001.\n",
      "Training on epoch 13 minibatch 1901/5000 completed\n",
      " bpr_loss on current minibatch is 0.693794, and regularization loss is 0.000646.\n",
      " Top K precision = 0.005084745762711865, recall = 0.002643699336772292.\n",
      "Training on epoch 13 minibatch 2001/5000 completed\n",
      " bpr_loss on current minibatch is 0.693832, and regularization loss is 0.000685.\n",
      " Top K precision = 0.006666666666666667, recall = 0.0026745290311181785.\n",
      "Training on epoch 13 minibatch 2101/5000 completed\n",
      " bpr_loss on current minibatch is 0.693836, and regularization loss is 0.000689.\n",
      " Top K precision = 0.016666666666666666, recall = 0.006421656936544759.\n",
      "Training on epoch 13 minibatch 2201/5000 completed\n",
      " bpr_loss on current minibatch is 0.693695, and regularization loss is 0.000548.\n",
      " Top K precision = 0.01, recall = 0.004571088298443371.\n",
      "Training on epoch 13 minibatch 2301/5000 completed\n",
      " bpr_loss on current minibatch is 0.693697, and regularization loss is 0.00055.\n",
      " Top K precision = 0.010344827586206896, recall = 0.0049494250796351166.\n",
      "Training on epoch 13 minibatch 2401/5000 completed\n",
      " bpr_loss on current minibatch is 0.693835, and regularization loss is 0.000688.\n",
      " Top K precision = 0.013559322033898305, recall = 0.00723100842669197.\n",
      "Training on epoch 13 minibatch 2501/5000 completed\n",
      " bpr_loss on current minibatch is 0.694005, and regularization loss is 0.000858.\n",
      " Top K precision = 0.011666666666666665, recall = 0.003465900444161314.\n",
      "Training on epoch 13 minibatch 2601/5000 completed\n",
      " bpr_loss on current minibatch is 0.693834, and regularization loss is 0.000687.\n",
      " Top K precision = 0.008333333333333333, recall = 0.0032389979960620085.\n",
      "Training on epoch 13 minibatch 2701/5000 completed\n",
      " bpr_loss on current minibatch is 0.693778, and regularization loss is 0.000631.\n",
      " Top K precision = 0.011864406779661016, recall = 0.005827437487172426.\n",
      "Training on epoch 13 minibatch 2801/5000 completed\n",
      " bpr_loss on current minibatch is 0.693741, and regularization loss is 0.000593.\n",
      " Top K precision = 0.008620689655172414, recall = 0.004493788868049106.\n",
      "Training on epoch 13 minibatch 2901/5000 completed\n",
      " bpr_loss on current minibatch is 0.693775, and regularization loss is 0.000628.\n",
      " Top K precision = 0.013333333333333332, recall = 0.007809218821682792.\n",
      "Training on epoch 13 minibatch 3001/5000 completed\n",
      " bpr_loss on current minibatch is 0.693834, and regularization loss is 0.000687.\n",
      " Top K precision = 0.011666666666666665, recall = 0.006105113210376368.\n",
      "Training on epoch 13 minibatch 3101/5000 completed\n",
      " bpr_loss on current minibatch is 0.693658, and regularization loss is 0.000511.\n",
      " Top K precision = 0.013333333333333332, recall = 0.005508260122230711.\n",
      "Training on epoch 13 minibatch 3201/5000 completed\n",
      " bpr_loss on current minibatch is 0.693754, and regularization loss is 0.000607.\n",
      " Top K precision = 0.011666666666666665, recall = 0.004488343821510297.\n",
      "Training on epoch 13 minibatch 3301/5000 completed\n",
      " bpr_loss on current minibatch is 0.693816, and regularization loss is 0.000669.\n",
      " Top K precision = 0.013559322033898305, recall = 0.009372146926344797.\n",
      "Training on epoch 13 minibatch 3401/5000 completed\n",
      " bpr_loss on current minibatch is 0.69384, and regularization loss is 0.000693.\n",
      " Top K precision = 0.015000000000000001, recall = 0.007882497757606285.\n",
      "Training on epoch 13 minibatch 3501/5000 completed\n",
      " bpr_loss on current minibatch is 0.693708, and regularization loss is 0.000561.\n",
      " Top K precision = 0.005172413793103449, recall = 0.0021711366538952745.\n",
      "Training on epoch 13 minibatch 3601/5000 completed\n",
      " bpr_loss on current minibatch is 0.693738, and regularization loss is 0.000591.\n",
      " Top K precision = 0.014999999999999998, recall = 0.005117416199843737.\n",
      "Training on epoch 13 minibatch 3701/5000 completed\n",
      " bpr_loss on current minibatch is 0.693879, and regularization loss is 0.000732.\n",
      " Top K precision = 0.010169491525423728, recall = 0.003958027834225328.\n",
      "Training on epoch 13 minibatch 3801/5000 completed\n",
      " bpr_loss on current minibatch is 0.693748, and regularization loss is 0.000601.\n",
      " Top K precision = 0.013559322033898306, recall = 0.004521773712588366.\n",
      "Training on epoch 13 minibatch 3901/5000 completed\n",
      " bpr_loss on current minibatch is 0.693735, and regularization loss is 0.000588.\n",
      " Top K precision = 0.008333333333333333, recall = 0.0043889358920262585.\n",
      "Training on epoch 13 minibatch 4001/5000 completed\n",
      " bpr_loss on current minibatch is 0.69375, and regularization loss is 0.000602.\n",
      " Top K precision = 0.014999999999999998, recall = 0.0070022831700463275.\n",
      "Training on epoch 13 minibatch 4101/5000 completed\n",
      " bpr_loss on current minibatch is 0.694009, and regularization loss is 0.000861.\n",
      " Top K precision = 0.021666666666666667, recall = 0.010288873659090205.\n",
      "Training on epoch 13 minibatch 4201/5000 completed\n",
      " bpr_loss on current minibatch is 0.693824, and regularization loss is 0.000677.\n",
      " Top K precision = 0.015517241379310343, recall = 0.008097576474185384.\n",
      "Training on epoch 13 minibatch 4301/5000 completed\n",
      " bpr_loss on current minibatch is 0.693708, and regularization loss is 0.000561.\n",
      " Top K precision = 0.016666666666666666, recall = 0.006103263208526367.\n",
      "Training on epoch 13 minibatch 4401/5000 completed\n",
      " bpr_loss on current minibatch is 0.693729, and regularization loss is 0.000582.\n",
      " Top K precision = 0.006896551724137932, recall = 0.0052515408962185576.\n",
      "Training on epoch 13 minibatch 4501/5000 completed\n",
      " bpr_loss on current minibatch is 0.693746, and regularization loss is 0.000599.\n",
      " Top K precision = 0.013559322033898305, recall = 0.004564404893352262.\n",
      "Training on epoch 13 minibatch 4601/5000 completed\n",
      " bpr_loss on current minibatch is 0.693649, and regularization loss is 0.000502.\n",
      " Top K precision = 0.018644067796610167, recall = 0.009021033392493421.\n",
      "Training on epoch 13 minibatch 4701/5000 completed\n",
      " bpr_loss on current minibatch is 0.693805, and regularization loss is 0.000658.\n",
      " Top K precision = 0.006666666666666667, recall = 0.0027732487922705316.\n",
      "Training on epoch 13 minibatch 4801/5000 completed\n",
      " bpr_loss on current minibatch is 0.693691, and regularization loss is 0.000544.\n",
      " Top K precision = 0.011666666666666665, recall = 0.005636065323565324.\n",
      "Training on epoch 13 minibatch 4901/5000 completed\n",
      " bpr_loss on current minibatch is 0.69387, and regularization loss is 0.000723.\n",
      " Top K precision = 0.01379310344827586, recall = 0.005210254068368115.\n",
      "\n",
      "Training on 13 epoch completed.\n",
      " Average bpr_loss on train set is 0.011563 for the current epoch.\n",
      " Training top K precision = 0.014566666666666762, recall = 0.006082406967906382.\n",
      " Average bpr_loss on the validation set is 2e-06, and regularization loss is 0.0.\n",
      " Validation top K precision = 0.014300000000000099, recall = 0.00638819851163712.\n",
      "\n",
      "Training on the 14 epoch\n",
      "Training on epoch 14 minibatch 1/5000 completed\n",
      " bpr_loss on current minibatch is 0.693738, and regularization loss is 0.00059.\n",
      " Top K precision = 0.01, recall = 0.004653463754694654.\n",
      "Training on epoch 14 minibatch 101/5000 completed\n",
      " bpr_loss on current minibatch is 0.693914, and regularization loss is 0.000767.\n",
      " Top K precision = 0.005000000000000001, recall = 0.0020833333333333333.\n",
      "Training on epoch 14 minibatch 201/5000 completed\n",
      " bpr_loss on current minibatch is 0.693853, and regularization loss is 0.000706.\n",
      " Top K precision = 0.008333333333333333, recall = 0.003699926281448021.\n",
      "Training on epoch 14 minibatch 301/5000 completed\n",
      " bpr_loss on current minibatch is 0.693739, and regularization loss is 0.000592.\n",
      " Top K precision = 0.00847457627118644, recall = 0.003155099775443158.\n",
      "Training on epoch 14 minibatch 401/5000 completed\n",
      " bpr_loss on current minibatch is 0.693827, and regularization loss is 0.00068.\n",
      " Top K precision = 0.003448275862068966, recall = 0.002442528735632184.\n",
      "Training on epoch 14 minibatch 501/5000 completed\n",
      " bpr_loss on current minibatch is 0.693941, and regularization loss is 0.000794.\n",
      " Top K precision = 0.010169491525423728, recall = 0.0030861636793840185.\n",
      "Training on epoch 14 minibatch 601/5000 completed\n",
      " bpr_loss on current minibatch is 0.693724, and regularization loss is 0.000577.\n",
      " Top K precision = 0.013333333333333332, recall = 0.004112592032950739.\n",
      "Training on epoch 14 minibatch 701/5000 completed\n",
      " bpr_loss on current minibatch is 0.693924, and regularization loss is 0.000777.\n",
      " Top K precision = 0.023333333333333334, recall = 0.01047151298314089.\n",
      "Training on epoch 14 minibatch 801/5000 completed\n",
      " bpr_loss on current minibatch is 0.693792, and regularization loss is 0.000645.\n",
      " Top K precision = 0.012280701754385965, recall = 0.004523116231735606.\n",
      "Training on epoch 14 minibatch 901/5000 completed\n",
      " bpr_loss on current minibatch is 0.693655, and regularization loss is 0.000508.\n",
      " Top K precision = 0.01, recall = 0.002948233053496211.\n",
      "Training on epoch 14 minibatch 1001/5000 completed\n",
      " bpr_loss on current minibatch is 0.693697, and regularization loss is 0.00055.\n",
      " Top K precision = 0.014035087719298244, recall = 0.005255005696855206.\n",
      "Training on epoch 14 minibatch 1101/5000 completed\n",
      " bpr_loss on current minibatch is 0.693849, and regularization loss is 0.000702.\n",
      " Top K precision = 0.013559322033898305, recall = 0.005705373888325035.\n",
      "Training on epoch 14 minibatch 1201/5000 completed\n",
      " bpr_loss on current minibatch is 0.693843, and regularization loss is 0.000696.\n",
      " Top K precision = 0.014999999999999998, recall = 0.005246127970276068.\n",
      "Training on epoch 14 minibatch 1301/5000 completed\n",
      " bpr_loss on current minibatch is 0.693849, and regularization loss is 0.000702.\n",
      " Top K precision = 0.021666666666666667, recall = 0.009482776069443585.\n",
      "Training on epoch 14 minibatch 1401/5000 completed\n",
      " bpr_loss on current minibatch is 0.69385, and regularization loss is 0.000703.\n",
      " Top K precision = 0.0033898305084745766, recall = 0.000707442888725129.\n",
      "Training on epoch 14 minibatch 1501/5000 completed\n",
      " bpr_loss on current minibatch is 0.693709, and regularization loss is 0.000561.\n",
      " Top K precision = 0.005000000000000001, recall = 0.0023333333333333335.\n",
      "Training on epoch 14 minibatch 1601/5000 completed\n",
      " bpr_loss on current minibatch is 0.693767, and regularization loss is 0.00062.\n",
      " Top K precision = 0.018333333333333333, recall = 0.006618137352549558.\n",
      "Training on epoch 14 minibatch 1701/5000 completed\n",
      " bpr_loss on current minibatch is 0.693805, and regularization loss is 0.000658.\n",
      " Top K precision = 0.015000000000000001, recall = 0.006118091358926823.\n",
      "Training on epoch 14 minibatch 1801/5000 completed\n",
      " bpr_loss on current minibatch is 0.69388, and regularization loss is 0.000732.\n",
      " Top K precision = 0.013333333333333332, recall = 0.006567620592640784.\n",
      "Training on epoch 14 minibatch 1901/5000 completed\n",
      " bpr_loss on current minibatch is 0.693882, and regularization loss is 0.000735.\n",
      " Top K precision = 0.010169491525423728, recall = 0.006273364928583483.\n",
      "Training on epoch 14 minibatch 2001/5000 completed\n",
      " bpr_loss on current minibatch is 0.693751, and regularization loss is 0.000604.\n",
      " Top K precision = 0.011666666666666665, recall = 0.0035696214577338532.\n",
      "Training on epoch 14 minibatch 2101/5000 completed\n",
      " bpr_loss on current minibatch is 0.69365, and regularization loss is 0.000503.\n",
      " Top K precision = 0.01, recall = 0.004268632276261384.\n",
      "Training on epoch 14 minibatch 2201/5000 completed\n",
      " bpr_loss on current minibatch is 0.693761, and regularization loss is 0.000614.\n",
      " Top K precision = 0.008333333333333333, recall = 0.0032083673318003113.\n",
      "Training on epoch 14 minibatch 2301/5000 completed\n",
      " bpr_loss on current minibatch is 0.693765, and regularization loss is 0.000618.\n",
      " Top K precision = 0.006666666666666667, recall = 0.0028373015873015875.\n",
      "Training on epoch 14 minibatch 2401/5000 completed\n",
      " bpr_loss on current minibatch is 0.693937, and regularization loss is 0.000789.\n",
      " Top K precision = 0.013333333333333332, recall = 0.0066709527651865105.\n",
      "Training on epoch 14 minibatch 2501/5000 completed\n",
      " bpr_loss on current minibatch is 0.69377, and regularization loss is 0.000623.\n",
      " Top K precision = 0.006666666666666667, recall = 0.0038024548550864338.\n",
      "Training on epoch 14 minibatch 2601/5000 completed\n",
      " bpr_loss on current minibatch is 0.693848, and regularization loss is 0.0007.\n",
      " Top K precision = 0.015254237288135592, recall = 0.005553800216586053.\n",
      "Training on epoch 14 minibatch 2701/5000 completed\n",
      " bpr_loss on current minibatch is 0.693754, and regularization loss is 0.000607.\n",
      " Top K precision = 0.008333333333333333, recall = 0.004683410271645566.\n",
      "Training on epoch 14 minibatch 2801/5000 completed\n",
      " bpr_loss on current minibatch is 0.693899, and regularization loss is 0.000752.\n",
      " Top K precision = 0.005084745762711865, recall = 0.0024560259841258946.\n",
      "Training on epoch 14 minibatch 2901/5000 completed\n",
      " bpr_loss on current minibatch is 0.693867, and regularization loss is 0.00072.\n",
      " Top K precision = 0.00847457627118644, recall = 0.0027918001185698095.\n",
      "Training on epoch 14 minibatch 3001/5000 completed\n",
      " bpr_loss on current minibatch is 0.693812, and regularization loss is 0.000665.\n",
      " Top K precision = 0.01, recall = 0.006013176638176639.\n",
      "Training on epoch 14 minibatch 3101/5000 completed\n",
      " bpr_loss on current minibatch is 0.693849, and regularization loss is 0.000701.\n",
      " Top K precision = 0.00847457627118644, recall = 0.004436533659210456.\n",
      "Training on epoch 14 minibatch 3201/5000 completed\n",
      " bpr_loss on current minibatch is 0.69392, and regularization loss is 0.000773.\n",
      " Top K precision = 0.016949152542372878, recall = 0.006021803537643116.\n",
      "Training on epoch 14 minibatch 3301/5000 completed\n",
      " bpr_loss on current minibatch is 0.693771, and regularization loss is 0.000624.\n",
      " Top K precision = 0.013333333333333332, recall = 0.008156765094151664.\n",
      "Training on epoch 14 minibatch 3401/5000 completed\n",
      " bpr_loss on current minibatch is 0.693863, and regularization loss is 0.000715.\n",
      " Top K precision = 0.006779661016949153, recall = 0.0037639471073041327.\n",
      "Training on epoch 14 minibatch 3501/5000 completed\n",
      " bpr_loss on current minibatch is 0.693724, and regularization loss is 0.000576.\n",
      " Top K precision = 0.01, recall = 0.005271450685537373.\n",
      "Training on epoch 14 minibatch 3601/5000 completed\n",
      " bpr_loss on current minibatch is 0.69377, and regularization loss is 0.000623.\n",
      " Top K precision = 0.013333333333333332, recall = 0.009213529318792475.\n",
      "Training on epoch 14 minibatch 3701/5000 completed\n",
      " bpr_loss on current minibatch is 0.693796, and regularization loss is 0.000649.\n",
      " Top K precision = 0.020689655172413793, recall = 0.0070061603209545355.\n",
      "Training on epoch 14 minibatch 3801/5000 completed\n",
      " bpr_loss on current minibatch is 0.693992, and regularization loss is 0.000845.\n",
      " Top K precision = 0.01206896551724138, recall = 0.006677300642817883.\n",
      "Training on epoch 14 minibatch 3901/5000 completed\n",
      " bpr_loss on current minibatch is 0.693736, and regularization loss is 0.000589.\n",
      " Top K precision = 0.008620689655172414, recall = 0.0033031675736058842.\n",
      "Training on epoch 14 minibatch 4001/5000 completed\n",
      " bpr_loss on current minibatch is 0.693691, and regularization loss is 0.000544.\n",
      " Top K precision = 0.010344827586206896, recall = 0.005190702496736979.\n",
      "Training on epoch 14 minibatch 4101/5000 completed\n",
      " bpr_loss on current minibatch is 0.69383, and regularization loss is 0.000683.\n",
      " Top K precision = 0.011666666666666665, recall = 0.0066998293570301685.\n",
      "Training on epoch 14 minibatch 4201/5000 completed\n",
      " bpr_loss on current minibatch is 0.693723, and regularization loss is 0.000576.\n",
      " Top K precision = 0.006666666666666667, recall = 0.0037274453941120605.\n",
      "Training on epoch 14 minibatch 4301/5000 completed\n",
      " bpr_loss on current minibatch is 0.693874, and regularization loss is 0.000727.\n",
      " Top K precision = 0.011864406779661016, recall = 0.004488903657804646.\n",
      "Training on epoch 14 minibatch 4401/5000 completed\n",
      " bpr_loss on current minibatch is 0.693839, and regularization loss is 0.000691.\n",
      " Top K precision = 0.013333333333333332, recall = 0.004934194532878744.\n",
      "Training on epoch 14 minibatch 4501/5000 completed\n",
      " bpr_loss on current minibatch is 0.693917, and regularization loss is 0.00077.\n",
      " Top K precision = 0.011666666666666665, recall = 0.005521569074200653.\n",
      "Training on epoch 14 minibatch 4601/5000 completed\n",
      " bpr_loss on current minibatch is 0.693633, and regularization loss is 0.000486.\n",
      " Top K precision = 0.021666666666666667, recall = 0.007109600988313021.\n",
      "Training on epoch 14 minibatch 4701/5000 completed\n",
      " bpr_loss on current minibatch is 0.693855, and regularization loss is 0.000708.\n",
      " Top K precision = 0.006779661016949153, recall = 0.0027688099721998025.\n",
      "Training on epoch 14 minibatch 4801/5000 completed\n",
      " bpr_loss on current minibatch is 0.693831, and regularization loss is 0.000684.\n",
      " Top K precision = 0.013333333333333332, recall = 0.007206099041625357.\n",
      "Training on epoch 14 minibatch 4901/5000 completed\n",
      " bpr_loss on current minibatch is 0.693909, and regularization loss is 0.000762.\n",
      " Top K precision = 0.006666666666666667, recall = 0.004200336700336701.\n",
      "\n",
      "Training on 14 epoch completed.\n",
      " Average bpr_loss on train set is 0.011563 for the current epoch.\n",
      " Training top K precision = 0.013166666666666745, recall = 0.005441901608698142.\n",
      " Average bpr_loss on the validation set is 2e-06, and regularization loss is 0.0.\n",
      " Validation top K precision = 0.014266666666666762, recall = 0.005921096370478801.\n",
      "\n",
      "Training on the 15 epoch\n",
      "Training on epoch 15 minibatch 1/5000 completed\n",
      " bpr_loss on current minibatch is 0.693788, and regularization loss is 0.00064.\n",
      " Top K precision = 0.018965517241379307, recall = 0.00963800475892655.\n",
      "Training on epoch 15 minibatch 101/5000 completed\n",
      " bpr_loss on current minibatch is 0.693855, and regularization loss is 0.000707.\n",
      " Top K precision = 0.016666666666666666, recall = 0.009688337511794735.\n",
      "Training on epoch 15 minibatch 201/5000 completed\n",
      " bpr_loss on current minibatch is 0.693724, and regularization loss is 0.000577.\n",
      " Top K precision = 0.01, recall = 0.003389704669196502.\n",
      "Training on epoch 15 minibatch 301/5000 completed\n",
      " bpr_loss on current minibatch is 0.693771, and regularization loss is 0.000624.\n",
      " Top K precision = 0.011666666666666665, recall = 0.0062668510615829405.\n",
      "Training on epoch 15 minibatch 401/5000 completed\n",
      " bpr_loss on current minibatch is 0.693857, and regularization loss is 0.00071.\n",
      " Top K precision = 0.01, recall = 0.00507847277243829.\n",
      "Training on epoch 15 minibatch 501/5000 completed\n",
      " bpr_loss on current minibatch is 0.693803, and regularization loss is 0.000655.\n",
      " Top K precision = 0.011666666666666665, recall = 0.004276616516199849.\n",
      "Training on epoch 15 minibatch 601/5000 completed\n",
      " bpr_loss on current minibatch is 0.693695, and regularization loss is 0.000547.\n",
      " Top K precision = 0.014999999999999998, recall = 0.008075438450438451.\n",
      "Training on epoch 15 minibatch 701/5000 completed\n",
      " bpr_loss on current minibatch is 0.693822, and regularization loss is 0.000675.\n",
      " Top K precision = 0.006666666666666667, recall = 0.0016108667318344737.\n",
      "Training on epoch 15 minibatch 801/5000 completed\n",
      " bpr_loss on current minibatch is 0.693764, and regularization loss is 0.000617.\n",
      " Top K precision = 0.006666666666666667, recall = 0.0023774597558321574.\n",
      "Training on epoch 15 minibatch 901/5000 completed\n",
      " bpr_loss on current minibatch is 0.693937, and regularization loss is 0.00079.\n",
      " Top K precision = 0.015254237288135592, recall = 0.007500104233291768.\n",
      "Training on epoch 15 minibatch 1001/5000 completed\n",
      " bpr_loss on current minibatch is 0.693749, and regularization loss is 0.000602.\n",
      " Top K precision = 0.010169491525423728, recall = 0.0061131579834808785.\n",
      "Training on epoch 15 minibatch 1101/5000 completed\n",
      " bpr_loss on current minibatch is 0.693802, and regularization loss is 0.000655.\n",
      " Top K precision = 0.01, recall = 0.0037121566858536606.\n",
      "Training on epoch 15 minibatch 1201/5000 completed\n",
      " bpr_loss on current minibatch is 0.693715, and regularization loss is 0.000568.\n",
      " Top K precision = 0.013333333333333332, recall = 0.005748560014864362.\n",
      "Training on epoch 15 minibatch 1301/5000 completed\n",
      " bpr_loss on current minibatch is 0.693737, and regularization loss is 0.00059.\n",
      " Top K precision = 0.008620689655172414, recall = 0.002997121982302566.\n",
      "Training on epoch 15 minibatch 1401/5000 completed\n",
      " bpr_loss on current minibatch is 0.693825, and regularization loss is 0.000678.\n",
      " Top K precision = 0.013333333333333334, recall = 0.007852766106442578.\n",
      "Training on epoch 15 minibatch 1501/5000 completed\n",
      " bpr_loss on current minibatch is 0.694056, and regularization loss is 0.000909.\n",
      " Top K precision = 0.015000000000000001, recall = 0.004709764156826.\n",
      "Training on epoch 15 minibatch 1601/5000 completed\n",
      " bpr_loss on current minibatch is 0.693802, and regularization loss is 0.000655.\n",
      " Top K precision = 0.008620689655172414, recall = 0.005510767730950743.\n",
      "Training on epoch 15 minibatch 1701/5000 completed\n",
      " bpr_loss on current minibatch is 0.693723, and regularization loss is 0.000576.\n",
      " Top K precision = 0.010344827586206896, recall = 0.0060812032794791415.\n",
      "Training on epoch 15 minibatch 1801/5000 completed\n",
      " bpr_loss on current minibatch is 0.6939, and regularization loss is 0.000752.\n",
      " Top K precision = 0.018644067796610167, recall = 0.007248345277279071.\n",
      "Training on epoch 15 minibatch 1901/5000 completed\n",
      " bpr_loss on current minibatch is 0.693862, and regularization loss is 0.000715.\n",
      " Top K precision = 0.00847457627118644, recall = 0.0032973931279016025.\n",
      "Training on epoch 15 minibatch 2001/5000 completed\n",
      " bpr_loss on current minibatch is 0.693907, and regularization loss is 0.00076.\n",
      " Top K precision = 0.011666666666666665, recall = 0.006099579032331672.\n",
      "Training on epoch 15 minibatch 2101/5000 completed\n",
      " bpr_loss on current minibatch is 0.693714, and regularization loss is 0.000567.\n",
      " Top K precision = 0.006666666666666667, recall = 0.0020394420394420393.\n",
      "Training on epoch 15 minibatch 2201/5000 completed\n",
      " bpr_loss on current minibatch is 0.693724, and regularization loss is 0.000577.\n",
      " Top K precision = 0.016666666666666666, recall = 0.006270900346169163.\n",
      "Training on epoch 15 minibatch 2301/5000 completed\n",
      " bpr_loss on current minibatch is 0.693565, and regularization loss is 0.000418.\n",
      " Top K precision = 0.01206896551724138, recall = 0.005389513441587015.\n",
      "Training on epoch 15 minibatch 2401/5000 completed\n",
      " bpr_loss on current minibatch is 0.693793, and regularization loss is 0.000646.\n",
      " Top K precision = 0.005000000000000001, recall = 0.0028808148373365766.\n",
      "Training on epoch 15 minibatch 2501/5000 completed\n",
      " bpr_loss on current minibatch is 0.693858, and regularization loss is 0.000711.\n",
      " Top K precision = 0.01, recall = 0.004613270977687454.\n",
      "Training on epoch 15 minibatch 2601/5000 completed\n",
      " bpr_loss on current minibatch is 0.693727, and regularization loss is 0.000579.\n",
      " Top K precision = 0.011864406779661017, recall = 0.006083643010362851.\n",
      "Training on epoch 15 minibatch 2701/5000 completed\n",
      " bpr_loss on current minibatch is 0.693713, and regularization loss is 0.000566.\n",
      " Top K precision = 0.014999999999999998, recall = 0.008404537456008046.\n",
      "Training on epoch 15 minibatch 2801/5000 completed\n",
      " bpr_loss on current minibatch is 0.693735, and regularization loss is 0.000588.\n",
      " Top K precision = 0.016949152542372878, recall = 0.005492760932095104.\n",
      "Training on epoch 15 minibatch 2901/5000 completed\n",
      " bpr_loss on current minibatch is 0.693831, and regularization loss is 0.000684.\n",
      " Top K precision = 0.011864406779661016, recall = 0.0037629176297536734.\n",
      "Training on epoch 15 minibatch 3001/5000 completed\n",
      " bpr_loss on current minibatch is 0.693776, and regularization loss is 0.000629.\n",
      " Top K precision = 0.013559322033898305, recall = 0.006396276133837643.\n",
      "Training on epoch 15 minibatch 3101/5000 completed\n",
      " bpr_loss on current minibatch is 0.693757, and regularization loss is 0.00061.\n",
      " Top K precision = 0.0033333333333333335, recall = 0.0005897435897435898.\n",
      "Training on epoch 15 minibatch 3201/5000 completed\n",
      " bpr_loss on current minibatch is 0.693834, and regularization loss is 0.000687.\n",
      " Top K precision = 0.005000000000000001, recall = 0.003346653346653347.\n",
      "Training on epoch 15 minibatch 3301/5000 completed\n",
      " bpr_loss on current minibatch is 0.693721, and regularization loss is 0.000574.\n",
      " Top K precision = 0.00847457627118644, recall = 0.0030871663375097217.\n",
      "Training on epoch 15 minibatch 3401/5000 completed\n",
      " bpr_loss on current minibatch is 0.693718, and regularization loss is 0.000571.\n",
      " Top K precision = 0.010169491525423728, recall = 0.004586373204203922.\n",
      "Training on epoch 15 minibatch 3501/5000 completed\n",
      " bpr_loss on current minibatch is 0.693738, and regularization loss is 0.00059.\n",
      " Top K precision = 0.01, recall = 0.005204046427955346.\n",
      "Training on epoch 15 minibatch 3601/5000 completed\n",
      " bpr_loss on current minibatch is 0.693902, and regularization loss is 0.000755.\n",
      " Top K precision = 0.00847457627118644, recall = 0.0032555026275995855.\n",
      "Training on epoch 15 minibatch 3701/5000 completed\n",
      " bpr_loss on current minibatch is 0.693746, and regularization loss is 0.000599.\n",
      " Top K precision = 0.006779661016949153, recall = 0.0025383373688458435.\n",
      "Training on epoch 15 minibatch 3801/5000 completed\n",
      " bpr_loss on current minibatch is 0.69377, and regularization loss is 0.000623.\n",
      " Top K precision = 0.01016949152542373, recall = 0.004985450441508634.\n",
      "Training on epoch 15 minibatch 3901/5000 completed\n",
      " bpr_loss on current minibatch is 0.693795, and regularization loss is 0.000648.\n",
      " Top K precision = 0.01, recall = 0.004714717046238785.\n",
      "Training on epoch 15 minibatch 4001/5000 completed\n",
      " bpr_loss on current minibatch is 0.69395, and regularization loss is 0.000803.\n",
      " Top K precision = 0.011864406779661016, recall = 0.006513300833492432.\n",
      "Training on epoch 15 minibatch 4101/5000 completed\n",
      " bpr_loss on current minibatch is 0.693728, and regularization loss is 0.000581.\n",
      " Top K precision = 0.013559322033898305, recall = 0.0058230401651992655.\n",
      "Training on epoch 15 minibatch 4201/5000 completed\n",
      " bpr_loss on current minibatch is 0.693779, and regularization loss is 0.000632.\n",
      " Top K precision = 0.006666666666666667, recall = 0.001913179413179413.\n",
      "Training on epoch 15 minibatch 4301/5000 completed\n",
      " bpr_loss on current minibatch is 0.693846, and regularization loss is 0.000699.\n",
      " Top K precision = 0.010169491525423728, recall = 0.0037621111025896666.\n",
      "Training on epoch 15 minibatch 4401/5000 completed\n",
      " bpr_loss on current minibatch is 0.693788, and regularization loss is 0.000641.\n",
      " Top K precision = 0.01833333333333333, recall = 0.008975596131491832.\n",
      "Training on epoch 15 minibatch 4501/5000 completed\n",
      " bpr_loss on current minibatch is 0.693785, and regularization loss is 0.000638.\n",
      " Top K precision = 0.008333333333333333, recall = 0.0033912037037037036.\n",
      "Training on epoch 15 minibatch 4601/5000 completed\n",
      " bpr_loss on current minibatch is 0.694027, and regularization loss is 0.00088.\n",
      " Top K precision = 0.010169491525423728, recall = 0.005363451604090153.\n",
      "Training on epoch 15 minibatch 4701/5000 completed\n",
      " bpr_loss on current minibatch is 0.693757, and regularization loss is 0.00061.\n",
      " Top K precision = 0.01, recall = 0.006334367792701126.\n",
      "Training on epoch 15 minibatch 4801/5000 completed\n",
      " bpr_loss on current minibatch is 0.693891, and regularization loss is 0.000744.\n",
      " Top K precision = 0.00847457627118644, recall = 0.0028764625028649855.\n",
      "Training on epoch 15 minibatch 4901/5000 completed\n",
      " bpr_loss on current minibatch is 0.693861, and regularization loss is 0.000714.\n",
      " Top K precision = 0.01, recall = 0.00444680233766921.\n",
      "\n",
      "Training on 15 epoch completed.\n",
      " Average bpr_loss on train set is 0.011563 for the current epoch.\n",
      " Training top K precision = 0.014933333333333439, recall = 0.006516247132118232.\n",
      " Average bpr_loss on the validation set is 2e-06, and regularization loss is 0.0.\n",
      " Validation top K precision = 0.013700000000000092, recall = 0.006500560970465168.\n",
      "\n",
      "Training on the 16 epoch\n",
      "Training on epoch 16 minibatch 1/5000 completed\n",
      " bpr_loss on current minibatch is 0.69371, and regularization loss is 0.000563.\n",
      " Top K precision = 0.01, recall = 0.003723537900008488.\n",
      "Training on epoch 16 minibatch 101/5000 completed\n",
      " bpr_loss on current minibatch is 0.693819, and regularization loss is 0.000672.\n",
      " Top K precision = 0.013333333333333332, recall = 0.006842864168403081.\n",
      "Training on epoch 16 minibatch 201/5000 completed\n",
      " bpr_loss on current minibatch is 0.693877, and regularization loss is 0.00073.\n",
      " Top K precision = 0.010344827586206896, recall = 0.0038947482913000153.\n",
      "Training on epoch 16 minibatch 301/5000 completed\n",
      " bpr_loss on current minibatch is 0.693879, and regularization loss is 0.000732.\n",
      " Top K precision = 0.01694915254237288, recall = 0.006420199197844523.\n",
      "Training on epoch 16 minibatch 401/5000 completed\n",
      " bpr_loss on current minibatch is 0.69398, and regularization loss is 0.000833.\n",
      " Top K precision = 0.014999999999999998, recall = 0.005068470484551047.\n",
      "Training on epoch 16 minibatch 501/5000 completed\n",
      " bpr_loss on current minibatch is 0.693775, and regularization loss is 0.000628.\n",
      " Top K precision = 0.011666666666666665, recall = 0.004628911140539048.\n",
      "Training on epoch 16 minibatch 601/5000 completed\n",
      " bpr_loss on current minibatch is 0.693798, and regularization loss is 0.000651.\n",
      " Top K precision = 0.01379310344827586, recall = 0.007010657872726838.\n",
      "Training on epoch 16 minibatch 701/5000 completed\n",
      " bpr_loss on current minibatch is 0.693662, and regularization loss is 0.000514.\n",
      " Top K precision = 0.014999999999999998, recall = 0.004252789677461063.\n",
      "Training on epoch 16 minibatch 801/5000 completed\n",
      " bpr_loss on current minibatch is 0.693729, and regularization loss is 0.000582.\n",
      " Top K precision = 0.021666666666666667, recall = 0.01064440682087741.\n",
      "Training on epoch 16 minibatch 901/5000 completed\n",
      " bpr_loss on current minibatch is 0.693734, and regularization loss is 0.000586.\n",
      " Top K precision = 0.013333333333333332, recall = 0.005871859621859623.\n",
      "Training on epoch 16 minibatch 1001/5000 completed\n",
      " bpr_loss on current minibatch is 0.693891, and regularization loss is 0.000744.\n",
      " Top K precision = 0.016666666666666666, recall = 0.006936548718282464.\n",
      "Training on epoch 16 minibatch 1101/5000 completed\n",
      " bpr_loss on current minibatch is 0.693866, and regularization loss is 0.000718.\n",
      " Top K precision = 0.013559322033898306, recall = 0.006429099797382046.\n",
      "Training on epoch 16 minibatch 1201/5000 completed\n",
      " bpr_loss on current minibatch is 0.693808, and regularization loss is 0.000661.\n",
      " Top K precision = 0.00847457627118644, recall = 0.003840657072821046.\n",
      "Training on epoch 16 minibatch 1301/5000 completed\n",
      " bpr_loss on current minibatch is 0.693773, and regularization loss is 0.000625.\n",
      " Top K precision = 0.008333333333333333, recall = 0.0021540496540496537.\n",
      "Training on epoch 16 minibatch 1401/5000 completed\n",
      " bpr_loss on current minibatch is 0.69367, and regularization loss is 0.000522.\n",
      " Top K precision = 0.013333333333333332, recall = 0.007251944392811266.\n",
      "Training on epoch 16 minibatch 1501/5000 completed\n",
      " bpr_loss on current minibatch is 0.693876, and regularization loss is 0.000729.\n",
      " Top K precision = 0.016949152542372878, recall = 0.006311238196831417.\n",
      "Training on epoch 16 minibatch 1601/5000 completed\n",
      " bpr_loss on current minibatch is 0.693697, and regularization loss is 0.000549.\n",
      " Top K precision = 0.00847457627118644, recall = 0.003460641180195765.\n",
      "Training on epoch 16 minibatch 1701/5000 completed\n",
      " bpr_loss on current minibatch is 0.693693, and regularization loss is 0.000546.\n",
      " Top K precision = 0.025000000000000005, recall = 0.013127565399843322.\n",
      "Training on epoch 16 minibatch 1801/5000 completed\n",
      " bpr_loss on current minibatch is 0.693669, and regularization loss is 0.000522.\n",
      " Top K precision = 0.015254237288135592, recall = 0.007575003788685419.\n",
      "Training on epoch 16 minibatch 1901/5000 completed\n",
      " bpr_loss on current minibatch is 0.693715, and regularization loss is 0.000568.\n",
      " Top K precision = 0.015517241379310343, recall = 0.009267241379310344.\n",
      "Training on epoch 16 minibatch 2001/5000 completed\n",
      " bpr_loss on current minibatch is 0.69388, and regularization loss is 0.000732.\n",
      " Top K precision = 0.010344827586206896, recall = 0.00437555545314166.\n",
      "Training on epoch 16 minibatch 2101/5000 completed\n",
      " bpr_loss on current minibatch is 0.693715, and regularization loss is 0.000567.\n",
      " Top K precision = 0.018333333333333333, recall = 0.00778805158989481.\n",
      "Training on epoch 16 minibatch 2201/5000 completed\n",
      " bpr_loss on current minibatch is 0.69372, and regularization loss is 0.000572.\n",
      " Top K precision = 0.01, recall = 0.004308954933954934.\n",
      "Training on epoch 16 minibatch 2301/5000 completed\n",
      " bpr_loss on current minibatch is 0.693877, and regularization loss is 0.00073.\n",
      " Top K precision = 0.01379310344827586, recall = 0.004754952358259118.\n",
      "Training on epoch 16 minibatch 2401/5000 completed\n",
      " bpr_loss on current minibatch is 0.693668, and regularization loss is 0.000521.\n",
      " Top K precision = 0.008333333333333333, recall = 0.005463486676721971.\n",
      "Training on epoch 16 minibatch 2501/5000 completed\n",
      " bpr_loss on current minibatch is 0.693825, and regularization loss is 0.000678.\n",
      " Top K precision = 0.01864406779661017, recall = 0.007358689846623221.\n",
      "Training on epoch 16 minibatch 2601/5000 completed\n",
      " bpr_loss on current minibatch is 0.693787, and regularization loss is 0.00064.\n",
      " Top K precision = 0.020338983050847456, recall = 0.008477636836307293.\n",
      "Training on epoch 16 minibatch 2701/5000 completed\n",
      " bpr_loss on current minibatch is 0.693813, and regularization loss is 0.000666.\n",
      " Top K precision = 0.01, recall = 0.0051850677160575395.\n",
      "Training on epoch 16 minibatch 2801/5000 completed\n",
      " bpr_loss on current minibatch is 0.693715, and regularization loss is 0.000568.\n",
      " Top K precision = 0.011666666666666665, recall = 0.005536862371947502.\n",
      "Training on epoch 16 minibatch 2901/5000 completed\n",
      " bpr_loss on current minibatch is 0.694049, and regularization loss is 0.000902.\n",
      " Top K precision = 0.008333333333333333, recall = 0.005537015848800745.\n",
      "Training on epoch 16 minibatch 3001/5000 completed\n",
      " bpr_loss on current minibatch is 0.693749, and regularization loss is 0.000602.\n",
      " Top K precision = 0.013559322033898305, recall = 0.004530664654994898.\n",
      "Training on epoch 16 minibatch 3101/5000 completed\n",
      " bpr_loss on current minibatch is 0.693772, and regularization loss is 0.000625.\n",
      " Top K precision = 0.016666666666666666, recall = 0.007260949084361887.\n",
      "Training on epoch 16 minibatch 3201/5000 completed\n",
      " bpr_loss on current minibatch is 0.693724, and regularization loss is 0.000577.\n",
      " Top K precision = 0.013333333333333332, recall = 0.0039038461538461536.\n",
      "Training on epoch 16 minibatch 3301/5000 completed\n",
      " bpr_loss on current minibatch is 0.693929, and regularization loss is 0.000782.\n",
      " Top K precision = 0.016666666666666666, recall = 0.004293860456999282.\n",
      "Training on epoch 16 minibatch 3401/5000 completed\n",
      " bpr_loss on current minibatch is 0.693806, and regularization loss is 0.000659.\n",
      " Top K precision = 0.010344827586206896, recall = 0.005431034482758621.\n",
      "Training on epoch 16 minibatch 3501/5000 completed\n",
      " bpr_loss on current minibatch is 0.693831, and regularization loss is 0.000684.\n",
      " Top K precision = 0.016666666666666666, recall = 0.00829175167200409.\n",
      "Training on epoch 16 minibatch 3601/5000 completed\n",
      " bpr_loss on current minibatch is 0.693663, and regularization loss is 0.000516.\n",
      " Top K precision = 0.01694915254237288, recall = 0.007412311471187475.\n",
      "Training on epoch 16 minibatch 3701/5000 completed\n",
      " bpr_loss on current minibatch is 0.693782, and regularization loss is 0.000635.\n",
      " Top K precision = 0.014999999999999998, recall = 0.0069341857287527914.\n",
      "Training on epoch 16 minibatch 3801/5000 completed\n",
      " bpr_loss on current minibatch is 0.693682, and regularization loss is 0.000534.\n",
      " Top K precision = 0.014999999999999998, recall = 0.008478189569306566.\n",
      "Training on epoch 16 minibatch 3901/5000 completed\n",
      " bpr_loss on current minibatch is 0.693906, and regularization loss is 0.000759.\n",
      " Top K precision = 0.013333333333333332, recall = 0.006242060337021576.\n",
      "Training on epoch 16 minibatch 4001/5000 completed\n",
      " bpr_loss on current minibatch is 0.693967, and regularization loss is 0.00082.\n",
      " Top K precision = 0.013333333333333332, recall = 0.005372915648402905.\n",
      "Training on epoch 16 minibatch 4101/5000 completed\n",
      " bpr_loss on current minibatch is 0.693902, and regularization loss is 0.000755.\n",
      " Top K precision = 0.015254237288135592, recall = 0.005971841922155795.\n",
      "Training on epoch 16 minibatch 4201/5000 completed\n",
      " bpr_loss on current minibatch is 0.693778, and regularization loss is 0.000631.\n",
      " Top K precision = 0.013333333333333332, recall = 0.005849672008208595.\n",
      "Training on epoch 16 minibatch 4301/5000 completed\n",
      " bpr_loss on current minibatch is 0.693815, and regularization loss is 0.000668.\n",
      " Top K precision = 0.0033333333333333335, recall = 0.0014190821256038647.\n",
      "Training on epoch 16 minibatch 4401/5000 completed\n",
      " bpr_loss on current minibatch is 0.693786, and regularization loss is 0.000639.\n",
      " Top K precision = 0.015254237288135592, recall = 0.007595656772320329.\n",
      "Training on epoch 16 minibatch 4501/5000 completed\n",
      " bpr_loss on current minibatch is 0.693693, and regularization loss is 0.000546.\n",
      " Top K precision = 0.011864406779661016, recall = 0.005679868274778053.\n",
      "Training on epoch 16 minibatch 4601/5000 completed\n",
      " bpr_loss on current minibatch is 0.693784, and regularization loss is 0.000636.\n",
      " Top K precision = 0.00847457627118644, recall = 0.0033082096490555323.\n",
      "Training on epoch 16 minibatch 4701/5000 completed\n",
      " bpr_loss on current minibatch is 0.69384, and regularization loss is 0.000692.\n",
      " Top K precision = 0.01, recall = 0.005722046196874571.\n",
      "Training on epoch 16 minibatch 4801/5000 completed\n",
      " bpr_loss on current minibatch is 0.693907, and regularization loss is 0.00076.\n",
      " Top K precision = 0.01, recall = 0.003216358804594099.\n",
      "Training on epoch 16 minibatch 4901/5000 completed\n",
      " bpr_loss on current minibatch is 0.693738, and regularization loss is 0.000591.\n",
      " Top K precision = 0.018644067796610167, recall = 0.00632790250970194.\n",
      "\n",
      "Training on 16 epoch completed.\n",
      " Average bpr_loss on train set is 0.011563 for the current epoch.\n",
      " Training top K precision = 0.014366666666666764, recall = 0.006574203812250643.\n",
      " Average bpr_loss on the validation set is 2e-06, and regularization loss is 0.0.\n",
      " Validation top K precision = 0.015600000000000116, recall = 0.00694915027485345.\n",
      "\n",
      "Training on the 17 epoch\n",
      "Training on epoch 17 minibatch 1/5000 completed\n",
      " bpr_loss on current minibatch is 0.693873, and regularization loss is 0.000725.\n",
      " Top K precision = 0.010169491525423728, recall = 0.0048112351907488235.\n",
      "Training on epoch 17 minibatch 101/5000 completed\n",
      " bpr_loss on current minibatch is 0.693793, and regularization loss is 0.000646.\n",
      " Top K precision = 0.011666666666666667, recall = 0.005460957647742544.\n",
      "Training on epoch 17 minibatch 201/5000 completed\n",
      " bpr_loss on current minibatch is 0.693781, and regularization loss is 0.000633.\n",
      " Top K precision = 0.014999999999999998, recall = 0.01010259391451342.\n",
      "Training on epoch 17 minibatch 301/5000 completed\n",
      " bpr_loss on current minibatch is 0.69391, and regularization loss is 0.000763.\n",
      " Top K precision = 0.01, recall = 0.0037122033174664753.\n",
      "Training on epoch 17 minibatch 401/5000 completed\n",
      " bpr_loss on current minibatch is 0.69397, and regularization loss is 0.000823.\n",
      " Top K precision = 0.015254237288135592, recall = 0.009645335311357837.\n",
      "Training on epoch 17 minibatch 501/5000 completed\n",
      " bpr_loss on current minibatch is 0.693805, and regularization loss is 0.000658.\n",
      " Top K precision = 0.01206896551724138, recall = 0.004200469457004496.\n",
      "Training on epoch 17 minibatch 601/5000 completed\n",
      " bpr_loss on current minibatch is 0.693781, and regularization loss is 0.000634.\n",
      " Top K precision = 0.010169491525423728, recall = 0.003916928708310082.\n",
      "Training on epoch 17 minibatch 701/5000 completed\n",
      " bpr_loss on current minibatch is 0.693717, and regularization loss is 0.00057.\n",
      " Top K precision = 0.013559322033898305, recall = 0.006656464324113551.\n",
      "Training on epoch 17 minibatch 801/5000 completed\n",
      " bpr_loss on current minibatch is 0.693768, and regularization loss is 0.000621.\n",
      " Top K precision = 0.016949152542372878, recall = 0.006620102791650717.\n",
      "Training on epoch 17 minibatch 901/5000 completed\n",
      " bpr_loss on current minibatch is 0.693734, and regularization loss is 0.000587.\n",
      " Top K precision = 0.01694915254237288, recall = 0.00635753446072489.\n",
      "Training on epoch 17 minibatch 1001/5000 completed\n",
      " bpr_loss on current minibatch is 0.693662, and regularization loss is 0.000515.\n",
      " Top K precision = 0.01206896551724138, recall = 0.003982908798129647.\n",
      "Training on epoch 17 minibatch 1101/5000 completed\n",
      " bpr_loss on current minibatch is 0.693646, and regularization loss is 0.000499.\n",
      " Top K precision = 0.011666666666666665, recall = 0.0031776556776556774.\n",
      "Training on epoch 17 minibatch 1201/5000 completed\n",
      " bpr_loss on current minibatch is 0.69368, and regularization loss is 0.000533.\n",
      " Top K precision = 0.011666666666666665, recall = 0.004209247542580876.\n",
      "Training on epoch 17 minibatch 1301/5000 completed\n",
      " bpr_loss on current minibatch is 0.693927, and regularization loss is 0.00078.\n",
      " Top K precision = 0.013333333333333332, recall = 0.006047244723715312.\n",
      "Training on epoch 17 minibatch 1401/5000 completed\n",
      " bpr_loss on current minibatch is 0.693661, and regularization loss is 0.000514.\n",
      " Top K precision = 0.011666666666666665, recall = 0.005602058102058102.\n",
      "Training on epoch 17 minibatch 1501/5000 completed\n",
      " bpr_loss on current minibatch is 0.694024, and regularization loss is 0.000877.\n",
      " Top K precision = 0.022033898305084745, recall = 0.008341450689438106.\n",
      "Training on epoch 17 minibatch 1601/5000 completed\n",
      " bpr_loss on current minibatch is 0.693689, and regularization loss is 0.000542.\n",
      " Top K precision = 0.01, recall = 0.0047075885409218745.\n",
      "Training on epoch 17 minibatch 1701/5000 completed\n",
      " bpr_loss on current minibatch is 0.693794, and regularization loss is 0.000647.\n",
      " Top K precision = 0.015254237288135594, recall = 0.005500587726279072.\n",
      "Training on epoch 17 minibatch 1801/5000 completed\n",
      " bpr_loss on current minibatch is 0.693714, and regularization loss is 0.000567.\n",
      " Top K precision = 0.011666666666666665, recall = 0.004288082229294261.\n",
      "Training on epoch 17 minibatch 1901/5000 completed\n",
      " bpr_loss on current minibatch is 0.693747, and regularization loss is 0.0006.\n",
      " Top K precision = 0.011864406779661016, recall = 0.005616816006299729.\n",
      "Training on epoch 17 minibatch 2001/5000 completed\n",
      " bpr_loss on current minibatch is 0.693809, and regularization loss is 0.000661.\n",
      " Top K precision = 0.01, recall = 0.003952252944188428.\n",
      "Training on epoch 17 minibatch 2101/5000 completed\n",
      " bpr_loss on current minibatch is 0.693844, and regularization loss is 0.000697.\n",
      " Top K precision = 0.01, recall = 0.003971431583386043.\n",
      "Training on epoch 17 minibatch 2201/5000 completed\n",
      " bpr_loss on current minibatch is 0.693787, and regularization loss is 0.00064.\n",
      " Top K precision = 0.006779661016949153, recall = 0.005104227547243327.\n",
      "Training on epoch 17 minibatch 2301/5000 completed\n",
      " bpr_loss on current minibatch is 0.693749, and regularization loss is 0.000602.\n",
      " Top K precision = 0.013333333333333332, recall = 0.007279302884566043.\n",
      "Training on epoch 17 minibatch 2401/5000 completed\n",
      " bpr_loss on current minibatch is 0.69369, and regularization loss is 0.000543.\n",
      " Top K precision = 0.01, recall = 0.005278989847955364.\n",
      "Training on epoch 17 minibatch 2501/5000 completed\n",
      " bpr_loss on current minibatch is 0.693871, and regularization loss is 0.000724.\n",
      " Top K precision = 0.011666666666666665, recall = 0.00615682894668402.\n",
      "Training on epoch 17 minibatch 2601/5000 completed\n",
      " bpr_loss on current minibatch is 0.693731, and regularization loss is 0.000584.\n",
      " Top K precision = 0.016666666666666666, recall = 0.005264926085162877.\n",
      "Training on epoch 17 minibatch 2701/5000 completed\n",
      " bpr_loss on current minibatch is 0.693792, and regularization loss is 0.000645.\n",
      " Top K precision = 0.016666666666666666, recall = 0.009013240481377737.\n",
      "Training on epoch 17 minibatch 2801/5000 completed\n",
      " bpr_loss on current minibatch is 0.693692, and regularization loss is 0.000545.\n",
      " Top K precision = 0.016666666666666666, recall = 0.0069372771166681816.\n",
      "Training on epoch 17 minibatch 2901/5000 completed\n",
      " bpr_loss on current minibatch is 0.69399, and regularization loss is 0.000843.\n",
      " Top K precision = 0.011666666666666667, recall = 0.005446443176706335.\n",
      "Training on epoch 17 minibatch 3001/5000 completed\n",
      " bpr_loss on current minibatch is 0.693909, and regularization loss is 0.000762.\n",
      " Top K precision = 0.011666666666666665, recall = 0.004049080371332185.\n",
      "Training on epoch 17 minibatch 3101/5000 completed\n",
      " bpr_loss on current minibatch is 0.693859, and regularization loss is 0.000712.\n",
      " Top K precision = 0.011666666666666665, recall = 0.004156530132761032.\n",
      "Training on epoch 17 minibatch 3201/5000 completed\n",
      " bpr_loss on current minibatch is 0.693878, and regularization loss is 0.000731.\n",
      " Top K precision = 0.006666666666666667, recall = 0.0019397508107185527.\n",
      "Training on epoch 17 minibatch 3301/5000 completed\n",
      " bpr_loss on current minibatch is 0.693609, and regularization loss is 0.000462.\n",
      " Top K precision = 0.015254237288135592, recall = 0.008187638821017432.\n",
      "Training on epoch 17 minibatch 3401/5000 completed\n",
      " bpr_loss on current minibatch is 0.693878, and regularization loss is 0.000731.\n",
      " Top K precision = 0.010344827586206896, recall = 0.004809493648897477.\n",
      "Training on epoch 17 minibatch 3501/5000 completed\n",
      " bpr_loss on current minibatch is 0.693802, and regularization loss is 0.000655.\n",
      " Top K precision = 0.013333333333333332, recall = 0.0031213142758732084.\n",
      "Training on epoch 17 minibatch 3601/5000 completed\n",
      " bpr_loss on current minibatch is 0.693735, and regularization loss is 0.000588.\n",
      " Top K precision = 0.011666666666666665, recall = 0.004147826334611231.\n",
      "Training on epoch 17 minibatch 3701/5000 completed\n",
      " bpr_loss on current minibatch is 0.693735, and regularization loss is 0.000588.\n",
      " Top K precision = 0.013333333333333332, recall = 0.0055094973109678985.\n",
      "Training on epoch 17 minibatch 3801/5000 completed\n",
      " bpr_loss on current minibatch is 0.693646, and regularization loss is 0.000499.\n",
      " Top K precision = 0.010169491525423728, recall = 0.004289381056904573.\n",
      "Training on epoch 17 minibatch 3901/5000 completed\n",
      " bpr_loss on current minibatch is 0.693703, and regularization loss is 0.000556.\n",
      " Top K precision = 0.00847457627118644, recall = 0.00541211674594136.\n",
      "Training on epoch 17 minibatch 4001/5000 completed\n",
      " bpr_loss on current minibatch is 0.693706, and regularization loss is 0.000559.\n",
      " Top K precision = 0.014999999999999998, recall = 0.006801336155351986.\n",
      "Training on epoch 17 minibatch 4101/5000 completed\n",
      " bpr_loss on current minibatch is 0.69372, and regularization loss is 0.000573.\n",
      " Top K precision = 0.008333333333333333, recall = 0.0034669100286949255.\n",
      "Training on epoch 17 minibatch 4201/5000 completed\n",
      " bpr_loss on current minibatch is 0.693753, and regularization loss is 0.000606.\n",
      " Top K precision = 0.011864406779661016, recall = 0.0047563335831789155.\n",
      "Training on epoch 17 minibatch 4301/5000 completed\n",
      " bpr_loss on current minibatch is 0.693901, and regularization loss is 0.000754.\n",
      " Top K precision = 0.010169491525423728, recall = 0.00429518447090378.\n",
      "Training on epoch 17 minibatch 4401/5000 completed\n",
      " bpr_loss on current minibatch is 0.693759, and regularization loss is 0.000612.\n",
      " Top K precision = 0.013559322033898305, recall = 0.007406266050333846.\n",
      "Training on epoch 17 minibatch 4501/5000 completed\n",
      " bpr_loss on current minibatch is 0.693703, and regularization loss is 0.000555.\n",
      " Top K precision = 0.014999999999999998, recall = 0.007981528904376303.\n",
      "Training on epoch 17 minibatch 4601/5000 completed\n",
      " bpr_loss on current minibatch is 0.693841, and regularization loss is 0.000694.\n",
      " Top K precision = 0.008333333333333333, recall = 0.003381634644337896.\n",
      "Training on epoch 17 minibatch 4701/5000 completed\n",
      " bpr_loss on current minibatch is 0.693876, and regularization loss is 0.000729.\n",
      " Top K precision = 0.016949152542372878, recall = 0.012660016908455802.\n",
      "Training on epoch 17 minibatch 4801/5000 completed\n",
      " bpr_loss on current minibatch is 0.693864, and regularization loss is 0.000717.\n",
      " Top K precision = 0.005000000000000001, recall = 0.002249858276643991.\n",
      "Training on epoch 17 minibatch 4901/5000 completed\n",
      " bpr_loss on current minibatch is 0.693825, and regularization loss is 0.000678.\n",
      " Top K precision = 0.011864406779661016, recall = 0.006756755894559875.\n",
      "\n",
      "Training on 17 epoch completed.\n",
      " Average bpr_loss on train set is 0.011563 for the current epoch.\n",
      " Training top K precision = 0.0142000000000001, recall = 0.006483584917138654.\n",
      " Average bpr_loss on the validation set is 2e-06, and regularization loss is 0.0.\n",
      " Validation top K precision = 0.015066666666666775, recall = 0.006559640023704737.\n",
      "\n",
      "Training on the 18 epoch\n",
      "Training on epoch 18 minibatch 1/5000 completed\n",
      " bpr_loss on current minibatch is 0.693664, and regularization loss is 0.000517.\n",
      " Top K precision = 0.013559322033898306, recall = 0.005052753579672821.\n",
      "Training on epoch 18 minibatch 101/5000 completed\n",
      " bpr_loss on current minibatch is 0.6937, and regularization loss is 0.000553.\n",
      " Top K precision = 0.008333333333333333, recall = 0.0039436026936026936.\n",
      "Training on epoch 18 minibatch 201/5000 completed\n",
      " bpr_loss on current minibatch is 0.693792, and regularization loss is 0.000644.\n",
      " Top K precision = 0.011666666666666665, recall = 0.007433993713485547.\n",
      "Training on epoch 18 minibatch 301/5000 completed\n",
      " bpr_loss on current minibatch is 0.694092, and regularization loss is 0.000945.\n",
      " Top K precision = 0.011666666666666665, recall = 0.005527136815867715.\n",
      "Training on epoch 18 minibatch 401/5000 completed\n",
      " bpr_loss on current minibatch is 0.693672, and regularization loss is 0.000525.\n",
      " Top K precision = 0.006896551724137932, recall = 0.002651028562171662.\n",
      "Training on epoch 18 minibatch 501/5000 completed\n",
      " bpr_loss on current minibatch is 0.69381, and regularization loss is 0.000663.\n",
      " Top K precision = 0.008333333333333333, recall = 0.002795390883626178.\n",
      "Training on epoch 18 minibatch 601/5000 completed\n",
      " bpr_loss on current minibatch is 0.693693, and regularization loss is 0.000546.\n",
      " Top K precision = 0.011864406779661016, recall = 0.002965970633247548.\n",
      "Training on epoch 18 minibatch 701/5000 completed\n",
      " bpr_loss on current minibatch is 0.69373, and regularization loss is 0.000583.\n",
      " Top K precision = 0.010344827586206896, recall = 0.005717962922927252.\n",
      "Training on epoch 18 minibatch 801/5000 completed\n",
      " bpr_loss on current minibatch is 0.693922, and regularization loss is 0.000774.\n",
      " Top K precision = 0.0033898305084745766, recall = 0.0032357473035439137.\n",
      "Training on epoch 18 minibatch 901/5000 completed\n",
      " bpr_loss on current minibatch is 0.693716, and regularization loss is 0.000569.\n",
      " Top K precision = 0.023728813559322035, recall = 0.007930819776261712.\n",
      "Training on epoch 18 minibatch 1001/5000 completed\n",
      " bpr_loss on current minibatch is 0.693731, and regularization loss is 0.000583.\n",
      " Top K precision = 0.014999999999999998, recall = 0.009345515595515597.\n",
      "Training on epoch 18 minibatch 1101/5000 completed\n",
      " bpr_loss on current minibatch is 0.694067, and regularization loss is 0.00092.\n",
      " Top K precision = 0.015000000000000001, recall = 0.007360244602891661.\n",
      "Training on epoch 18 minibatch 1201/5000 completed\n",
      " bpr_loss on current minibatch is 0.693697, and regularization loss is 0.00055.\n",
      " Top K precision = 0.02, recall = 0.010103667148424181.\n",
      "Training on epoch 18 minibatch 1301/5000 completed\n",
      " bpr_loss on current minibatch is 0.693849, and regularization loss is 0.000702.\n",
      " Top K precision = 0.013559322033898305, recall = 0.007345724585060591.\n",
      "Training on epoch 18 minibatch 1401/5000 completed\n",
      " bpr_loss on current minibatch is 0.693858, and regularization loss is 0.000711.\n",
      " Top K precision = 0.013793103448275864, recall = 0.007196718319207359.\n",
      "Training on epoch 18 minibatch 1501/5000 completed\n",
      " bpr_loss on current minibatch is 0.693798, and regularization loss is 0.000651.\n",
      " Top K precision = 0.011666666666666665, recall = 0.004133429251475067.\n",
      "Training on epoch 18 minibatch 1601/5000 completed\n",
      " bpr_loss on current minibatch is 0.693949, and regularization loss is 0.000802.\n",
      " Top K precision = 0.008333333333333333, recall = 0.003287735052724534.\n",
      "Training on epoch 18 minibatch 1701/5000 completed\n",
      " bpr_loss on current minibatch is 0.693796, and regularization loss is 0.000649.\n",
      " Top K precision = 0.01, recall = 0.005730311355311355.\n",
      "Training on epoch 18 minibatch 1801/5000 completed\n",
      " bpr_loss on current minibatch is 0.693731, and regularization loss is 0.000584.\n",
      " Top K precision = 0.014999999999999998, recall = 0.005789719148579156.\n",
      "Training on epoch 18 minibatch 1901/5000 completed\n",
      " bpr_loss on current minibatch is 0.693753, and regularization loss is 0.000605.\n",
      " Top K precision = 0.02, recall = 0.00981052717787173.\n",
      "Training on epoch 18 minibatch 2001/5000 completed\n",
      " bpr_loss on current minibatch is 0.693867, and regularization loss is 0.00072.\n",
      " Top K precision = 0.016666666666666666, recall = 0.00700989948725456.\n",
      "Training on epoch 18 minibatch 2101/5000 completed\n",
      " bpr_loss on current minibatch is 0.693876, and regularization loss is 0.000729.\n",
      " Top K precision = 0.01, recall = 0.0032550987642520823.\n",
      "Training on epoch 18 minibatch 2201/5000 completed\n",
      " bpr_loss on current minibatch is 0.693624, and regularization loss is 0.000477.\n",
      " Top K precision = 0.010000000000000002, recall = 0.00368769302592832.\n",
      "Training on epoch 18 minibatch 2301/5000 completed\n",
      " bpr_loss on current minibatch is 0.693756, and regularization loss is 0.000609.\n",
      " Top K precision = 0.02166666666666667, recall = 0.007154944871663138.\n",
      "Training on epoch 18 minibatch 2401/5000 completed\n",
      " bpr_loss on current minibatch is 0.693752, and regularization loss is 0.000605.\n",
      " Top K precision = 0.012280701754385965, recall = 0.005731402453164163.\n",
      "Training on epoch 18 minibatch 2501/5000 completed\n",
      " bpr_loss on current minibatch is 0.693637, and regularization loss is 0.000489.\n",
      " Top K precision = 0.011666666666666665, recall = 0.0063899985548536275.\n",
      "Training on epoch 18 minibatch 2601/5000 completed\n",
      " bpr_loss on current minibatch is 0.693941, and regularization loss is 0.000794.\n",
      " Top K precision = 0.008333333333333333, recall = 0.002044887044887045.\n",
      "Training on epoch 18 minibatch 2701/5000 completed\n",
      " bpr_loss on current minibatch is 0.693778, and regularization loss is 0.00063.\n",
      " Top K precision = 0.008620689655172414, recall = 0.003495605138607167.\n",
      "Training on epoch 18 minibatch 2801/5000 completed\n",
      " bpr_loss on current minibatch is 0.693997, and regularization loss is 0.00085.\n",
      " Top K precision = 0.011666666666666665, recall = 0.005011369673017771.\n",
      "Training on epoch 18 minibatch 2901/5000 completed\n",
      " bpr_loss on current minibatch is 0.693812, and regularization loss is 0.000665.\n",
      " Top K precision = 0.008333333333333333, recall = 0.003173701298701299.\n",
      "Training on epoch 18 minibatch 3001/5000 completed\n",
      " bpr_loss on current minibatch is 0.693713, and regularization loss is 0.000566.\n",
      " Top K precision = 0.013333333333333332, recall = 0.004521773312520341.\n",
      "Training on epoch 18 minibatch 3101/5000 completed\n",
      " bpr_loss on current minibatch is 0.693841, and regularization loss is 0.000694.\n",
      " Top K precision = 0.006666666666666667, recall = 0.0036802232854864438.\n",
      "Training on epoch 18 minibatch 3201/5000 completed\n",
      " bpr_loss on current minibatch is 0.693804, and regularization loss is 0.000656.\n",
      " Top K precision = 0.0033333333333333335, recall = 0.0012222222222222222.\n",
      "Training on epoch 18 minibatch 3301/5000 completed\n",
      " bpr_loss on current minibatch is 0.693806, and regularization loss is 0.000658.\n",
      " Top K precision = 0.018644067796610167, recall = 0.007822881671336308.\n",
      "Training on epoch 18 minibatch 3401/5000 completed\n",
      " bpr_loss on current minibatch is 0.693663, and regularization loss is 0.000516.\n",
      " Top K precision = 0.010169491525423728, recall = 0.0039920441467972785.\n",
      "Training on epoch 18 minibatch 3501/5000 completed\n",
      " bpr_loss on current minibatch is 0.693891, and regularization loss is 0.000744.\n",
      " Top K precision = 0.01, recall = 0.0039998885287510074.\n",
      "Training on epoch 18 minibatch 3601/5000 completed\n",
      " bpr_loss on current minibatch is 0.693767, and regularization loss is 0.00062.\n",
      " Top K precision = 0.011666666666666665, recall = 0.007866053946647371.\n",
      "Training on epoch 18 minibatch 3701/5000 completed\n",
      " bpr_loss on current minibatch is 0.693787, and regularization loss is 0.00064.\n",
      " Top K precision = 0.014999999999999998, recall = 0.005554703688796036.\n",
      "Training on epoch 18 minibatch 3801/5000 completed\n",
      " bpr_loss on current minibatch is 0.693928, and regularization loss is 0.00078.\n",
      " Top K precision = 0.015254237288135592, recall = 0.010636847890875285.\n",
      "Training on epoch 18 minibatch 3901/5000 completed\n",
      " bpr_loss on current minibatch is 0.69386, and regularization loss is 0.000712.\n",
      " Top K precision = 0.011666666666666665, recall = 0.003550473048456919.\n",
      "Training on epoch 18 minibatch 4001/5000 completed\n",
      " bpr_loss on current minibatch is 0.693763, and regularization loss is 0.000616.\n",
      " Top K precision = 0.011666666666666665, recall = 0.0034236237044055827.\n",
      "Training on epoch 18 minibatch 4101/5000 completed\n",
      " bpr_loss on current minibatch is 0.693806, and regularization loss is 0.000659.\n",
      " Top K precision = 0.01864406779661017, recall = 0.004537465228219053.\n",
      "Training on epoch 18 minibatch 4201/5000 completed\n",
      " bpr_loss on current minibatch is 0.693864, and regularization loss is 0.000717.\n",
      " Top K precision = 0.005084745762711865, recall = 0.001897725626539186.\n",
      "Training on epoch 18 minibatch 4301/5000 completed\n",
      " bpr_loss on current minibatch is 0.693707, and regularization loss is 0.00056.\n",
      " Top K precision = 0.013559322033898305, recall = 0.005715133418942652.\n",
      "Training on epoch 18 minibatch 4401/5000 completed\n",
      " bpr_loss on current minibatch is 0.69373, and regularization loss is 0.000583.\n",
      " Top K precision = 0.013333333333333332, recall = 0.005250668496104603.\n",
      "Training on epoch 18 minibatch 4501/5000 completed\n",
      " bpr_loss on current minibatch is 0.693693, and regularization loss is 0.000546.\n",
      " Top K precision = 0.020338983050847456, recall = 0.008299570635948599.\n",
      "Training on epoch 18 minibatch 4601/5000 completed\n",
      " bpr_loss on current minibatch is 0.69379, and regularization loss is 0.000643.\n",
      " Top K precision = 0.013559322033898305, recall = 0.005363195380936486.\n",
      "Training on epoch 18 minibatch 4701/5000 completed\n",
      " bpr_loss on current minibatch is 0.693678, and regularization loss is 0.000531.\n",
      " Top K precision = 0.008333333333333333, recall = 0.0037882933200270663.\n",
      "Training on epoch 18 minibatch 4801/5000 completed\n",
      " bpr_loss on current minibatch is 0.693832, and regularization loss is 0.000685.\n",
      " Top K precision = 0.01, recall = 0.00399203970632542.\n",
      "Training on epoch 18 minibatch 4901/5000 completed\n",
      " bpr_loss on current minibatch is 0.693871, and regularization loss is 0.000724.\n",
      " Top K precision = 0.00847457627118644, recall = 0.003306044211898079.\n",
      "\n",
      "Training on 18 epoch completed.\n",
      " Average bpr_loss on train set is 0.011563 for the current epoch.\n",
      " Training top K precision = 0.01566666666666678, recall = 0.006701123620879693.\n",
      " Average bpr_loss on the validation set is 2e-06, and regularization loss is 0.0.\n",
      " Validation top K precision = 0.014333333333333432, recall = 0.006428737364090366.\n",
      "\n",
      "Training on the 19 epoch\n",
      "Training on epoch 19 minibatch 1/5000 completed\n",
      " bpr_loss on current minibatch is 0.693875, and regularization loss is 0.000728.\n",
      " Top K precision = 0.02033898305084746, recall = 0.009103277377814233.\n",
      "Training on epoch 19 minibatch 101/5000 completed\n",
      " bpr_loss on current minibatch is 0.693829, and regularization loss is 0.000682.\n",
      " Top K precision = 0.011666666666666665, recall = 0.005575349668486923.\n",
      "Training on epoch 19 minibatch 201/5000 completed\n",
      " bpr_loss on current minibatch is 0.69373, and regularization loss is 0.000583.\n",
      " Top K precision = 0.010169491525423728, recall = 0.004506622817807684.\n",
      "Training on epoch 19 minibatch 301/5000 completed\n",
      " bpr_loss on current minibatch is 0.693787, and regularization loss is 0.000639.\n",
      " Top K precision = 0.01206896551724138, recall = 0.005573073166451775.\n",
      "Training on epoch 19 minibatch 401/5000 completed\n",
      " bpr_loss on current minibatch is 0.693943, and regularization loss is 0.000796.\n",
      " Top K precision = 0.011864406779661016, recall = 0.005408228776872845.\n",
      "Training on epoch 19 minibatch 501/5000 completed\n",
      " bpr_loss on current minibatch is 0.693749, and regularization loss is 0.000601.\n",
      " Top K precision = 0.005084745762711865, recall = 0.003500008284043276.\n",
      "Training on epoch 19 minibatch 601/5000 completed\n",
      " bpr_loss on current minibatch is 0.69374, and regularization loss is 0.000592.\n",
      " Top K precision = 0.011666666666666665, recall = 0.0025941738688449218.\n",
      "Training on epoch 19 minibatch 701/5000 completed\n",
      " bpr_loss on current minibatch is 0.69391, and regularization loss is 0.000762.\n",
      " Top K precision = 0.011666666666666665, recall = 0.003842973047017791.\n",
      "Training on epoch 19 minibatch 801/5000 completed\n",
      " bpr_loss on current minibatch is 0.693848, and regularization loss is 0.000701.\n",
      " Top K precision = 0.01, recall = 0.0074358974358974365.\n",
      "Training on epoch 19 minibatch 901/5000 completed\n",
      " bpr_loss on current minibatch is 0.693803, and regularization loss is 0.000656.\n",
      " Top K precision = 0.010344827586206896, recall = 0.006185002736726874.\n",
      "Training on epoch 19 minibatch 1001/5000 completed\n",
      " bpr_loss on current minibatch is 0.693855, and regularization loss is 0.000708.\n",
      " Top K precision = 0.016666666666666666, recall = 0.007672685821310633.\n",
      "Training on epoch 19 minibatch 1101/5000 completed\n",
      " bpr_loss on current minibatch is 0.693919, and regularization loss is 0.000772.\n",
      " Top K precision = 0.006779661016949153, recall = 0.0024325172630257374.\n",
      "Training on epoch 19 minibatch 1201/5000 completed\n",
      " bpr_loss on current minibatch is 0.693826, and regularization loss is 0.000678.\n",
      " Top K precision = 0.010169491525423728, recall = 0.003819190641418466.\n",
      "Training on epoch 19 minibatch 1301/5000 completed\n",
      " bpr_loss on current minibatch is 0.693599, and regularization loss is 0.000451.\n",
      " Top K precision = 0.01, recall = 0.004082635520734016.\n",
      "Training on epoch 19 minibatch 1401/5000 completed\n",
      " bpr_loss on current minibatch is 0.693771, and regularization loss is 0.000624.\n",
      " Top K precision = 0.008333333333333333, recall = 0.0033002067377067377.\n",
      "Training on epoch 19 minibatch 1501/5000 completed\n",
      " bpr_loss on current minibatch is 0.693896, and regularization loss is 0.000749.\n",
      " Top K precision = 0.015254237288135592, recall = 0.006614014498513177.\n",
      "Training on epoch 19 minibatch 1601/5000 completed\n",
      " bpr_loss on current minibatch is 0.693853, and regularization loss is 0.000706.\n",
      " Top K precision = 0.013333333333333332, recall = 0.0051582605524841075.\n",
      "Training on epoch 19 minibatch 1701/5000 completed\n",
      " bpr_loss on current minibatch is 0.693866, and regularization loss is 0.000718.\n",
      " Top K precision = 0.011666666666666665, recall = 0.008128561253561255.\n",
      "Training on epoch 19 minibatch 1801/5000 completed\n",
      " bpr_loss on current minibatch is 0.693661, and regularization loss is 0.000514.\n",
      " Top K precision = 0.006666666666666667, recall = 0.003828116328116328.\n",
      "Training on epoch 19 minibatch 1901/5000 completed\n",
      " bpr_loss on current minibatch is 0.693705, and regularization loss is 0.000558.\n",
      " Top K precision = 0.008333333333333333, recall = 0.005605505605505605.\n",
      "Training on epoch 19 minibatch 2001/5000 completed\n",
      " bpr_loss on current minibatch is 0.693963, and regularization loss is 0.000816.\n",
      " Top K precision = 0.010526315789473684, recall = 0.004085445094217024.\n",
      "Training on epoch 19 minibatch 2101/5000 completed\n",
      " bpr_loss on current minibatch is 0.693806, and regularization loss is 0.000659.\n",
      " Top K precision = 0.015254237288135592, recall = 0.006945245949135918.\n",
      "Training on epoch 19 minibatch 2201/5000 completed\n",
      " bpr_loss on current minibatch is 0.693694, and regularization loss is 0.000547.\n",
      " Top K precision = 0.016666666666666666, recall = 0.008291838084893238.\n",
      "Training on epoch 19 minibatch 2301/5000 completed\n",
      " bpr_loss on current minibatch is 0.693655, and regularization loss is 0.000508.\n",
      " Top K precision = 0.018644067796610167, recall = 0.009713646299643825.\n",
      "Training on epoch 19 minibatch 2401/5000 completed\n",
      " bpr_loss on current minibatch is 0.693861, and regularization loss is 0.000714.\n",
      " Top K precision = 0.013559322033898305, recall = 0.007733131650053652.\n",
      "Training on epoch 19 minibatch 2501/5000 completed\n",
      " bpr_loss on current minibatch is 0.693902, and regularization loss is 0.000755.\n",
      " Top K precision = 0.013333333333333332, recall = 0.004231608404463865.\n",
      "Training on epoch 19 minibatch 2601/5000 completed\n",
      " bpr_loss on current minibatch is 0.693877, and regularization loss is 0.00073.\n",
      " Top K precision = 0.01, recall = 0.0034244475237746484.\n",
      "Training on epoch 19 minibatch 2701/5000 completed\n",
      " bpr_loss on current minibatch is 0.693708, and regularization loss is 0.000561.\n",
      " Top K precision = 0.01, recall = 0.0029012927534432915.\n",
      "Training on epoch 19 minibatch 2801/5000 completed\n",
      " bpr_loss on current minibatch is 0.693774, and regularization loss is 0.000627.\n",
      " Top K precision = 0.015254237288135592, recall = 0.006011173681549651.\n",
      "Training on epoch 19 minibatch 2901/5000 completed\n",
      " bpr_loss on current minibatch is 0.693902, and regularization loss is 0.000755.\n",
      " Top K precision = 0.005000000000000001, recall = 0.004085982218974546.\n",
      "Training on epoch 19 minibatch 3001/5000 completed\n",
      " bpr_loss on current minibatch is 0.693995, and regularization loss is 0.000848.\n",
      " Top K precision = 0.021052631578947368, recall = 0.0073821904257610725.\n",
      "Training on epoch 19 minibatch 3101/5000 completed\n",
      " bpr_loss on current minibatch is 0.693812, and regularization loss is 0.000665.\n",
      " Top K precision = 0.011666666666666665, recall = 0.006701641270606787.\n",
      "Training on epoch 19 minibatch 3201/5000 completed\n",
      " bpr_loss on current minibatch is 0.69381, and regularization loss is 0.000663.\n",
      " Top K precision = 0.015000000000000001, recall = 0.007419524919524921.\n",
      "Training on epoch 19 minibatch 3301/5000 completed\n",
      " bpr_loss on current minibatch is 0.693695, and regularization loss is 0.000548.\n",
      " Top K precision = 0.01833333333333333, recall = 0.007745655903550641.\n",
      "Training on epoch 19 minibatch 3401/5000 completed\n",
      " bpr_loss on current minibatch is 0.693927, and regularization loss is 0.000779.\n",
      " Top K precision = 0.003448275862068966, recall = 0.0012745643307378568.\n",
      "Training on epoch 19 minibatch 3501/5000 completed\n",
      " bpr_loss on current minibatch is 0.69372, and regularization loss is 0.000573.\n",
      " Top K precision = 0.01379310344827586, recall = 0.004715814926186495.\n",
      "Training on epoch 19 minibatch 3601/5000 completed\n",
      " bpr_loss on current minibatch is 0.693675, and regularization loss is 0.000528.\n",
      " Top K precision = 0.015254237288135592, recall = 0.00621961547249655.\n",
      "Training on epoch 19 minibatch 3701/5000 completed\n",
      " bpr_loss on current minibatch is 0.693879, and regularization loss is 0.000732.\n",
      " Top K precision = 0.016949152542372878, recall = 0.0063564040231092.\n",
      "Training on epoch 19 minibatch 3801/5000 completed\n",
      " bpr_loss on current minibatch is 0.693758, and regularization loss is 0.000611.\n",
      " Top K precision = 0.016666666666666666, recall = 0.006557127615512163.\n",
      "Training on epoch 19 minibatch 3901/5000 completed\n",
      " bpr_loss on current minibatch is 0.693816, and regularization loss is 0.000669.\n",
      " Top K precision = 0.010344827586206896, recall = 0.003507220748600059.\n",
      "Training on epoch 19 minibatch 4001/5000 completed\n",
      " bpr_loss on current minibatch is 0.693773, and regularization loss is 0.000626.\n",
      " Top K precision = 0.01833333333333333, recall = 0.008197204172903434.\n",
      "Training on epoch 19 minibatch 4101/5000 completed\n",
      " bpr_loss on current minibatch is 0.693755, and regularization loss is 0.000608.\n",
      " Top K precision = 0.006666666666666667, recall = 0.0024685110211426.\n",
      "Training on epoch 19 minibatch 4201/5000 completed\n",
      " bpr_loss on current minibatch is 0.693829, and regularization loss is 0.000682.\n",
      " Top K precision = 0.018965517241379317, recall = 0.005851405467915102.\n",
      "Training on epoch 19 minibatch 4301/5000 completed\n",
      " bpr_loss on current minibatch is 0.693757, and regularization loss is 0.00061.\n",
      " Top K precision = 0.011864406779661016, recall = 0.0043569945364561515.\n",
      "Training on epoch 19 minibatch 4401/5000 completed\n",
      " bpr_loss on current minibatch is 0.693757, and regularization loss is 0.00061.\n",
      " Top K precision = 0.005084745762711865, recall = 0.002146629265273333.\n",
      "Training on epoch 19 minibatch 4501/5000 completed\n",
      " bpr_loss on current minibatch is 0.693697, and regularization loss is 0.00055.\n",
      " Top K precision = 0.01694915254237288, recall = 0.00476847524337697.\n",
      "Training on epoch 19 minibatch 4601/5000 completed\n",
      " bpr_loss on current minibatch is 0.693849, and regularization loss is 0.000702.\n",
      " Top K precision = 0.003448275862068966, recall = 0.0008319967923015236.\n",
      "Training on epoch 19 minibatch 4701/5000 completed\n",
      " bpr_loss on current minibatch is 0.693845, and regularization loss is 0.000698.\n",
      " Top K precision = 0.010169491525423728, recall = 0.005553298223674193.\n",
      "Training on epoch 19 minibatch 4801/5000 completed\n",
      " bpr_loss on current minibatch is 0.693929, and regularization loss is 0.000782.\n",
      " Top K precision = 0.020338983050847456, recall = 0.011299250358800594.\n",
      "Training on epoch 19 minibatch 4901/5000 completed\n",
      " bpr_loss on current minibatch is 0.693823, and regularization loss is 0.000676.\n",
      " Top K precision = 0.018644067796610167, recall = 0.008602719750814738.\n",
      "\n",
      "Training on 19 epoch completed.\n",
      " Average bpr_loss on train set is 0.011563 for the current epoch.\n",
      " Training top K precision = 0.01580000000000012, recall = 0.00684763087191334.\n",
      " Average bpr_loss on the validation set is 2e-06, and regularization loss is 0.0.\n",
      " Validation top K precision = 0.014466666666666773, recall = 0.006498327945480845.\n",
      "\n",
      "Training on the 20 epoch\n",
      "Training on epoch 20 minibatch 1/5000 completed\n",
      " bpr_loss on current minibatch is 0.693933, and regularization loss is 0.000786.\n",
      " Top K precision = 0.016666666666666666, recall = 0.005535887277115346.\n",
      "Training on epoch 20 minibatch 101/5000 completed\n",
      " bpr_loss on current minibatch is 0.693924, and regularization loss is 0.000777.\n",
      " Top K precision = 0.016949152542372878, recall = 0.00842116286685483.\n",
      "Training on epoch 20 minibatch 201/5000 completed\n",
      " bpr_loss on current minibatch is 0.693708, and regularization loss is 0.00056.\n",
      " Top K precision = 0.02166666666666667, recall = 0.006827301762438107.\n",
      "Training on epoch 20 minibatch 301/5000 completed\n",
      " bpr_loss on current minibatch is 0.693808, and regularization loss is 0.000661.\n",
      " Top K precision = 0.018644067796610167, recall = 0.00878880406548427.\n",
      "Training on epoch 20 minibatch 401/5000 completed\n",
      " bpr_loss on current minibatch is 0.693941, and regularization loss is 0.000794.\n",
      " Top K precision = 0.008333333333333333, recall = 0.00379983660130719.\n",
      "Training on epoch 20 minibatch 501/5000 completed\n",
      " bpr_loss on current minibatch is 0.693668, and regularization loss is 0.000521.\n",
      " Top K precision = 0.013559322033898305, recall = 0.0052088228939384616.\n",
      "Training on epoch 20 minibatch 601/5000 completed\n",
      " bpr_loss on current minibatch is 0.693927, and regularization loss is 0.000779.\n",
      " Top K precision = 0.013333333333333332, recall = 0.00504266289849273.\n",
      "Training on epoch 20 minibatch 701/5000 completed\n",
      " bpr_loss on current minibatch is 0.693868, and regularization loss is 0.000721.\n",
      " Top K precision = 0.017241379310344827, recall = 0.007589550339782477.\n",
      "Training on epoch 20 minibatch 801/5000 completed\n",
      " bpr_loss on current minibatch is 0.693762, and regularization loss is 0.000615.\n",
      " Top K precision = 0.013333333333333332, recall = 0.006355769230769232.\n",
      "Training on epoch 20 minibatch 901/5000 completed\n",
      " bpr_loss on current minibatch is 0.693889, and regularization loss is 0.000742.\n",
      " Top K precision = 0.010169491525423728, recall = 0.005598217653934602.\n",
      "Training on epoch 20 minibatch 1001/5000 completed\n",
      " bpr_loss on current minibatch is 0.693732, and regularization loss is 0.000585.\n",
      " Top K precision = 0.01833333333333333, recall = 0.009984441807854611.\n",
      "Training on epoch 20 minibatch 1101/5000 completed\n",
      " bpr_loss on current minibatch is 0.693776, and regularization loss is 0.000629.\n",
      " Top K precision = 0.008333333333333333, recall = 0.003962842712842712.\n",
      "Training on epoch 20 minibatch 1201/5000 completed\n",
      " bpr_loss on current minibatch is 0.693683, and regularization loss is 0.000536.\n",
      " Top K precision = 0.005000000000000001, recall = 0.0018513431013431013.\n",
      "Training on epoch 20 minibatch 1301/5000 completed\n",
      " bpr_loss on current minibatch is 0.69388, and regularization loss is 0.000733.\n",
      " Top K precision = 0.015254237288135592, recall = 0.005168598425504278.\n",
      "Training on epoch 20 minibatch 1401/5000 completed\n",
      " bpr_loss on current minibatch is 0.693837, and regularization loss is 0.00069.\n",
      " Top K precision = 0.010169491525423728, recall = 0.003845231980825201.\n",
      "Training on epoch 20 minibatch 1501/5000 completed\n",
      " bpr_loss on current minibatch is 0.693927, and regularization loss is 0.000779.\n",
      " Top K precision = 0.011666666666666665, recall = 0.00492832768655269.\n",
      "Training on epoch 20 minibatch 1601/5000 completed\n",
      " bpr_loss on current minibatch is 0.693801, and regularization loss is 0.000653.\n",
      " Top K precision = 0.018644067796610167, recall = 0.0086409641033812.\n",
      "Training on epoch 20 minibatch 1701/5000 completed\n",
      " bpr_loss on current minibatch is 0.693769, and regularization loss is 0.000622.\n",
      " Top K precision = 0.006666666666666667, recall = 0.0017670351003684335.\n",
      "Training on epoch 20 minibatch 1801/5000 completed\n",
      " bpr_loss on current minibatch is 0.693879, and regularization loss is 0.000732.\n",
      " Top K precision = 0.006779661016949153, recall = 0.0027489608221097964.\n",
      "Training on epoch 20 minibatch 1901/5000 completed\n",
      " bpr_loss on current minibatch is 0.693887, and regularization loss is 0.00074.\n",
      " Top K precision = 0.008333333333333333, recall = 0.0036957728700015447.\n",
      "Training on epoch 20 minibatch 2001/5000 completed\n",
      " bpr_loss on current minibatch is 0.693944, and regularization loss is 0.000797.\n",
      " Top K precision = 0.006896551724137932, recall = 0.002635877012011313.\n",
      "Training on epoch 20 minibatch 2101/5000 completed\n",
      " bpr_loss on current minibatch is 0.693764, and regularization loss is 0.000617.\n",
      " Top K precision = 0.013559322033898306, recall = 0.00494650259541632.\n",
      "Training on epoch 20 minibatch 2201/5000 completed\n",
      " bpr_loss on current minibatch is 0.693754, and regularization loss is 0.000607.\n",
      " Top K precision = 0.013333333333333332, recall = 0.0072067715975279.\n",
      "Training on epoch 20 minibatch 2301/5000 completed\n",
      " bpr_loss on current minibatch is 0.693808, and regularization loss is 0.000661.\n",
      " Top K precision = 0.010169491525423728, recall = 0.003486479549138255.\n",
      "Training on epoch 20 minibatch 2401/5000 completed\n",
      " bpr_loss on current minibatch is 0.693672, and regularization loss is 0.000525.\n",
      " Top K precision = 0.011666666666666665, recall = 0.004007252326217843.\n",
      "Training on epoch 20 minibatch 2501/5000 completed\n",
      " bpr_loss on current minibatch is 0.69375, and regularization loss is 0.000603.\n",
      " Top K precision = 0.015517241379310343, recall = 0.005263780618750193.\n",
      "Training on epoch 20 minibatch 2601/5000 completed\n",
      " bpr_loss on current minibatch is 0.693713, and regularization loss is 0.000566.\n",
      " Top K precision = 0.011666666666666665, recall = 0.004767988548638195.\n",
      "Training on epoch 20 minibatch 2701/5000 completed\n",
      " bpr_loss on current minibatch is 0.693727, and regularization loss is 0.00058.\n",
      " Top K precision = 0.006666666666666667, recall = 0.0016429476955792744.\n",
      "Training on epoch 20 minibatch 2801/5000 completed\n",
      " bpr_loss on current minibatch is 0.693783, and regularization loss is 0.000636.\n",
      " Top K precision = 0.008333333333333333, recall = 0.004634081196581197.\n",
      "Training on epoch 20 minibatch 2901/5000 completed\n",
      " bpr_loss on current minibatch is 0.693735, and regularization loss is 0.000588.\n",
      " Top K precision = 0.015254237288135594, recall = 0.008112026862026861.\n",
      "Training on epoch 20 minibatch 3001/5000 completed\n",
      " bpr_loss on current minibatch is 0.693751, and regularization loss is 0.000604.\n",
      " Top K precision = 0.006666666666666667, recall = 0.002578856328856329.\n",
      "Training on epoch 20 minibatch 3101/5000 completed\n",
      " bpr_loss on current minibatch is 0.693791, and regularization loss is 0.000644.\n",
      " Top K precision = 0.01, recall = 0.00525375092565762.\n",
      "Training on epoch 20 minibatch 3201/5000 completed\n",
      " bpr_loss on current minibatch is 0.693854, and regularization loss is 0.000707.\n",
      " Top K precision = 0.011666666666666665, recall = 0.0035883706936338513.\n",
      "Training on epoch 20 minibatch 3301/5000 completed\n",
      " bpr_loss on current minibatch is 0.693751, and regularization loss is 0.000603.\n",
      " Top K precision = 0.00847457627118644, recall = 0.004687878590394645.\n",
      "Training on epoch 20 minibatch 3401/5000 completed\n",
      " bpr_loss on current minibatch is 0.693716, and regularization loss is 0.000568.\n",
      " Top K precision = 0.013333333333333332, recall = 0.00789516683866529.\n",
      "Training on epoch 20 minibatch 3501/5000 completed\n",
      " bpr_loss on current minibatch is 0.693765, and regularization loss is 0.000618.\n",
      " Top K precision = 0.01, recall = 0.0025147532117640813.\n",
      "Training on epoch 20 minibatch 3601/5000 completed\n",
      " bpr_loss on current minibatch is 0.693846, and regularization loss is 0.000699.\n",
      " Top K precision = 0.01833333333333333, recall = 0.011911773616899974.\n",
      "Training on epoch 20 minibatch 3701/5000 completed\n",
      " bpr_loss on current minibatch is 0.693642, and regularization loss is 0.000495.\n",
      " Top K precision = 0.008333333333333333, recall = 0.0025746475746475745.\n",
      "Training on epoch 20 minibatch 3801/5000 completed\n",
      " bpr_loss on current minibatch is 0.693685, and regularization loss is 0.000537.\n",
      " Top K precision = 0.01, recall = 0.002711873377476748.\n",
      "Training on epoch 20 minibatch 3901/5000 completed\n",
      " bpr_loss on current minibatch is 0.693792, and regularization loss is 0.000645.\n",
      " Top K precision = 0.008333333333333333, recall = 0.003827614379084967.\n",
      "Training on epoch 20 minibatch 4001/5000 completed\n",
      " bpr_loss on current minibatch is 0.693827, and regularization loss is 0.000679.\n",
      " Top K precision = 0.005000000000000001, recall = 0.003088115588115588.\n",
      "Training on epoch 20 minibatch 4101/5000 completed\n",
      " bpr_loss on current minibatch is 0.693891, and regularization loss is 0.000744.\n",
      " Top K precision = 0.015517241379310343, recall = 0.005262160569636142.\n",
      "Training on epoch 20 minibatch 4201/5000 completed\n",
      " bpr_loss on current minibatch is 0.693902, and regularization loss is 0.000755.\n",
      " Top K precision = 0.005000000000000001, recall = 0.0020391218081435474.\n",
      "Training on epoch 20 minibatch 4301/5000 completed\n",
      " bpr_loss on current minibatch is 0.693677, and regularization loss is 0.00053.\n",
      " Top K precision = 0.014999999999999998, recall = 0.006870607838257503.\n",
      "Training on epoch 20 minibatch 4401/5000 completed\n",
      " bpr_loss on current minibatch is 0.693695, and regularization loss is 0.000548.\n",
      " Top K precision = 0.014999999999999998, recall = 0.007020207853541186.\n",
      "Training on epoch 20 minibatch 4501/5000 completed\n",
      " bpr_loss on current minibatch is 0.693772, and regularization loss is 0.000624.\n",
      " Top K precision = 0.01, recall = 0.006059796684796684.\n",
      "Training on epoch 20 minibatch 4601/5000 completed\n",
      " bpr_loss on current minibatch is 0.693961, and regularization loss is 0.000814.\n",
      " Top K precision = 0.016666666666666666, recall = 0.007108978983978984.\n",
      "Training on epoch 20 minibatch 4701/5000 completed\n",
      " bpr_loss on current minibatch is 0.693888, and regularization loss is 0.000741.\n",
      " Top K precision = 0.006666666666666667, recall = 0.002553793672214725.\n",
      "Training on epoch 20 minibatch 4801/5000 completed\n",
      " bpr_loss on current minibatch is 0.693836, and regularization loss is 0.000688.\n",
      " Top K precision = 0.008333333333333333, recall = 0.0036801966149792235.\n",
      "Training on epoch 20 minibatch 4901/5000 completed\n",
      " bpr_loss on current minibatch is 0.693848, and regularization loss is 0.000701.\n",
      " Top K precision = 0.013559322033898305, recall = 0.0078081755523026625.\n",
      "\n",
      "Training on 20 epoch completed.\n",
      " Average bpr_loss on train set is 0.011563 for the current epoch.\n",
      " Training top K precision = 0.015500000000000114, recall = 0.00696993857912209.\n",
      " Average bpr_loss on the validation set is 2e-06, and regularization loss is 0.0.\n",
      " Validation top K precision = 0.014800000000000106, recall = 0.006642193536755516.\n",
      "\n",
      "Training on the 21 epoch\n",
      "Training on epoch 21 minibatch 1/5000 completed\n",
      " bpr_loss on current minibatch is 0.693743, and regularization loss is 0.000596.\n",
      " Top K precision = 0.01, recall = 0.003991347251151173.\n",
      "Training on epoch 21 minibatch 101/5000 completed\n",
      " bpr_loss on current minibatch is 0.693955, and regularization loss is 0.000808.\n",
      " Top K precision = 0.006666666666666667, recall = 0.003998057498057498.\n",
      "Training on epoch 21 minibatch 201/5000 completed\n",
      " bpr_loss on current minibatch is 0.693746, and regularization loss is 0.000599.\n",
      " Top K precision = 0.005084745762711865, recall = 0.002169329332576433.\n",
      "Training on epoch 21 minibatch 301/5000 completed\n",
      " bpr_loss on current minibatch is 0.693897, and regularization loss is 0.00075.\n",
      " Top K precision = 0.013559322033898305, recall = 0.007006134635845969.\n",
      "Training on epoch 21 minibatch 401/5000 completed\n",
      " bpr_loss on current minibatch is 0.69359, and regularization loss is 0.000442.\n",
      " Top K precision = 0.01, recall = 0.00555894567336215.\n",
      "Training on epoch 21 minibatch 501/5000 completed\n",
      " bpr_loss on current minibatch is 0.693689, and regularization loss is 0.000542.\n",
      " Top K precision = 0.005084745762711865, recall = 0.002122496147919877.\n",
      "Training on epoch 21 minibatch 601/5000 completed\n",
      " bpr_loss on current minibatch is 0.69384, and regularization loss is 0.000693.\n",
      " Top K precision = 0.01, recall = 0.00387469964675847.\n",
      "Training on epoch 21 minibatch 701/5000 completed\n",
      " bpr_loss on current minibatch is 0.693929, and regularization loss is 0.000781.\n",
      " Top K precision = 0.0016666666666666668, recall = 0.0006666666666666666.\n",
      "Training on epoch 21 minibatch 801/5000 completed\n",
      " bpr_loss on current minibatch is 0.693788, and regularization loss is 0.000641.\n",
      " Top K precision = 0.006666666666666667, recall = 0.0031837606837606834.\n",
      "Training on epoch 21 minibatch 901/5000 completed\n",
      " bpr_loss on current minibatch is 0.693719, and regularization loss is 0.000572.\n",
      " Top K precision = 0.013333333333333332, recall = 0.006136972595305929.\n",
      "Training on epoch 21 minibatch 1001/5000 completed\n",
      " bpr_loss on current minibatch is 0.693698, and regularization loss is 0.000551.\n",
      " Top K precision = 0.011666666666666665, recall = 0.004969628422922042.\n",
      "Training on epoch 21 minibatch 1101/5000 completed\n",
      " bpr_loss on current minibatch is 0.693766, and regularization loss is 0.000619.\n",
      " Top K precision = 0.01, recall = 0.003808176691169019.\n",
      "Training on epoch 21 minibatch 1201/5000 completed\n",
      " bpr_loss on current minibatch is 0.693698, and regularization loss is 0.000551.\n",
      " Top K precision = 0.013333333333333332, recall = 0.008172244422244422.\n",
      "Training on epoch 21 minibatch 1301/5000 completed\n",
      " bpr_loss on current minibatch is 0.693761, and regularization loss is 0.000614.\n",
      " Top K precision = 0.008333333333333333, recall = 0.003521807140228193.\n",
      "Training on epoch 21 minibatch 1401/5000 completed\n",
      " bpr_loss on current minibatch is 0.693651, and regularization loss is 0.000504.\n",
      " Top K precision = 0.02, recall = 0.008012316688787276.\n",
      "Training on epoch 21 minibatch 1501/5000 completed\n",
      " bpr_loss on current minibatch is 0.693798, and regularization loss is 0.000651.\n",
      " Top K precision = 0.01, recall = 0.005123016603279762.\n",
      "Training on epoch 21 minibatch 1601/5000 completed\n",
      " bpr_loss on current minibatch is 0.693738, and regularization loss is 0.000591.\n",
      " Top K precision = 0.011666666666666665, recall = 0.005101612097579839.\n",
      "Training on epoch 21 minibatch 1701/5000 completed\n",
      " bpr_loss on current minibatch is 0.693799, and regularization loss is 0.000652.\n",
      " Top K precision = 0.014999999999999998, recall = 0.007037378879290643.\n",
      "Training on epoch 21 minibatch 1801/5000 completed\n",
      " bpr_loss on current minibatch is 0.693662, and regularization loss is 0.000514.\n",
      " Top K precision = 0.01206896551724138, recall = 0.004926284508121879.\n",
      "Training on epoch 21 minibatch 1901/5000 completed\n",
      " bpr_loss on current minibatch is 0.693709, and regularization loss is 0.000562.\n",
      " Top K precision = 0.01, recall = 0.0037888288125479774.\n",
      "Training on epoch 21 minibatch 2001/5000 completed\n",
      " bpr_loss on current minibatch is 0.693788, and regularization loss is 0.000641.\n",
      " Top K precision = 0.023333333333333334, recall = 0.009001136914867813.\n",
      "Training on epoch 21 minibatch 2101/5000 completed\n",
      " bpr_loss on current minibatch is 0.693824, and regularization loss is 0.000677.\n",
      " Top K precision = 0.008333333333333333, recall = 0.003436264671896856.\n",
      "Training on epoch 21 minibatch 2201/5000 completed\n",
      " bpr_loss on current minibatch is 0.693766, and regularization loss is 0.000619.\n",
      " Top K precision = 0.010169491525423728, recall = 0.004333268168813771.\n",
      "Training on epoch 21 minibatch 2301/5000 completed\n",
      " bpr_loss on current minibatch is 0.693863, and regularization loss is 0.000716.\n",
      " Top K precision = 0.02, recall = 0.007849679896362231.\n",
      "Training on epoch 21 minibatch 2401/5000 completed\n",
      " bpr_loss on current minibatch is 0.693676, and regularization loss is 0.000529.\n",
      " Top K precision = 0.013333333333333332, recall = 0.006802902979373567.\n",
      "Training on epoch 21 minibatch 2501/5000 completed\n",
      " bpr_loss on current minibatch is 0.693799, and regularization loss is 0.000652.\n",
      " Top K precision = 0.006666666666666667, recall = 0.003603059581320451.\n",
      "Training on epoch 21 minibatch 2601/5000 completed\n",
      " bpr_loss on current minibatch is 0.693815, and regularization loss is 0.000668.\n",
      " Top K precision = 0.006896551724137932, recall = 0.002592522420108627.\n",
      "Training on epoch 21 minibatch 2701/5000 completed\n",
      " bpr_loss on current minibatch is 0.693736, and regularization loss is 0.000588.\n",
      " Top K precision = 0.013559322033898305, recall = 0.004267921592345835.\n",
      "Training on epoch 21 minibatch 2801/5000 completed\n",
      " bpr_loss on current minibatch is 0.693712, and regularization loss is 0.000565.\n",
      " Top K precision = 0.015517241379310343, recall = 0.005349779421454649.\n",
      "Training on epoch 21 minibatch 2901/5000 completed\n",
      " bpr_loss on current minibatch is 0.693965, and regularization loss is 0.000818.\n",
      " Top K precision = 0.007407407407407408, recall = 0.002627995642701525.\n",
      "Training on epoch 21 minibatch 3001/5000 completed\n",
      " bpr_loss on current minibatch is 0.693784, and regularization loss is 0.000636.\n",
      " Top K precision = 0.014999999999999998, recall = 0.0062311198480109135.\n",
      "Training on epoch 21 minibatch 3101/5000 completed\n",
      " bpr_loss on current minibatch is 0.693859, and regularization loss is 0.000712.\n",
      " Top K precision = 0.011666666666666665, recall = 0.004335607537361923.\n",
      "Training on epoch 21 minibatch 3201/5000 completed\n",
      " bpr_loss on current minibatch is 0.69366, and regularization loss is 0.000513.\n",
      " Top K precision = 0.01206896551724138, recall = 0.00609410450941891.\n",
      "Training on epoch 21 minibatch 3301/5000 completed\n",
      " bpr_loss on current minibatch is 0.693872, and regularization loss is 0.000725.\n",
      " Top K precision = 0.00847457627118644, recall = 0.0021994213690495813.\n",
      "Training on epoch 21 minibatch 3401/5000 completed\n",
      " bpr_loss on current minibatch is 0.693987, and regularization loss is 0.000839.\n",
      " Top K precision = 0.01379310344827586, recall = 0.004682437088270394.\n",
      "Training on epoch 21 minibatch 3501/5000 completed\n",
      " bpr_loss on current minibatch is 0.693788, and regularization loss is 0.000641.\n",
      " Top K precision = 0.00847457627118644, recall = 0.0026602532240859195.\n",
      "Training on epoch 21 minibatch 3601/5000 completed\n",
      " bpr_loss on current minibatch is 0.693892, and regularization loss is 0.000745.\n",
      " Top K precision = 0.013333333333333332, recall = 0.005251938607201765.\n",
      "Training on epoch 21 minibatch 3701/5000 completed\n",
      " bpr_loss on current minibatch is 0.693802, and regularization loss is 0.000655.\n",
      " Top K precision = 0.018965517241379307, recall = 0.00817347594223862.\n",
      "Training on epoch 21 minibatch 3801/5000 completed\n",
      " bpr_loss on current minibatch is 0.693727, and regularization loss is 0.00058.\n",
      " Top K precision = 0.010344827586206896, recall = 0.004518759874930473.\n",
      "Training on epoch 21 minibatch 3901/5000 completed\n",
      " bpr_loss on current minibatch is 0.69373, and regularization loss is 0.000583.\n",
      " Top K precision = 0.01, recall = 0.0037935593817946755.\n",
      "Training on epoch 21 minibatch 4001/5000 completed\n",
      " bpr_loss on current minibatch is 0.69384, and regularization loss is 0.000693.\n",
      " Top K precision = 0.011864406779661016, recall = 0.0048757167650487696.\n",
      "Training on epoch 21 minibatch 4101/5000 completed\n",
      " bpr_loss on current minibatch is 0.693836, and regularization loss is 0.000689.\n",
      " Top K precision = 0.010169491525423728, recall = 0.0034190723102249395.\n",
      "Training on epoch 21 minibatch 4201/5000 completed\n",
      " bpr_loss on current minibatch is 0.693975, and regularization loss is 0.000828.\n",
      " Top K precision = 0.01833333333333333, recall = 0.008080382842846812.\n",
      "Training on epoch 21 minibatch 4301/5000 completed\n",
      " bpr_loss on current minibatch is 0.693733, and regularization loss is 0.000586.\n",
      " Top K precision = 0.00847457627118644, recall = 0.004335894801996497.\n",
      "Training on epoch 21 minibatch 4401/5000 completed\n",
      " bpr_loss on current minibatch is 0.693751, and regularization loss is 0.000604.\n",
      " Top K precision = 0.014999999999999998, recall = 0.007254799512791841.\n",
      "Training on epoch 21 minibatch 4501/5000 completed\n",
      " bpr_loss on current minibatch is 0.693687, and regularization loss is 0.000539.\n",
      " Top K precision = 0.01379310344827586, recall = 0.006600798626660694.\n",
      "Training on epoch 21 minibatch 4601/5000 completed\n",
      " bpr_loss on current minibatch is 0.693856, and regularization loss is 0.000709.\n",
      " Top K precision = 0.010169491525423728, recall = 0.006802332929947089.\n",
      "Training on epoch 21 minibatch 4701/5000 completed\n",
      " bpr_loss on current minibatch is 0.693759, and regularization loss is 0.000612.\n",
      " Top K precision = 0.018644067796610167, recall = 0.007557313487174016.\n",
      "Training on epoch 21 minibatch 4801/5000 completed\n",
      " bpr_loss on current minibatch is 0.693729, and regularization loss is 0.000582.\n",
      " Top K precision = 0.014999999999999998, recall = 0.004486861390834081.\n",
      "Training on epoch 21 minibatch 4901/5000 completed\n",
      " bpr_loss on current minibatch is 0.693772, and regularization loss is 0.000625.\n",
      " Top K precision = 0.006896551724137932, recall = 0.0028122283396117063.\n",
      "\n",
      "Training on 21 epoch completed.\n",
      " Average bpr_loss on train set is 0.011563 for the current epoch.\n",
      " Training top K precision = 0.01396666666666676, recall = 0.006034310657326706.\n",
      " Average bpr_loss on the validation set is 2e-06, and regularization loss is 0.0.\n",
      " Validation top K precision = 0.015466666666666783, recall = 0.006808328416391555.\n",
      "\n",
      "Training on the 22 epoch\n",
      "Training on epoch 22 minibatch 1/5000 completed\n",
      " bpr_loss on current minibatch is 0.693703, and regularization loss is 0.000556.\n",
      " Top K precision = 0.015254237288135592, recall = 0.0064735257603551226.\n",
      "Training on epoch 22 minibatch 101/5000 completed\n",
      " bpr_loss on current minibatch is 0.693664, and regularization loss is 0.000517.\n",
      " Top K precision = 0.008333333333333333, recall = 0.004305555555555556.\n",
      "Training on epoch 22 minibatch 201/5000 completed\n",
      " bpr_loss on current minibatch is 0.69375, and regularization loss is 0.000602.\n",
      " Top K precision = 0.02666666666666667, recall = 0.010318957612094467.\n",
      "Training on epoch 22 minibatch 301/5000 completed\n",
      " bpr_loss on current minibatch is 0.693692, and regularization loss is 0.000545.\n",
      " Top K precision = 0.006666666666666667, recall = 0.0036001906590141883.\n",
      "Training on epoch 22 minibatch 401/5000 completed\n",
      " bpr_loss on current minibatch is 0.693747, and regularization loss is 0.0006.\n",
      " Top K precision = 0.010169491525423728, recall = 0.0045611387255060885.\n",
      "Training on epoch 22 minibatch 501/5000 completed\n",
      " bpr_loss on current minibatch is 0.693819, and regularization loss is 0.000672.\n",
      " Top K precision = 0.00847457627118644, recall = 0.0038549503006133114.\n",
      "Training on epoch 22 minibatch 601/5000 completed\n",
      " bpr_loss on current minibatch is 0.693754, and regularization loss is 0.000607.\n",
      " Top K precision = 0.016949152542372878, recall = 0.006412157759056911.\n",
      "Training on epoch 22 minibatch 701/5000 completed\n",
      " bpr_loss on current minibatch is 0.693808, and regularization loss is 0.00066.\n",
      " Top K precision = 0.011666666666666665, recall = 0.0048504273504273495.\n",
      "Training on epoch 22 minibatch 801/5000 completed\n",
      " bpr_loss on current minibatch is 0.693827, and regularization loss is 0.00068.\n",
      " Top K precision = 0.011864406779661016, recall = 0.004849371203461108.\n",
      "Training on epoch 22 minibatch 901/5000 completed\n",
      " bpr_loss on current minibatch is 0.693908, and regularization loss is 0.000761.\n",
      " Top K precision = 0.018644067796610167, recall = 0.00767105928234385.\n",
      "Training on epoch 22 minibatch 1001/5000 completed\n",
      " bpr_loss on current minibatch is 0.693677, and regularization loss is 0.00053.\n",
      " Top K precision = 0.013333333333333332, recall = 0.005518705580625085.\n",
      "Training on epoch 22 minibatch 1101/5000 completed\n",
      " bpr_loss on current minibatch is 0.693842, and regularization loss is 0.000695.\n",
      " Top K precision = 0.01206896551724138, recall = 0.004952982149383948.\n",
      "Training on epoch 22 minibatch 1201/5000 completed\n",
      " bpr_loss on current minibatch is 0.693832, and regularization loss is 0.000684.\n",
      " Top K precision = 0.011666666666666665, recall = 0.003993312767404643.\n",
      "Training on epoch 22 minibatch 1301/5000 completed\n",
      " bpr_loss on current minibatch is 0.693959, and regularization loss is 0.000812.\n",
      " Top K precision = 0.005084745762711865, recall = 0.004257042392635613.\n",
      "Training on epoch 22 minibatch 1401/5000 completed\n",
      " bpr_loss on current minibatch is 0.693922, and regularization loss is 0.000775.\n",
      " Top K precision = 0.023333333333333334, recall = 0.011652724867056652.\n",
      "Training on epoch 22 minibatch 1501/5000 completed\n",
      " bpr_loss on current minibatch is 0.693771, and regularization loss is 0.000624.\n",
      " Top K precision = 0.01694915254237288, recall = 0.008487699808949308.\n",
      "Training on epoch 22 minibatch 1601/5000 completed\n",
      " bpr_loss on current minibatch is 0.69386, and regularization loss is 0.000713.\n",
      " Top K precision = 0.006779661016949153, recall = 0.004788737286894987.\n",
      "Training on epoch 22 minibatch 1701/5000 completed\n",
      " bpr_loss on current minibatch is 0.693764, and regularization loss is 0.000617.\n",
      " Top K precision = 0.020338983050847456, recall = 0.010319468326100603.\n",
      "Training on epoch 22 minibatch 1801/5000 completed\n",
      " bpr_loss on current minibatch is 0.693731, and regularization loss is 0.000584.\n",
      " Top K precision = 0.008333333333333333, recall = 0.005087984459581556.\n",
      "Training on epoch 22 minibatch 1901/5000 completed\n",
      " bpr_loss on current minibatch is 0.693715, and regularization loss is 0.000568.\n",
      " Top K precision = 0.010169491525423728, recall = 0.006268262156250366.\n",
      "Training on epoch 22 minibatch 2001/5000 completed\n",
      " bpr_loss on current minibatch is 0.693798, and regularization loss is 0.000651.\n",
      " Top K precision = 0.010344827586206896, recall = 0.006775679620507207.\n",
      "Training on epoch 22 minibatch 2101/5000 completed\n",
      " bpr_loss on current minibatch is 0.693767, and regularization loss is 0.00062.\n",
      " Top K precision = 0.008333333333333333, recall = 0.004403208876893087.\n",
      "Training on epoch 22 minibatch 2201/5000 completed\n",
      " bpr_loss on current minibatch is 0.693761, and regularization loss is 0.000614.\n",
      " Top K precision = 0.011666666666666665, recall = 0.006184730368198111.\n",
      "Training on epoch 22 minibatch 2301/5000 completed\n",
      " bpr_loss on current minibatch is 0.693789, and regularization loss is 0.000642.\n",
      " Top K precision = 0.005000000000000001, recall = 0.0010921912624699001.\n",
      "Training on epoch 22 minibatch 2401/5000 completed\n",
      " bpr_loss on current minibatch is 0.693799, and regularization loss is 0.000652.\n",
      " Top K precision = 0.008333333333333333, recall = 0.004465421303656598.\n",
      "Training on epoch 22 minibatch 2501/5000 completed\n",
      " bpr_loss on current minibatch is 0.693702, and regularization loss is 0.000555.\n",
      " Top K precision = 0.006666666666666667, recall = 0.0030908790283790282.\n",
      "Training on epoch 22 minibatch 2601/5000 completed\n",
      " bpr_loss on current minibatch is 0.693744, and regularization loss is 0.000597.\n",
      " Top K precision = 0.0033333333333333335, recall = 0.0010475297060662913.\n",
      "Training on epoch 22 minibatch 2701/5000 completed\n",
      " bpr_loss on current minibatch is 0.693675, and regularization loss is 0.000527.\n",
      " Top K precision = 0.005000000000000001, recall = 0.001598524931858265.\n",
      "Training on epoch 22 minibatch 2801/5000 completed\n",
      " bpr_loss on current minibatch is 0.693853, and regularization loss is 0.000706.\n",
      " Top K precision = 0.018644067796610167, recall = 0.008588426549899596.\n",
      "Training on epoch 22 minibatch 2901/5000 completed\n",
      " bpr_loss on current minibatch is 0.693935, and regularization loss is 0.000788.\n",
      " Top K precision = 0.011864406779661016, recall = 0.004790620657422426.\n",
      "Training on epoch 22 minibatch 3001/5000 completed\n",
      " bpr_loss on current minibatch is 0.693778, and regularization loss is 0.000631.\n",
      " Top K precision = 0.014999999999999998, recall = 0.005826838964281755.\n",
      "Training on epoch 22 minibatch 3101/5000 completed\n",
      " bpr_loss on current minibatch is 0.693901, and regularization loss is 0.000754.\n",
      " Top K precision = 0.015517241379310343, recall = 0.004655614085921798.\n",
      "Training on epoch 22 minibatch 3201/5000 completed\n",
      " bpr_loss on current minibatch is 0.693667, and regularization loss is 0.000519.\n",
      " Top K precision = 0.018644067796610174, recall = 0.009201696258546303.\n",
      "Training on epoch 22 minibatch 3301/5000 completed\n",
      " bpr_loss on current minibatch is 0.693881, and regularization loss is 0.000734.\n",
      " Top K precision = 0.008333333333333333, recall = 0.002794343007797401.\n",
      "Training on epoch 22 minibatch 3401/5000 completed\n",
      " bpr_loss on current minibatch is 0.693844, and regularization loss is 0.000697.\n",
      " Top K precision = 0.013333333333333332, recall = 0.0038716482374401757.\n",
      "Training on epoch 22 minibatch 3501/5000 completed\n",
      " bpr_loss on current minibatch is 0.693775, and regularization loss is 0.000628.\n",
      " Top K precision = 0.015254237288135592, recall = 0.008110706364056777.\n",
      "Training on epoch 22 minibatch 3601/5000 completed\n",
      " bpr_loss on current minibatch is 0.693906, and regularization loss is 0.000759.\n",
      " Top K precision = 0.01694915254237288, recall = 0.007708324722825893.\n",
      "Training on epoch 22 minibatch 3701/5000 completed\n",
      " bpr_loss on current minibatch is 0.693717, and regularization loss is 0.00057.\n",
      " Top K precision = 0.014999999999999998, recall = 0.006557349561309631.\n",
      "Training on epoch 22 minibatch 3801/5000 completed\n",
      " bpr_loss on current minibatch is 0.693657, and regularization loss is 0.00051.\n",
      " Top K precision = 0.01833333333333333, recall = 0.006864157883179622.\n",
      "Training on epoch 22 minibatch 3901/5000 completed\n",
      " bpr_loss on current minibatch is 0.693724, and regularization loss is 0.000577.\n",
      " Top K precision = 0.018644067796610167, recall = 0.008167751779446406.\n",
      "Training on epoch 22 minibatch 4001/5000 completed\n",
      " bpr_loss on current minibatch is 0.694066, and regularization loss is 0.000919.\n",
      " Top K precision = 0.013559322033898305, recall = 0.004787770810754491.\n",
      "Training on epoch 22 minibatch 4101/5000 completed\n",
      " bpr_loss on current minibatch is 0.69365, and regularization loss is 0.000503.\n",
      " Top K precision = 0.013333333333333332, recall = 0.006059471692464019.\n",
      "Training on epoch 22 minibatch 4201/5000 completed\n",
      " bpr_loss on current minibatch is 0.693838, and regularization loss is 0.00069.\n",
      " Top K precision = 0.013559322033898305, recall = 0.005882124518185038.\n",
      "Training on epoch 22 minibatch 4301/5000 completed\n",
      " bpr_loss on current minibatch is 0.693694, and regularization loss is 0.000547.\n",
      " Top K precision = 0.016666666666666666, recall = 0.006033466916620542.\n",
      "Training on epoch 22 minibatch 4401/5000 completed\n",
      " bpr_loss on current minibatch is 0.693675, and regularization loss is 0.000528.\n",
      " Top K precision = 0.022033898305084745, recall = 0.013881975657536075.\n",
      "Training on epoch 22 minibatch 4501/5000 completed\n",
      " bpr_loss on current minibatch is 0.693795, and regularization loss is 0.000648.\n",
      " Top K precision = 0.015254237288135594, recall = 0.006671048630171263.\n",
      "Training on epoch 22 minibatch 4601/5000 completed\n",
      " bpr_loss on current minibatch is 0.693828, and regularization loss is 0.000681.\n",
      " Top K precision = 0.010169491525423728, recall = 0.0037755323772272922.\n",
      "Training on epoch 22 minibatch 4701/5000 completed\n",
      " bpr_loss on current minibatch is 0.693823, and regularization loss is 0.000676.\n",
      " Top K precision = 0.018965517241379307, recall = 0.010647019352964558.\n",
      "Training on epoch 22 minibatch 4801/5000 completed\n",
      " bpr_loss on current minibatch is 0.693639, and regularization loss is 0.000491.\n",
      " Top K precision = 0.010169491525423728, recall = 0.004370348598010441.\n",
      "Training on epoch 22 minibatch 4901/5000 completed\n",
      " bpr_loss on current minibatch is 0.693785, and regularization loss is 0.000638.\n",
      " Top K precision = 0.01379310344827586, recall = 0.006540634821567884.\n",
      "\n",
      "Training on 22 epoch completed.\n",
      " Average bpr_loss on train set is 0.011563 for the current epoch.\n",
      " Training top K precision = 0.014333333333333436, recall = 0.0061158438759453225.\n",
      " Average bpr_loss on the validation set is 2e-06, and regularization loss is 0.0.\n",
      " Validation top K precision = 0.01403333333333343, recall = 0.006257282312415879.\n",
      "\n",
      "Training on the 23 epoch\n",
      "Training on epoch 23 minibatch 1/5000 completed\n",
      " bpr_loss on current minibatch is 0.693721, and regularization loss is 0.000574.\n",
      " Top K precision = 0.015517241379310343, recall = 0.00636683524614559.\n",
      "Training on epoch 23 minibatch 101/5000 completed\n",
      " bpr_loss on current minibatch is 0.693813, and regularization loss is 0.000666.\n",
      " Top K precision = 0.01833333333333333, recall = 0.010755663150590684.\n",
      "Training on epoch 23 minibatch 201/5000 completed\n",
      " bpr_loss on current minibatch is 0.693669, and regularization loss is 0.000522.\n",
      " Top K precision = 0.01, recall = 0.0037535131285131285.\n",
      "Training on epoch 23 minibatch 301/5000 completed\n",
      " bpr_loss on current minibatch is 0.693788, and regularization loss is 0.00064.\n",
      " Top K precision = 0.010169491525423728, recall = 0.0051067576491305305.\n",
      "Training on epoch 23 minibatch 401/5000 completed\n",
      " bpr_loss on current minibatch is 0.693686, and regularization loss is 0.000539.\n",
      " Top K precision = 0.011666666666666665, recall = 0.005796562159817646.\n",
      "Training on epoch 23 minibatch 501/5000 completed\n",
      " bpr_loss on current minibatch is 0.693744, and regularization loss is 0.000597.\n",
      " Top K precision = 0.013559322033898305, recall = 0.007086976112399841.\n",
      "Training on epoch 23 minibatch 601/5000 completed\n",
      " bpr_loss on current minibatch is 0.693765, and regularization loss is 0.000618.\n",
      " Top K precision = 0.016666666666666666, recall = 0.007606843034474612.\n",
      "Training on epoch 23 minibatch 701/5000 completed\n",
      " bpr_loss on current minibatch is 0.693695, and regularization loss is 0.000548.\n",
      " Top K precision = 0.005084745762711865, recall = 0.0016714350106462631.\n",
      "Training on epoch 23 minibatch 801/5000 completed\n",
      " bpr_loss on current minibatch is 0.693745, and regularization loss is 0.000598.\n",
      " Top K precision = 0.01, recall = 0.004932412358882947.\n",
      "Training on epoch 23 minibatch 901/5000 completed\n",
      " bpr_loss on current minibatch is 0.693808, and regularization loss is 0.000661.\n",
      " Top K precision = 0.011864406779661016, recall = 0.005308471530213037.\n",
      "Training on epoch 23 minibatch 1001/5000 completed\n",
      " bpr_loss on current minibatch is 0.694019, and regularization loss is 0.000872.\n",
      " Top K precision = 0.020000000000000004, recall = 0.008755199478883691.\n",
      "Training on epoch 23 minibatch 1101/5000 completed\n",
      " bpr_loss on current minibatch is 0.693825, and regularization loss is 0.000678.\n",
      " Top K precision = 0.016949152542372878, recall = 0.007318014882172326.\n",
      "Training on epoch 23 minibatch 1201/5000 completed\n",
      " bpr_loss on current minibatch is 0.69379, and regularization loss is 0.000643.\n",
      " Top K precision = 0.013559322033898305, recall = 0.009487180593860552.\n",
      "Training on epoch 23 minibatch 1301/5000 completed\n",
      " bpr_loss on current minibatch is 0.693829, and regularization loss is 0.000682.\n",
      " Top K precision = 0.021666666666666667, recall = 0.007857093978577022.\n",
      "Training on epoch 23 minibatch 1401/5000 completed\n",
      " bpr_loss on current minibatch is 0.693882, and regularization loss is 0.000735.\n",
      " Top K precision = 0.00847457627118644, recall = 0.004537121237021536.\n",
      "Training on epoch 23 minibatch 1501/5000 completed\n",
      " bpr_loss on current minibatch is 0.693948, and regularization loss is 0.000801.\n",
      " Top K precision = 0.0016949152542372883, recall = 0.00047080979284369113.\n",
      "Training on epoch 23 minibatch 1601/5000 completed\n",
      " bpr_loss on current minibatch is 0.693762, and regularization loss is 0.000615.\n",
      " Top K precision = 0.011666666666666665, recall = 0.0039634208384208384.\n",
      "Training on epoch 23 minibatch 1701/5000 completed\n",
      " bpr_loss on current minibatch is 0.693937, and regularization loss is 0.00079.\n",
      " Top K precision = 0.014999999999999998, recall = 0.005955364826332568.\n",
      "Training on epoch 23 minibatch 1801/5000 completed\n",
      " bpr_loss on current minibatch is 0.693847, and regularization loss is 0.0007.\n",
      " Top K precision = 0.011864406779661016, recall = 0.006939347934383422.\n",
      "Training on epoch 23 minibatch 1901/5000 completed\n",
      " bpr_loss on current minibatch is 0.69379, and regularization loss is 0.000643.\n",
      " Top K precision = 0.018644067796610167, recall = 0.007108434020578025.\n",
      "Training on epoch 23 minibatch 2001/5000 completed\n",
      " bpr_loss on current minibatch is 0.693686, and regularization loss is 0.000539.\n",
      " Top K precision = 0.01, recall = 0.0035724468184145605.\n",
      "Training on epoch 23 minibatch 2101/5000 completed\n",
      " bpr_loss on current minibatch is 0.693828, and regularization loss is 0.000681.\n",
      " Top K precision = 0.014999999999999998, recall = 0.007067362047625206.\n",
      "Training on epoch 23 minibatch 2201/5000 completed\n",
      " bpr_loss on current minibatch is 0.693852, and regularization loss is 0.000705.\n",
      " Top K precision = 0.01206896551724138, recall = 0.004900825505408083.\n",
      "Training on epoch 23 minibatch 2301/5000 completed\n",
      " bpr_loss on current minibatch is 0.693693, and regularization loss is 0.000546.\n",
      " Top K precision = 0.00847457627118644, recall = 0.004341805237505234.\n",
      "Training on epoch 23 minibatch 2401/5000 completed\n",
      " bpr_loss on current minibatch is 0.693866, and regularization loss is 0.000719.\n",
      " Top K precision = 0.011864406779661016, recall = 0.0037650680830013795.\n",
      "Training on epoch 23 minibatch 2501/5000 completed\n",
      " bpr_loss on current minibatch is 0.693784, and regularization loss is 0.000637.\n",
      " Top K precision = 0.005084745762711865, recall = 0.002124441352559238.\n",
      "Training on epoch 23 minibatch 2601/5000 completed\n",
      " bpr_loss on current minibatch is 0.69398, and regularization loss is 0.000833.\n",
      " Top K precision = 0.013559322033898305, recall = 0.005288130980593067.\n",
      "Training on epoch 23 minibatch 2701/5000 completed\n",
      " bpr_loss on current minibatch is 0.693796, and regularization loss is 0.000648.\n",
      " Top K precision = 0.016949152542372878, recall = 0.006025037494070244.\n",
      "Training on epoch 23 minibatch 2801/5000 completed\n",
      " bpr_loss on current minibatch is 0.693796, and regularization loss is 0.000648.\n",
      " Top K precision = 0.01694915254237288, recall = 0.007977793072508925.\n",
      "Training on epoch 23 minibatch 2901/5000 completed\n",
      " bpr_loss on current minibatch is 0.693689, and regularization loss is 0.000542.\n",
      " Top K precision = 0.016666666666666666, recall = 0.008223752142158213.\n",
      "Training on epoch 23 minibatch 3001/5000 completed\n",
      " bpr_loss on current minibatch is 0.693865, and regularization loss is 0.000718.\n",
      " Top K precision = 0.00847457627118644, recall = 0.0027184679727052614.\n",
      "Training on epoch 23 minibatch 3101/5000 completed\n",
      " bpr_loss on current minibatch is 0.693673, and regularization loss is 0.000526.\n",
      " Top K precision = 0.01206896551724138, recall = 0.004005313811348294.\n",
      "Training on epoch 23 minibatch 3201/5000 completed\n",
      " bpr_loss on current minibatch is 0.6939, and regularization loss is 0.000753.\n",
      " Top K precision = 0.010344827586206896, recall = 0.003173115229997973.\n",
      "Training on epoch 23 minibatch 3301/5000 completed\n",
      " bpr_loss on current minibatch is 0.69379, and regularization loss is 0.000642.\n",
      " Top K precision = 0.016666666666666666, recall = 0.006050034034621643.\n",
      "Training on epoch 23 minibatch 3401/5000 completed\n",
      " bpr_loss on current minibatch is 0.693807, and regularization loss is 0.00066.\n",
      " Top K precision = 0.016666666666666666, recall = 0.007146196997282225.\n",
      "Training on epoch 23 minibatch 3501/5000 completed\n",
      " bpr_loss on current minibatch is 0.693841, and regularization loss is 0.000694.\n",
      " Top K precision = 0.0016666666666666668, recall = 0.0011904761904761904.\n",
      "Training on epoch 23 minibatch 3601/5000 completed\n",
      " bpr_loss on current minibatch is 0.693697, and regularization loss is 0.000549.\n",
      " Top K precision = 0.014999999999999998, recall = 0.007845815860805343.\n",
      "Training on epoch 23 minibatch 3701/5000 completed\n",
      " bpr_loss on current minibatch is 0.693736, and regularization loss is 0.000589.\n",
      " Top K precision = 0.010169491525423728, recall = 0.005727417591824371.\n",
      "Training on epoch 23 minibatch 3801/5000 completed\n",
      " bpr_loss on current minibatch is 0.693842, and regularization loss is 0.000695.\n",
      " Top K precision = 0.013559322033898305, recall = 0.006482268891632823.\n",
      "Training on epoch 23 minibatch 3901/5000 completed\n",
      " bpr_loss on current minibatch is 0.693981, and regularization loss is 0.000834.\n",
      " Top K precision = 0.006666666666666667, recall = 0.0020310922969887604.\n",
      "Training on epoch 23 minibatch 4001/5000 completed\n",
      " bpr_loss on current minibatch is 0.693859, and regularization loss is 0.000712.\n",
      " Top K precision = 0.01833333333333333, recall = 0.011289347059274594.\n",
      "Training on epoch 23 minibatch 4101/5000 completed\n",
      " bpr_loss on current minibatch is 0.693734, and regularization loss is 0.000587.\n",
      " Top K precision = 0.008333333333333333, recall = 0.005044302103125633.\n",
      "Training on epoch 23 minibatch 4201/5000 completed\n",
      " bpr_loss on current minibatch is 0.693849, and regularization loss is 0.000702.\n",
      " Top K precision = 0.00847457627118644, recall = 0.004129059857526631.\n",
      "Training on epoch 23 minibatch 4301/5000 completed\n",
      " bpr_loss on current minibatch is 0.693849, and regularization loss is 0.000701.\n",
      " Top K precision = 0.007017543859649123, recall = 0.004096652913430465.\n",
      "Training on epoch 23 minibatch 4401/5000 completed\n",
      " bpr_loss on current minibatch is 0.693633, and regularization loss is 0.000486.\n",
      " Top K precision = 0.00847457627118644, recall = 0.0067518404382811165.\n",
      "Training on epoch 23 minibatch 4501/5000 completed\n",
      " bpr_loss on current minibatch is 0.693772, and regularization loss is 0.000625.\n",
      " Top K precision = 0.013333333333333334, recall = 0.00498536660735105.\n",
      "Training on epoch 23 minibatch 4601/5000 completed\n",
      " bpr_loss on current minibatch is 0.693756, and regularization loss is 0.000608.\n",
      " Top K precision = 0.01833333333333333, recall = 0.0113011764321485.\n",
      "Training on epoch 23 minibatch 4701/5000 completed\n",
      " bpr_loss on current minibatch is 0.694034, and regularization loss is 0.000887.\n",
      " Top K precision = 0.013559322033898305, recall = 0.007156047219325128.\n",
      "Training on epoch 23 minibatch 4801/5000 completed\n",
      " bpr_loss on current minibatch is 0.69371, and regularization loss is 0.000562.\n",
      " Top K precision = 0.008333333333333333, recall = 0.004660261765524924.\n",
      "Training on epoch 23 minibatch 4901/5000 completed\n",
      " bpr_loss on current minibatch is 0.693796, and regularization loss is 0.000648.\n",
      " Top K precision = 0.016666666666666666, recall = 0.00956573397362871.\n",
      "\n",
      "Training on 23 epoch completed.\n",
      " Average bpr_loss on train set is 0.011563 for the current epoch.\n",
      " Training top K precision = 0.014333333333333429, recall = 0.006254985214344834.\n",
      " Average bpr_loss on the validation set is 2e-06, and regularization loss is 0.0.\n",
      " Validation top K precision = 0.015066666666666778, recall = 0.00684911980059185.\n",
      "\n",
      "Training on the 24 epoch\n",
      "Training on epoch 24 minibatch 1/5000 completed\n",
      " bpr_loss on current minibatch is 0.693697, and regularization loss is 0.000549.\n",
      " Top K precision = 0.010169491525423728, recall = 0.0038750863521467556.\n",
      "Training on epoch 24 minibatch 101/5000 completed\n",
      " bpr_loss on current minibatch is 0.693879, and regularization loss is 0.000731.\n",
      " Top K precision = 0.013333333333333332, recall = 0.005222837661092622.\n",
      "Training on epoch 24 minibatch 201/5000 completed\n",
      " bpr_loss on current minibatch is 0.693754, and regularization loss is 0.000607.\n",
      " Top K precision = 0.011864406779661016, recall = 0.005240974691176716.\n",
      "Training on epoch 24 minibatch 301/5000 completed\n",
      " bpr_loss on current minibatch is 0.693898, and regularization loss is 0.000751.\n",
      " Top K precision = 0.02, recall = 0.007546791917759658.\n",
      "Training on epoch 24 minibatch 401/5000 completed\n",
      " bpr_loss on current minibatch is 0.693781, and regularization loss is 0.000634.\n",
      " Top K precision = 0.005000000000000001, recall = 0.0019285759175465059.\n",
      "Training on epoch 24 minibatch 501/5000 completed\n",
      " bpr_loss on current minibatch is 0.693828, and regularization loss is 0.000681.\n",
      " Top K precision = 0.02372881355932203, recall = 0.013087732024503319.\n",
      "Training on epoch 24 minibatch 601/5000 completed\n",
      " bpr_loss on current minibatch is 0.693975, and regularization loss is 0.000828.\n",
      " Top K precision = 0.00847457627118644, recall = 0.005376090115909927.\n",
      "Training on epoch 24 minibatch 701/5000 completed\n",
      " bpr_loss on current minibatch is 0.693792, and regularization loss is 0.000645.\n",
      " Top K precision = 0.011864406779661016, recall = 0.004882133257352428.\n",
      "Training on epoch 24 minibatch 801/5000 completed\n",
      " bpr_loss on current minibatch is 0.693612, and regularization loss is 0.000465.\n",
      " Top K precision = 0.013559322033898305, recall = 0.005745076334993241.\n",
      "Training on epoch 24 minibatch 901/5000 completed\n",
      " bpr_loss on current minibatch is 0.693852, and regularization loss is 0.000705.\n",
      " Top K precision = 0.00847457627118644, recall = 0.006289738842081813.\n",
      "Training on epoch 24 minibatch 1001/5000 completed\n",
      " bpr_loss on current minibatch is 0.693735, and regularization loss is 0.000588.\n",
      " Top K precision = 0.00847457627118644, recall = 0.004978627241199987.\n",
      "Training on epoch 24 minibatch 1101/5000 completed\n",
      " bpr_loss on current minibatch is 0.693892, and regularization loss is 0.000745.\n",
      " Top K precision = 0.01379310344827586, recall = 0.0058290681245925634.\n",
      "Training on epoch 24 minibatch 1201/5000 completed\n",
      " bpr_loss on current minibatch is 0.693769, and regularization loss is 0.000621.\n",
      " Top K precision = 0.015517241379310343, recall = 0.0042975727876768495.\n",
      "Training on epoch 24 minibatch 1301/5000 completed\n",
      " bpr_loss on current minibatch is 0.693855, and regularization loss is 0.000707.\n",
      " Top K precision = 0.011666666666666665, recall = 0.0049978172269193955.\n",
      "Training on epoch 24 minibatch 1401/5000 completed\n",
      " bpr_loss on current minibatch is 0.693652, and regularization loss is 0.000505.\n",
      " Top K precision = 0.008333333333333333, recall = 0.002527754274526154.\n",
      "Training on epoch 24 minibatch 1501/5000 completed\n",
      " bpr_loss on current minibatch is 0.693651, and regularization loss is 0.000504.\n",
      " Top K precision = 0.011666666666666665, recall = 0.00407843137254902.\n",
      "Training on epoch 24 minibatch 1601/5000 completed\n",
      " bpr_loss on current minibatch is 0.693956, and regularization loss is 0.000809.\n",
      " Top K precision = 0.018644067796610167, recall = 0.010238606267380409.\n",
      "Training on epoch 24 minibatch 1701/5000 completed\n",
      " bpr_loss on current minibatch is 0.69369, and regularization loss is 0.000542.\n",
      " Top K precision = 0.00909090909090909, recall = 0.0039025279533300926.\n",
      "Training on epoch 24 minibatch 1801/5000 completed\n",
      " bpr_loss on current minibatch is 0.693767, and regularization loss is 0.00062.\n",
      " Top K precision = 0.006666666666666667, recall = 0.0023395191409897294.\n",
      "Training on epoch 24 minibatch 1901/5000 completed\n",
      " bpr_loss on current minibatch is 0.693792, and regularization loss is 0.000645.\n",
      " Top K precision = 0.011666666666666665, recall = 0.006164624681781544.\n",
      "Training on epoch 24 minibatch 2001/5000 completed\n",
      " bpr_loss on current minibatch is 0.693794, and regularization loss is 0.000647.\n",
      " Top K precision = 0.01833333333333333, recall = 0.010276254609587943.\n",
      "Training on epoch 24 minibatch 2101/5000 completed\n",
      " bpr_loss on current minibatch is 0.693796, and regularization loss is 0.000649.\n",
      " Top K precision = 0.0033898305084745766, recall = 0.0009994932147080354.\n",
      "Training on epoch 24 minibatch 2201/5000 completed\n",
      " bpr_loss on current minibatch is 0.693728, and regularization loss is 0.00058.\n",
      " Top K precision = 0.013559322033898305, recall = 0.006269264226833168.\n",
      "Training on epoch 24 minibatch 2301/5000 completed\n",
      " bpr_loss on current minibatch is 0.693692, and regularization loss is 0.000545.\n",
      " Top K precision = 0.010344827586206896, recall = 0.005597518700966976.\n",
      "Training on epoch 24 minibatch 2401/5000 completed\n",
      " bpr_loss on current minibatch is 0.693702, and regularization loss is 0.000555.\n",
      " Top K precision = 0.015254237288135592, recall = 0.005976099386712888.\n",
      "Training on epoch 24 minibatch 2501/5000 completed\n",
      " bpr_loss on current minibatch is 0.693832, and regularization loss is 0.000685.\n",
      " Top K precision = 0.014999999999999998, recall = 0.007229511687716022.\n",
      "Training on epoch 24 minibatch 2601/5000 completed\n",
      " bpr_loss on current minibatch is 0.693865, and regularization loss is 0.000718.\n",
      " Top K precision = 0.011666666666666665, recall = 0.004721056950159118.\n",
      "Training on epoch 24 minibatch 2701/5000 completed\n",
      " bpr_loss on current minibatch is 0.693791, and regularization loss is 0.000644.\n",
      " Top K precision = 0.021052631578947368, recall = 0.010312205570572408.\n",
      "Training on epoch 24 minibatch 2801/5000 completed\n",
      " bpr_loss on current minibatch is 0.693792, and regularization loss is 0.000644.\n",
      " Top K precision = 0.011864406779661016, recall = 0.004133416465639752.\n",
      "Training on epoch 24 minibatch 2901/5000 completed\n",
      " bpr_loss on current minibatch is 0.693954, and regularization loss is 0.000807.\n",
      " Top K precision = 0.011864406779661016, recall = 0.004415444540720885.\n",
      "Training on epoch 24 minibatch 3001/5000 completed\n",
      " bpr_loss on current minibatch is 0.693668, and regularization loss is 0.000521.\n",
      " Top K precision = 0.011666666666666665, recall = 0.003978994979634365.\n",
      "Training on epoch 24 minibatch 3101/5000 completed\n",
      " bpr_loss on current minibatch is 0.693713, and regularization loss is 0.000565.\n",
      " Top K precision = 0.013333333333333332, recall = 0.006319664645124156.\n",
      "Training on epoch 24 minibatch 3201/5000 completed\n",
      " bpr_loss on current minibatch is 0.693855, and regularization loss is 0.000708.\n",
      " Top K precision = 0.013333333333333332, recall = 0.005234122602543656.\n",
      "Training on epoch 24 minibatch 3301/5000 completed\n",
      " bpr_loss on current minibatch is 0.693869, and regularization loss is 0.000722.\n",
      " Top K precision = 0.011864406779661016, recall = 0.0050583365534035895.\n",
      "Training on epoch 24 minibatch 3401/5000 completed\n",
      " bpr_loss on current minibatch is 0.693588, and regularization loss is 0.00044.\n",
      " Top K precision = 0.01, recall = 0.002931457805895587.\n",
      "Training on epoch 24 minibatch 3501/5000 completed\n",
      " bpr_loss on current minibatch is 0.693871, and regularization loss is 0.000724.\n",
      " Top K precision = 0.006666666666666667, recall = 0.004887057387057387.\n",
      "Training on epoch 24 minibatch 3601/5000 completed\n",
      " bpr_loss on current minibatch is 0.693627, and regularization loss is 0.00048.\n",
      " Top K precision = 0.01, recall = 0.0057166313218944805.\n",
      "Training on epoch 24 minibatch 3701/5000 completed\n",
      " bpr_loss on current minibatch is 0.693873, and regularization loss is 0.000726.\n",
      " Top K precision = 0.01833333333333333, recall = 0.007176371543241462.\n",
      "Training on epoch 24 minibatch 3801/5000 completed\n",
      " bpr_loss on current minibatch is 0.693883, and regularization loss is 0.000736.\n",
      " Top K precision = 0.01, recall = 0.004268722891911297.\n",
      "Training on epoch 24 minibatch 3901/5000 completed\n",
      " bpr_loss on current minibatch is 0.693694, and regularization loss is 0.000547.\n",
      " Top K precision = 0.01206896551724138, recall = 0.005521063842961944.\n",
      "Training on epoch 24 minibatch 4001/5000 completed\n",
      " bpr_loss on current minibatch is 0.693889, and regularization loss is 0.000742.\n",
      " Top K precision = 0.01, recall = 0.004564822920086077.\n",
      "Training on epoch 24 minibatch 4101/5000 completed\n",
      " bpr_loss on current minibatch is 0.693704, and regularization loss is 0.000557.\n",
      " Top K precision = 0.014999999999999998, recall = 0.006749148927443501.\n",
      "Training on epoch 24 minibatch 4201/5000 completed\n",
      " bpr_loss on current minibatch is 0.693771, and regularization loss is 0.000623.\n",
      " Top K precision = 0.010169491525423728, recall = 0.0037580675850878566.\n",
      "Training on epoch 24 minibatch 4301/5000 completed\n",
      " bpr_loss on current minibatch is 0.693752, and regularization loss is 0.000604.\n",
      " Top K precision = 0.013559322033898305, recall = 0.005782136027011864.\n",
      "Training on epoch 24 minibatch 4401/5000 completed\n",
      " bpr_loss on current minibatch is 0.693832, and regularization loss is 0.000685.\n",
      " Top K precision = 0.01016949152542373, recall = 0.003424182121773558.\n",
      "Training on epoch 24 minibatch 4501/5000 completed\n",
      " bpr_loss on current minibatch is 0.693848, and regularization loss is 0.000701.\n",
      " Top K precision = 0.005000000000000001, recall = 0.002369281045751634.\n",
      "Training on epoch 24 minibatch 4601/5000 completed\n",
      " bpr_loss on current minibatch is 0.693667, and regularization loss is 0.00052.\n",
      " Top K precision = 0.006666666666666667, recall = 0.001767834336799854.\n",
      "Training on epoch 24 minibatch 4701/5000 completed\n",
      " bpr_loss on current minibatch is 0.693828, and regularization loss is 0.000681.\n",
      " Top K precision = 0.016666666666666666, recall = 0.007022580962209445.\n",
      "Training on epoch 24 minibatch 4801/5000 completed\n",
      " bpr_loss on current minibatch is 0.693671, and regularization loss is 0.000524.\n",
      " Top K precision = 0.021666666666666667, recall = 0.009886053092574834.\n",
      "Training on epoch 24 minibatch 4901/5000 completed\n",
      " bpr_loss on current minibatch is 0.693689, and regularization loss is 0.000541.\n",
      " Top K precision = 0.014999999999999998, recall = 0.007401611981029274.\n",
      "\n",
      "Training on 24 epoch completed.\n",
      " Average bpr_loss on train set is 0.011563 for the current epoch.\n",
      " Training top K precision = 0.013466666666666748, recall = 0.006456427059115984.\n",
      " Average bpr_loss on the validation set is 2e-06, and regularization loss is 0.0.\n",
      " Validation top K precision = 0.014266666666666775, recall = 0.006211217810688519.\n",
      "\n",
      "Training on the 25 epoch\n",
      "Training on epoch 25 minibatch 1/5000 completed\n",
      " bpr_loss on current minibatch is 0.693735, and regularization loss is 0.000588.\n",
      " Top K precision = 0.008333333333333333, recall = 0.004242354532209605.\n",
      "Training on epoch 25 minibatch 101/5000 completed\n",
      " bpr_loss on current minibatch is 0.693776, and regularization loss is 0.000629.\n",
      " Top K precision = 0.011666666666666665, recall = 0.004332341585485632.\n",
      "Training on epoch 25 minibatch 201/5000 completed\n",
      " bpr_loss on current minibatch is 0.693828, and regularization loss is 0.00068.\n",
      " Top K precision = 0.015254237288135592, recall = 0.006806594867412415.\n",
      "Training on epoch 25 minibatch 301/5000 completed\n",
      " bpr_loss on current minibatch is 0.693796, and regularization loss is 0.000648.\n",
      " Top K precision = 0.011666666666666665, recall = 0.006061308984551452.\n",
      "Training on epoch 25 minibatch 401/5000 completed\n",
      " bpr_loss on current minibatch is 0.693832, and regularization loss is 0.000685.\n",
      " Top K precision = 0.015000000000000001, recall = 0.00469061059044081.\n",
      "Training on epoch 25 minibatch 501/5000 completed\n",
      " bpr_loss on current minibatch is 0.69378, and regularization loss is 0.000632.\n",
      " Top K precision = 0.021666666666666664, recall = 0.01088107947827812.\n",
      "Training on epoch 25 minibatch 601/5000 completed\n",
      " bpr_loss on current minibatch is 0.693819, and regularization loss is 0.000672.\n",
      " Top K precision = 0.01833333333333333, recall = 0.010520855486056972.\n",
      "Training on epoch 25 minibatch 701/5000 completed\n",
      " bpr_loss on current minibatch is 0.69394, and regularization loss is 0.000793.\n",
      " Top K precision = 0.013559322033898305, recall = 0.006650830337271015.\n",
      "Training on epoch 25 minibatch 801/5000 completed\n",
      " bpr_loss on current minibatch is 0.693807, and regularization loss is 0.00066.\n",
      " Top K precision = 0.022033898305084745, recall = 0.012922170001345571.\n",
      "Training on epoch 25 minibatch 901/5000 completed\n",
      " bpr_loss on current minibatch is 0.693761, and regularization loss is 0.000614.\n",
      " Top K precision = 0.015254237288135592, recall = 0.005861222093178397.\n",
      "Training on epoch 25 minibatch 1001/5000 completed\n",
      " bpr_loss on current minibatch is 0.693807, and regularization loss is 0.00066.\n",
      " Top K precision = 0.011666666666666665, recall = 0.0044957493486905255.\n",
      "Training on epoch 25 minibatch 1101/5000 completed\n",
      " bpr_loss on current minibatch is 0.693757, and regularization loss is 0.00061.\n",
      " Top K precision = 0.014999999999999998, recall = 0.008113629290099879.\n",
      "Training on epoch 25 minibatch 1201/5000 completed\n",
      " bpr_loss on current minibatch is 0.693893, and regularization loss is 0.000746.\n",
      " Top K precision = 0.01, recall = 0.0047086805177802135.\n",
      "Training on epoch 25 minibatch 1301/5000 completed\n",
      " bpr_loss on current minibatch is 0.693898, and regularization loss is 0.000751.\n",
      " Top K precision = 0.013333333333333332, recall = 0.005871919078440817.\n",
      "Training on epoch 25 minibatch 1401/5000 completed\n",
      " bpr_loss on current minibatch is 0.693689, and regularization loss is 0.000541.\n",
      " Top K precision = 0.011666666666666665, recall = 0.0053464491857349.\n",
      "Training on epoch 25 minibatch 1501/5000 completed\n",
      " bpr_loss on current minibatch is 0.693701, and regularization loss is 0.000554.\n",
      " Top K precision = 0.010344827586206896, recall = 0.005333442172491143.\n",
      "Training on epoch 25 minibatch 1601/5000 completed\n",
      " bpr_loss on current minibatch is 0.693888, and regularization loss is 0.000741.\n",
      " Top K precision = 0.011864406779661016, recall = 0.005763670677082614.\n",
      "Training on epoch 25 minibatch 1701/5000 completed\n",
      " bpr_loss on current minibatch is 0.693824, and regularization loss is 0.000677.\n",
      " Top K precision = 0.006779661016949153, recall = 0.0029812402812008647.\n",
      "Training on epoch 25 minibatch 1801/5000 completed\n",
      " bpr_loss on current minibatch is 0.693761, and regularization loss is 0.000613.\n",
      " Top K precision = 0.006779661016949153, recall = 0.0034399222176181676.\n",
      "Training on epoch 25 minibatch 1901/5000 completed\n",
      " bpr_loss on current minibatch is 0.693763, and regularization loss is 0.000616.\n",
      " Top K precision = 0.014999999999999998, recall = 0.0071417423807129685.\n",
      "Training on epoch 25 minibatch 2001/5000 completed\n",
      " bpr_loss on current minibatch is 0.693875, and regularization loss is 0.000728.\n",
      " Top K precision = 0.02, recall = 0.009308941114141456.\n",
      "Training on epoch 25 minibatch 2101/5000 completed\n",
      " bpr_loss on current minibatch is 0.693774, and regularization loss is 0.000627.\n",
      " Top K precision = 0.00847457627118644, recall = 0.00336685330145168.\n",
      "Training on epoch 25 minibatch 2201/5000 completed\n",
      " bpr_loss on current minibatch is 0.69376, and regularization loss is 0.000613.\n",
      " Top K precision = 0.02833333333333334, recall = 0.012249105871845243.\n",
      "Training on epoch 25 minibatch 2301/5000 completed\n",
      " bpr_loss on current minibatch is 0.693725, and regularization loss is 0.000577.\n",
      " Top K precision = 0.014999999999999998, recall = 0.006749567218800965.\n",
      "Training on epoch 25 minibatch 2401/5000 completed\n",
      " bpr_loss on current minibatch is 0.693802, and regularization loss is 0.000655.\n",
      " Top K precision = 0.00847457627118644, recall = 0.004575627580001554.\n",
      "Training on epoch 25 minibatch 2501/5000 completed\n",
      " bpr_loss on current minibatch is 0.693681, and regularization loss is 0.000533.\n",
      " Top K precision = 0.011666666666666665, recall = 0.0038508481126827273.\n",
      "Training on epoch 25 minibatch 2601/5000 completed\n",
      " bpr_loss on current minibatch is 0.69377, and regularization loss is 0.000623.\n",
      " Top K precision = 0.023333333333333334, recall = 0.009081480634141803.\n",
      "Training on epoch 25 minibatch 2701/5000 completed\n",
      " bpr_loss on current minibatch is 0.693828, and regularization loss is 0.000681.\n",
      " Top K precision = 0.006666666666666667, recall = 0.0022832391214744154.\n",
      "Training on epoch 25 minibatch 2801/5000 completed\n",
      " bpr_loss on current minibatch is 0.693935, and regularization loss is 0.000788.\n",
      " Top K precision = 0.01833333333333333, recall = 0.007095007114241449.\n",
      "Training on epoch 25 minibatch 2901/5000 completed\n",
      " bpr_loss on current minibatch is 0.693781, and regularization loss is 0.000634.\n",
      " Top K precision = 0.01379310344827586, recall = 0.0068186921486564755.\n",
      "Training on epoch 25 minibatch 3001/5000 completed\n",
      " bpr_loss on current minibatch is 0.693836, and regularization loss is 0.000689.\n",
      " Top K precision = 0.0033333333333333335, recall = 0.0017676767676767678.\n",
      "Training on epoch 25 minibatch 3101/5000 completed\n",
      " bpr_loss on current minibatch is 0.693818, and regularization loss is 0.00067.\n",
      " Top K precision = 0.014999999999999998, recall = 0.004561340212075506.\n",
      "Training on epoch 25 minibatch 3201/5000 completed\n",
      " bpr_loss on current minibatch is 0.693863, and regularization loss is 0.000716.\n",
      " Top K precision = 0.013559322033898305, recall = 0.0044837925330138894.\n",
      "Training on epoch 25 minibatch 3301/5000 completed\n",
      " bpr_loss on current minibatch is 0.693835, and regularization loss is 0.000688.\n",
      " Top K precision = 0.011864406779661016, recall = 0.0030808202482852445.\n",
      "Training on epoch 25 minibatch 3401/5000 completed\n",
      " bpr_loss on current minibatch is 0.693802, and regularization loss is 0.000654.\n",
      " Top K precision = 0.023728813559322035, recall = 0.010199778158402287.\n",
      "Training on epoch 25 minibatch 3501/5000 completed\n",
      " bpr_loss on current minibatch is 0.693801, and regularization loss is 0.000654.\n",
      " Top K precision = 0.011864406779661016, recall = 0.006810115035439063.\n",
      "Training on epoch 25 minibatch 3601/5000 completed\n",
      " bpr_loss on current minibatch is 0.693959, and regularization loss is 0.000812.\n",
      " Top K precision = 0.010169491525423728, recall = 0.007253964760018028.\n",
      "Training on epoch 25 minibatch 3701/5000 completed\n",
      " bpr_loss on current minibatch is 0.693782, and regularization loss is 0.000635.\n",
      " Top K precision = 0.015254237288135592, recall = 0.010034412310246097.\n",
      "Training on epoch 25 minibatch 3801/5000 completed\n",
      " bpr_loss on current minibatch is 0.693767, and regularization loss is 0.00062.\n",
      " Top K precision = 0.008333333333333333, recall = 0.003616150163769211.\n",
      "Training on epoch 25 minibatch 3901/5000 completed\n",
      " bpr_loss on current minibatch is 0.693731, and regularization loss is 0.000583.\n",
      " Top K precision = 0.016666666666666666, recall = 0.00612831877650426.\n",
      "Training on epoch 25 minibatch 4001/5000 completed\n",
      " bpr_loss on current minibatch is 0.69387, and regularization loss is 0.000722.\n",
      " Top K precision = 0.016666666666666666, recall = 0.00668611777148822.\n",
      "Training on epoch 25 minibatch 4101/5000 completed\n",
      " bpr_loss on current minibatch is 0.693806, and regularization loss is 0.000659.\n",
      " Top K precision = 0.014999999999999998, recall = 0.00976943652518694.\n",
      "Training on epoch 25 minibatch 4201/5000 completed\n",
      " bpr_loss on current minibatch is 0.693659, and regularization loss is 0.000512.\n",
      " Top K precision = 0.0035087719298245615, recall = 0.0037593984962406013.\n",
      "Training on epoch 25 minibatch 4301/5000 completed\n",
      " bpr_loss on current minibatch is 0.693794, and regularization loss is 0.000647.\n",
      " Top K precision = 0.008333333333333333, recall = 0.004206349206349206.\n",
      "Training on epoch 25 minibatch 4401/5000 completed\n",
      " bpr_loss on current minibatch is 0.693794, and regularization loss is 0.000647.\n",
      " Top K precision = 0.016666666666666666, recall = 0.008440263105118176.\n",
      "Training on epoch 25 minibatch 4501/5000 completed\n",
      " bpr_loss on current minibatch is 0.693795, and regularization loss is 0.000648.\n",
      " Top K precision = 0.01, recall = 0.005422130973601561.\n",
      "Training on epoch 25 minibatch 4601/5000 completed\n",
      " bpr_loss on current minibatch is 0.693711, and regularization loss is 0.000564.\n",
      " Top K precision = 0.013333333333333332, recall = 0.005030871185375513.\n",
      "Training on epoch 25 minibatch 4701/5000 completed\n",
      " bpr_loss on current minibatch is 0.693678, and regularization loss is 0.000531.\n",
      " Top K precision = 0.011666666666666665, recall = 0.004766657588961511.\n",
      "Training on epoch 25 minibatch 4801/5000 completed\n",
      " bpr_loss on current minibatch is 0.693861, and regularization loss is 0.000714.\n",
      " Top K precision = 0.018644067796610167, recall = 0.008947961177745304.\n",
      "Training on epoch 25 minibatch 4901/5000 completed\n",
      " bpr_loss on current minibatch is 0.693751, and regularization loss is 0.000603.\n",
      " Top K precision = 0.016666666666666666, recall = 0.005190079916310816.\n",
      "\n",
      "Training on 25 epoch completed.\n",
      " Average bpr_loss on train set is 0.011563 for the current epoch.\n",
      " Training top K precision = 0.016300000000000123, recall = 0.007184741793750913.\n",
      " Average bpr_loss on the validation set is 2e-06, and regularization loss is 0.0.\n",
      " Validation top K precision = 0.014700000000000105, recall = 0.006511890801039289.\n",
      "\n",
      "Training on the 26 epoch\n",
      "Training on epoch 26 minibatch 1/5000 completed\n",
      " bpr_loss on current minibatch is 0.69368, and regularization loss is 0.000533.\n",
      " Top K precision = 0.008771929824561403, recall = 0.0031700463279410646.\n",
      "Training on epoch 26 minibatch 101/5000 completed\n",
      " bpr_loss on current minibatch is 0.693741, and regularization loss is 0.000594.\n",
      " Top K precision = 0.01, recall = 0.004808020984491573.\n",
      "Training on epoch 26 minibatch 201/5000 completed\n",
      " bpr_loss on current minibatch is 0.693807, and regularization loss is 0.00066.\n",
      " Top K precision = 0.013559322033898305, recall = 0.005690978042672957.\n",
      "Training on epoch 26 minibatch 301/5000 completed\n",
      " bpr_loss on current minibatch is 0.693822, and regularization loss is 0.000675.\n",
      " Top K precision = 0.008333333333333333, recall = 0.0029361155413786992.\n",
      "Training on epoch 26 minibatch 401/5000 completed\n",
      " bpr_loss on current minibatch is 0.693877, and regularization loss is 0.00073.\n",
      " Top K precision = 0.013333333333333332, recall = 0.005286400135628747.\n",
      "Training on epoch 26 minibatch 501/5000 completed\n",
      " bpr_loss on current minibatch is 0.693901, and regularization loss is 0.000754.\n",
      " Top K precision = 0.017241379310344827, recall = 0.006403693972445769.\n",
      "Training on epoch 26 minibatch 601/5000 completed\n",
      " bpr_loss on current minibatch is 0.693706, and regularization loss is 0.000559.\n",
      " Top K precision = 0.021666666666666667, recall = 0.008172246301019806.\n",
      "Training on epoch 26 minibatch 701/5000 completed\n",
      " bpr_loss on current minibatch is 0.69381, and regularization loss is 0.000663.\n",
      " Top K precision = 0.006666666666666667, recall = 0.0022255362900024836.\n",
      "Training on epoch 26 minibatch 801/5000 completed\n",
      " bpr_loss on current minibatch is 0.693635, and regularization loss is 0.000488.\n",
      " Top K precision = 0.011666666666666665, recall = 0.0041343193683879955.\n",
      "Training on epoch 26 minibatch 901/5000 completed\n",
      " bpr_loss on current minibatch is 0.693949, and regularization loss is 0.000802.\n",
      " Top K precision = 0.011864406779661016, recall = 0.004615562535190747.\n",
      "Training on epoch 26 minibatch 1001/5000 completed\n",
      " bpr_loss on current minibatch is 0.693706, and regularization loss is 0.000559.\n",
      " Top K precision = 0.016666666666666666, recall = 0.005437468027349377.\n",
      "Training on epoch 26 minibatch 1101/5000 completed\n",
      " bpr_loss on current minibatch is 0.693805, and regularization loss is 0.000657.\n",
      " Top K precision = 0.011864406779661016, recall = 0.004460045624952544.\n",
      "Training on epoch 26 minibatch 1201/5000 completed\n",
      " bpr_loss on current minibatch is 0.69376, and regularization loss is 0.000613.\n",
      " Top K precision = 0.016666666666666666, recall = 0.007650085044070689.\n",
      "Training on epoch 26 minibatch 1301/5000 completed\n",
      " bpr_loss on current minibatch is 0.6938, and regularization loss is 0.000653.\n",
      " Top K precision = 0.00847457627118644, recall = 0.003335695624946294.\n",
      "Training on epoch 26 minibatch 1401/5000 completed\n",
      " bpr_loss on current minibatch is 0.69382, and regularization loss is 0.000672.\n",
      " Top K precision = 0.013333333333333332, recall = 0.008306076639409974.\n",
      "Training on epoch 26 minibatch 1501/5000 completed\n",
      " bpr_loss on current minibatch is 0.693827, and regularization loss is 0.00068.\n",
      " Top K precision = 0.01, recall = 0.0036940235528441427.\n",
      "Training on epoch 26 minibatch 1601/5000 completed\n",
      " bpr_loss on current minibatch is 0.693922, and regularization loss is 0.000775.\n",
      " Top K precision = 0.010344827586206896, recall = 0.004183816768149601.\n",
      "Training on epoch 26 minibatch 1701/5000 completed\n",
      " bpr_loss on current minibatch is 0.693803, and regularization loss is 0.000656.\n",
      " Top K precision = 0.020689655172413793, recall = 0.011585843791799917.\n",
      "Training on epoch 26 minibatch 1801/5000 completed\n",
      " bpr_loss on current minibatch is 0.693837, and regularization loss is 0.00069.\n",
      " Top K precision = 0.011864406779661016, recall = 0.005783903719457524.\n",
      "Training on epoch 26 minibatch 1901/5000 completed\n",
      " bpr_loss on current minibatch is 0.693736, and regularization loss is 0.000589.\n",
      " Top K precision = 0.023728813559322035, recall = 0.012084233960465726.\n",
      "Training on epoch 26 minibatch 2001/5000 completed\n",
      " bpr_loss on current minibatch is 0.693795, and regularization loss is 0.000648.\n",
      " Top K precision = 0.01, recall = 0.004752140581441657.\n",
      "Training on epoch 26 minibatch 2101/5000 completed\n",
      " bpr_loss on current minibatch is 0.69383, and regularization loss is 0.000683.\n",
      " Top K precision = 0.00847457627118644, recall = 0.004051010953690013.\n",
      "Training on epoch 26 minibatch 2201/5000 completed\n",
      " bpr_loss on current minibatch is 0.693804, and regularization loss is 0.000657.\n",
      " Top K precision = 0.014999999999999998, recall = 0.009361725019619757.\n",
      "Training on epoch 26 minibatch 2301/5000 completed\n",
      " bpr_loss on current minibatch is 0.693842, and regularization loss is 0.000695.\n",
      " Top K precision = 0.015254237288135592, recall = 0.007557430741244721.\n",
      "Training on epoch 26 minibatch 2401/5000 completed\n",
      " bpr_loss on current minibatch is 0.693945, and regularization loss is 0.000798.\n",
      " Top K precision = 0.008333333333333333, recall = 0.003936594944190593.\n",
      "Training on epoch 26 minibatch 2501/5000 completed\n",
      " bpr_loss on current minibatch is 0.693757, and regularization loss is 0.00061.\n",
      " Top K precision = 0.014035087719298244, recall = 0.00561165372378187.\n",
      "Training on epoch 26 minibatch 2601/5000 completed\n",
      " bpr_loss on current minibatch is 0.693833, and regularization loss is 0.000686.\n",
      " Top K precision = 0.01833333333333333, recall = 0.009592142894774471.\n",
      "Training on epoch 26 minibatch 2701/5000 completed\n",
      " bpr_loss on current minibatch is 0.693826, and regularization loss is 0.000679.\n",
      " Top K precision = 0.023728813559322035, recall = 0.009411453394467535.\n",
      "Training on epoch 26 minibatch 2801/5000 completed\n",
      " bpr_loss on current minibatch is 0.693688, and regularization loss is 0.000541.\n",
      " Top K precision = 0.014999999999999998, recall = 0.01178890638494297.\n",
      "Training on epoch 26 minibatch 2901/5000 completed\n",
      " bpr_loss on current minibatch is 0.693838, and regularization loss is 0.000691.\n",
      " Top K precision = 0.015254237288135592, recall = 0.006025661066191648.\n",
      "Training on epoch 26 minibatch 3001/5000 completed\n",
      " bpr_loss on current minibatch is 0.694022, and regularization loss is 0.000874.\n",
      " Top K precision = 0.006779661016949153, recall = 0.006161493873358281.\n",
      "Training on epoch 26 minibatch 3101/5000 completed\n",
      " bpr_loss on current minibatch is 0.693806, and regularization loss is 0.000658.\n",
      " Top K precision = 0.008333333333333333, recall = 0.0033545349577958276.\n",
      "Training on epoch 26 minibatch 3201/5000 completed\n",
      " bpr_loss on current minibatch is 0.693987, and regularization loss is 0.000839.\n",
      " Top K precision = 0.015517241379310343, recall = 0.005573361749183722.\n",
      "Training on epoch 26 minibatch 3301/5000 completed\n",
      " bpr_loss on current minibatch is 0.693699, and regularization loss is 0.000552.\n",
      " Top K precision = 0.02, recall = 0.010130645800893935.\n",
      "Training on epoch 26 minibatch 3401/5000 completed\n",
      " bpr_loss on current minibatch is 0.693692, and regularization loss is 0.000545.\n",
      " Top K precision = 0.013333333333333332, recall = 0.007136146125116713.\n",
      "Training on epoch 26 minibatch 3501/5000 completed\n",
      " bpr_loss on current minibatch is 0.69374, and regularization loss is 0.000593.\n",
      " Top K precision = 0.006666666666666667, recall = 0.0031836219336219334.\n",
      "Training on epoch 26 minibatch 3601/5000 completed\n",
      " bpr_loss on current minibatch is 0.693792, and regularization loss is 0.000645.\n",
      " Top K precision = 0.011666666666666665, recall = 0.006994865449166525.\n",
      "Training on epoch 26 minibatch 3701/5000 completed\n",
      " bpr_loss on current minibatch is 0.693792, and regularization loss is 0.000644.\n",
      " Top K precision = 0.016666666666666666, recall = 0.00657381672630627.\n",
      "Training on epoch 26 minibatch 3801/5000 completed\n",
      " bpr_loss on current minibatch is 0.693836, and regularization loss is 0.000688.\n",
      " Top K precision = 0.00847457627118644, recall = 0.003126204491445154.\n",
      "Training on epoch 26 minibatch 3901/5000 completed\n",
      " bpr_loss on current minibatch is 0.693761, and regularization loss is 0.000613.\n",
      " Top K precision = 0.013333333333333332, recall = 0.007239998051782949.\n",
      "Training on epoch 26 minibatch 4001/5000 completed\n",
      " bpr_loss on current minibatch is 0.693819, and regularization loss is 0.000672.\n",
      " Top K precision = 0.01833333333333333, recall = 0.008714393812433028.\n",
      "Training on epoch 26 minibatch 4101/5000 completed\n",
      " bpr_loss on current minibatch is 0.693828, and regularization loss is 0.000681.\n",
      " Top K precision = 0.0033898305084745766, recall = 0.0011413570735604635.\n",
      "Training on epoch 26 minibatch 4201/5000 completed\n",
      " bpr_loss on current minibatch is 0.693851, and regularization loss is 0.000704.\n",
      " Top K precision = 0.008333333333333333, recall = 0.004308620467157053.\n",
      "Training on epoch 26 minibatch 4301/5000 completed\n",
      " bpr_loss on current minibatch is 0.693675, and regularization loss is 0.000528.\n",
      " Top K precision = 0.013559322033898305, recall = 0.007280632848927963.\n",
      "Training on epoch 26 minibatch 4401/5000 completed\n",
      " bpr_loss on current minibatch is 0.693714, and regularization loss is 0.000567.\n",
      " Top K precision = 0.006666666666666667, recall = 0.002190155523488857.\n",
      "Training on epoch 26 minibatch 4501/5000 completed\n",
      " bpr_loss on current minibatch is 0.693799, and regularization loss is 0.000651.\n",
      " Top K precision = 0.008333333333333333, recall = 0.0033926250812215722.\n",
      "Training on epoch 26 minibatch 4601/5000 completed\n",
      " bpr_loss on current minibatch is 0.693959, and regularization loss is 0.000812.\n",
      " Top K precision = 0.011666666666666665, recall = 0.006071520575480645.\n",
      "Training on epoch 26 minibatch 4701/5000 completed\n",
      " bpr_loss on current minibatch is 0.693834, and regularization loss is 0.000687.\n",
      " Top K precision = 0.011666666666666665, recall = 0.005023224324694914.\n",
      "Training on epoch 26 minibatch 4801/5000 completed\n",
      " bpr_loss on current minibatch is 0.693682, and regularization loss is 0.000535.\n",
      " Top K precision = 0.011666666666666665, recall = 0.004635325687957267.\n",
      "Training on epoch 26 minibatch 4901/5000 completed\n",
      " bpr_loss on current minibatch is 0.693851, and regularization loss is 0.000704.\n",
      " Top K precision = 0.013559322033898305, recall = 0.006300422087350384.\n",
      "\n",
      "Training on 26 epoch completed.\n",
      " Average bpr_loss on train set is 0.011563 for the current epoch.\n",
      " Training top K precision = 0.013133333333333415, recall = 0.00596790559734144.\n",
      " Average bpr_loss on the validation set is 2e-06, and regularization loss is 0.0.\n",
      " Validation top K precision = 0.01336666666666675, recall = 0.00567535870200148.\n",
      "\n",
      "Training on the 27 epoch\n",
      "Training on epoch 27 minibatch 1/5000 completed\n",
      " bpr_loss on current minibatch is 0.693983, and regularization loss is 0.000835.\n",
      " Top K precision = 0.010169491525423728, recall = 0.006666469984955971.\n",
      "Training on epoch 27 minibatch 101/5000 completed\n",
      " bpr_loss on current minibatch is 0.693783, and regularization loss is 0.000635.\n",
      " Top K precision = 0.014999999999999998, recall = 0.00664015320664937.\n",
      "Training on epoch 27 minibatch 201/5000 completed\n",
      " bpr_loss on current minibatch is 0.693912, and regularization loss is 0.000764.\n",
      " Top K precision = 0.014999999999999998, recall = 0.005435732050790375.\n",
      "Training on epoch 27 minibatch 301/5000 completed\n",
      " bpr_loss on current minibatch is 0.693784, and regularization loss is 0.000637.\n",
      " Top K precision = 0.013559322033898305, recall = 0.0044940428734983285.\n",
      "Training on epoch 27 minibatch 401/5000 completed\n",
      " bpr_loss on current minibatch is 0.693857, and regularization loss is 0.00071.\n",
      " Top K precision = 0.01833333333333333, recall = 0.009238092258925594.\n",
      "Training on epoch 27 minibatch 501/5000 completed\n",
      " bpr_loss on current minibatch is 0.693899, and regularization loss is 0.000752.\n",
      " Top K precision = 0.016949152542372878, recall = 0.006273483624831221.\n",
      "Training on epoch 27 minibatch 601/5000 completed\n",
      " bpr_loss on current minibatch is 0.693788, and regularization loss is 0.000641.\n",
      " Top K precision = 0.014999999999999998, recall = 0.006797084841841874.\n",
      "Training on epoch 27 minibatch 701/5000 completed\n",
      " bpr_loss on current minibatch is 0.694007, and regularization loss is 0.00086.\n",
      " Top K precision = 0.006779661016949153, recall = 0.003753308838054601.\n",
      "Training on epoch 27 minibatch 801/5000 completed\n",
      " bpr_loss on current minibatch is 0.693717, and regularization loss is 0.00057.\n",
      " Top K precision = 0.008333333333333333, recall = 0.0036577805974357695.\n",
      "Training on epoch 27 minibatch 901/5000 completed\n",
      " bpr_loss on current minibatch is 0.693772, and regularization loss is 0.000625.\n",
      " Top K precision = 0.01, recall = 0.0048966670019301595.\n",
      "Training on epoch 27 minibatch 1001/5000 completed\n",
      " bpr_loss on current minibatch is 0.693834, and regularization loss is 0.000687.\n",
      " Top K precision = 0.01833333333333333, recall = 0.0075034123703034365.\n",
      "Training on epoch 27 minibatch 1101/5000 completed\n",
      " bpr_loss on current minibatch is 0.693906, and regularization loss is 0.000758.\n",
      " Top K precision = 0.011666666666666665, recall = 0.003620476745476745.\n",
      "Training on epoch 27 minibatch 1201/5000 completed\n",
      " bpr_loss on current minibatch is 0.693744, and regularization loss is 0.000597.\n",
      " Top K precision = 0.0033333333333333335, recall = 0.002182539682539682.\n",
      "Training on epoch 27 minibatch 1301/5000 completed\n",
      " bpr_loss on current minibatch is 0.693603, and regularization loss is 0.000456.\n",
      " Top K precision = 0.013333333333333332, recall = 0.005711340984596799.\n",
      "Training on epoch 27 minibatch 1401/5000 completed\n",
      " bpr_loss on current minibatch is 0.693757, and regularization loss is 0.00061.\n",
      " Top K precision = 0.008333333333333333, recall = 0.00279842225675559.\n",
      "Training on epoch 27 minibatch 1501/5000 completed\n",
      " bpr_loss on current minibatch is 0.693825, and regularization loss is 0.000678.\n",
      " Top K precision = 0.016666666666666666, recall = 0.00671346083110789.\n",
      "Training on epoch 27 minibatch 1601/5000 completed\n",
      " bpr_loss on current minibatch is 0.693803, and regularization loss is 0.000655.\n",
      " Top K precision = 0.015517241379310345, recall = 0.007931186303397257.\n",
      "Training on epoch 27 minibatch 1701/5000 completed\n",
      " bpr_loss on current minibatch is 0.693584, and regularization loss is 0.000436.\n",
      " Top K precision = 0.005000000000000001, recall = 0.002777777777777778.\n",
      "Training on epoch 27 minibatch 1801/5000 completed\n",
      " bpr_loss on current minibatch is 0.693838, and regularization loss is 0.000691.\n",
      " Top K precision = 0.01833333333333333, recall = 0.008101348180490252.\n",
      "Training on epoch 27 minibatch 1901/5000 completed\n",
      " bpr_loss on current minibatch is 0.693682, and regularization loss is 0.000535.\n",
      " Top K precision = 0.005084745762711865, recall = 0.0020905026854919112.\n",
      "Training on epoch 27 minibatch 2001/5000 completed\n",
      " bpr_loss on current minibatch is 0.693788, and regularization loss is 0.000641.\n",
      " Top K precision = 0.00847457627118644, recall = 0.0030701407820051883.\n",
      "Training on epoch 27 minibatch 2101/5000 completed\n",
      " bpr_loss on current minibatch is 0.693747, and regularization loss is 0.000599.\n",
      " Top K precision = 0.006779661016949153, recall = 0.002576898932831136.\n",
      "Training on epoch 27 minibatch 2201/5000 completed\n",
      " bpr_loss on current minibatch is 0.693934, and regularization loss is 0.000787.\n",
      " Top K precision = 0.00847457627118644, recall = 0.002631505451493762.\n",
      "Training on epoch 27 minibatch 2301/5000 completed\n",
      " bpr_loss on current minibatch is 0.693851, and regularization loss is 0.000704.\n",
      " Top K precision = 0.011666666666666665, recall = 0.006317687896457335.\n",
      "Training on epoch 27 minibatch 2401/5000 completed\n",
      " bpr_loss on current minibatch is 0.693864, and regularization loss is 0.000717.\n",
      " Top K precision = 0.010344827586206896, recall = 0.002400026537957572.\n",
      "Training on epoch 27 minibatch 2501/5000 completed\n",
      " bpr_loss on current minibatch is 0.693736, and regularization loss is 0.000589.\n",
      " Top K precision = 0.010169491525423728, recall = 0.006197581705433152.\n",
      "Training on epoch 27 minibatch 2601/5000 completed\n",
      " bpr_loss on current minibatch is 0.693756, and regularization loss is 0.000609.\n",
      " Top K precision = 0.02033898305084746, recall = 0.008474498815646426.\n",
      "Training on epoch 27 minibatch 2701/5000 completed\n",
      " bpr_loss on current minibatch is 0.693767, and regularization loss is 0.00062.\n",
      " Top K precision = 0.02, recall = 0.009049183103402124.\n",
      "Training on epoch 27 minibatch 2801/5000 completed\n",
      " bpr_loss on current minibatch is 0.693714, and regularization loss is 0.000567.\n",
      " Top K precision = 0.006779661016949153, recall = 0.003654606356369488.\n",
      "Training on epoch 27 minibatch 2901/5000 completed\n",
      " bpr_loss on current minibatch is 0.693792, and regularization loss is 0.000645.\n",
      " Top K precision = 0.01, recall = 0.004070341684758161.\n",
      "Training on epoch 27 minibatch 3001/5000 completed\n",
      " bpr_loss on current minibatch is 0.693793, and regularization loss is 0.000646.\n",
      " Top K precision = 0.016666666666666666, recall = 0.005227869124046034.\n",
      "Training on epoch 27 minibatch 3101/5000 completed\n",
      " bpr_loss on current minibatch is 0.693774, and regularization loss is 0.000627.\n",
      " Top K precision = 0.01694915254237288, recall = 0.005990426557819208.\n",
      "Training on epoch 27 minibatch 3201/5000 completed\n",
      " bpr_loss on current minibatch is 0.693762, and regularization loss is 0.000615.\n",
      " Top K precision = 0.017241379310344827, recall = 0.00714306719864796.\n",
      "Training on epoch 27 minibatch 3301/5000 completed\n",
      " bpr_loss on current minibatch is 0.693974, and regularization loss is 0.000827.\n",
      " Top K precision = 0.013333333333333334, recall = 0.00605932826046678.\n",
      "Training on epoch 27 minibatch 3401/5000 completed\n",
      " bpr_loss on current minibatch is 0.693592, and regularization loss is 0.000445.\n",
      " Top K precision = 0.013333333333333332, recall = 0.005576873576873577.\n",
      "Training on epoch 27 minibatch 3501/5000 completed\n",
      " bpr_loss on current minibatch is 0.693834, and regularization loss is 0.000687.\n",
      " Top K precision = 0.01, recall = 0.004424733762969058.\n",
      "Training on epoch 27 minibatch 3601/5000 completed\n",
      " bpr_loss on current minibatch is 0.69375, and regularization loss is 0.000603.\n",
      " Top K precision = 0.013333333333333332, recall = 0.006676587301587301.\n",
      "Training on epoch 27 minibatch 3701/5000 completed\n",
      " bpr_loss on current minibatch is 0.69378, and regularization loss is 0.000633.\n",
      " Top K precision = 0.008620689655172414, recall = 0.0029651011598273262.\n",
      "Training on epoch 27 minibatch 3801/5000 completed\n",
      " bpr_loss on current minibatch is 0.693639, and regularization loss is 0.000492.\n",
      " Top K precision = 0.02, recall = 0.009288100362654076.\n",
      "Training on epoch 27 minibatch 3901/5000 completed\n",
      " bpr_loss on current minibatch is 0.693698, and regularization loss is 0.000551.\n",
      " Top K precision = 0.010169491525423728, recall = 0.0025378416133966385.\n",
      "Training on epoch 27 minibatch 4001/5000 completed\n",
      " bpr_loss on current minibatch is 0.693712, and regularization loss is 0.000565.\n",
      " Top K precision = 0.02033898305084746, recall = 0.009119613825233809.\n",
      "Training on epoch 27 minibatch 4101/5000 completed\n",
      " bpr_loss on current minibatch is 0.69369, and regularization loss is 0.000542.\n",
      " Top K precision = 0.013333333333333332, recall = 0.006737831805761939.\n",
      "Training on epoch 27 minibatch 4201/5000 completed\n",
      " bpr_loss on current minibatch is 0.693729, and regularization loss is 0.000581.\n",
      " Top K precision = 0.016666666666666666, recall = 0.007508899053016701.\n",
      "Training on epoch 27 minibatch 4301/5000 completed\n",
      " bpr_loss on current minibatch is 0.69372, and regularization loss is 0.000573.\n",
      " Top K precision = 0.020338983050847456, recall = 0.009865008434103779.\n",
      "Training on epoch 27 minibatch 4401/5000 completed\n",
      " bpr_loss on current minibatch is 0.693853, and regularization loss is 0.000706.\n",
      " Top K precision = 0.008333333333333333, recall = 0.0042519841269841275.\n",
      "Training on epoch 27 minibatch 4501/5000 completed\n",
      " bpr_loss on current minibatch is 0.693769, and regularization loss is 0.000621.\n",
      " Top K precision = 0.005000000000000001, recall = 0.00253968253968254.\n",
      "Training on epoch 27 minibatch 4601/5000 completed\n",
      " bpr_loss on current minibatch is 0.693854, and regularization loss is 0.000707.\n",
      " Top K precision = 0.01, recall = 0.008524499379762537.\n",
      "Training on epoch 27 minibatch 4701/5000 completed\n",
      " bpr_loss on current minibatch is 0.693865, and regularization loss is 0.000718.\n",
      " Top K precision = 0.011666666666666665, recall = 0.003106308833322376.\n",
      "Training on epoch 27 minibatch 4801/5000 completed\n",
      " bpr_loss on current minibatch is 0.693826, and regularization loss is 0.000679.\n",
      " Top K precision = 0.011666666666666665, recall = 0.006092835791293014.\n",
      "Training on epoch 27 minibatch 4901/5000 completed\n",
      " bpr_loss on current minibatch is 0.693717, and regularization loss is 0.00057.\n",
      " Top K precision = 0.013559322033898306, recall = 0.005315939480306843.\n",
      "\n",
      "Training on 27 epoch completed.\n",
      " Average bpr_loss on train set is 0.011563 for the current epoch.\n",
      " Training top K precision = 0.014666666666666767, recall = 0.007175747992977082.\n",
      " Average bpr_loss on the validation set is 2e-06, and regularization loss is 0.0.\n",
      " Validation top K precision = 0.014466666666666773, recall = 0.0071492692761344.\n",
      "\n",
      "Training on the 28 epoch\n",
      "Training on epoch 28 minibatch 1/5000 completed\n",
      " bpr_loss on current minibatch is 0.693944, and regularization loss is 0.000796.\n",
      " Top K precision = 0.020338983050847456, recall = 0.008582749986427966.\n",
      "Training on epoch 28 minibatch 101/5000 completed\n",
      " bpr_loss on current minibatch is 0.693854, and regularization loss is 0.000706.\n",
      " Top K precision = 0.01, recall = 0.003901445441300514.\n",
      "Training on epoch 28 minibatch 201/5000 completed\n",
      " bpr_loss on current minibatch is 0.693814, and regularization loss is 0.000667.\n",
      " Top K precision = 0.008333333333333333, recall = 0.0037642985669301457.\n",
      "Training on epoch 28 minibatch 301/5000 completed\n",
      " bpr_loss on current minibatch is 0.693932, and regularization loss is 0.000785.\n",
      " Top K precision = 0.016666666666666666, recall = 0.004711608682645268.\n",
      "Training on epoch 28 minibatch 401/5000 completed\n",
      " bpr_loss on current minibatch is 0.693805, and regularization loss is 0.000658.\n",
      " Top K precision = 0.005000000000000001, recall = 0.0027417027417027413.\n",
      "Training on epoch 28 minibatch 501/5000 completed\n",
      " bpr_loss on current minibatch is 0.693821, and regularization loss is 0.000674.\n",
      " Top K precision = 0.014999999999999998, recall = 0.0061629442055495445.\n",
      "Training on epoch 28 minibatch 601/5000 completed\n",
      " bpr_loss on current minibatch is 0.693759, and regularization loss is 0.000612.\n",
      " Top K precision = 0.0033333333333333335, recall = 0.0012329174093879977.\n",
      "Training on epoch 28 minibatch 701/5000 completed\n",
      " bpr_loss on current minibatch is 0.693681, and regularization loss is 0.000534.\n",
      " Top K precision = 0.008333333333333333, recall = 0.0040997831615680585.\n",
      "Training on epoch 28 minibatch 801/5000 completed\n",
      " bpr_loss on current minibatch is 0.693848, and regularization loss is 0.0007.\n",
      " Top K precision = 0.016666666666666666, recall = 0.006886898578572674.\n",
      "Training on epoch 28 minibatch 901/5000 completed\n",
      " bpr_loss on current minibatch is 0.693895, and regularization loss is 0.000748.\n",
      " Top K precision = 0.011666666666666665, recall = 0.006311442525728239.\n",
      "Training on epoch 28 minibatch 1001/5000 completed\n",
      " bpr_loss on current minibatch is 0.693859, and regularization loss is 0.000711.\n",
      " Top K precision = 0.013333333333333332, recall = 0.004850417753308221.\n",
      "Training on epoch 28 minibatch 1101/5000 completed\n",
      " bpr_loss on current minibatch is 0.69372, and regularization loss is 0.000573.\n",
      " Top K precision = 0.016949152542372878, recall = 0.007597609408426955.\n",
      "Training on epoch 28 minibatch 1201/5000 completed\n",
      " bpr_loss on current minibatch is 0.693568, and regularization loss is 0.000421.\n",
      " Top K precision = 0.017241379310344827, recall = 0.006774963408891028.\n",
      "Training on epoch 28 minibatch 1301/5000 completed\n",
      " bpr_loss on current minibatch is 0.693725, and regularization loss is 0.000577.\n",
      " Top K precision = 0.005000000000000001, recall = 0.001822484479685291.\n",
      "Training on epoch 28 minibatch 1401/5000 completed\n",
      " bpr_loss on current minibatch is 0.693728, and regularization loss is 0.00058.\n",
      " Top K precision = 0.013333333333333334, recall = 0.0072135447135447135.\n",
      "Training on epoch 28 minibatch 1501/5000 completed\n",
      " bpr_loss on current minibatch is 0.693903, and regularization loss is 0.000755.\n",
      " Top K precision = 0.015000000000000001, recall = 0.006518605230877384.\n",
      "Training on epoch 28 minibatch 1601/5000 completed\n",
      " bpr_loss on current minibatch is 0.693881, and regularization loss is 0.000734.\n",
      " Top K precision = 0.011666666666666665, recall = 0.005863393988393989.\n",
      "Training on epoch 28 minibatch 1701/5000 completed\n",
      " bpr_loss on current minibatch is 0.693792, and regularization loss is 0.000645.\n",
      " Top K precision = 0.00847457627118644, recall = 0.003648697163804017.\n",
      "Training on epoch 28 minibatch 1801/5000 completed\n",
      " bpr_loss on current minibatch is 0.693765, and regularization loss is 0.000617.\n",
      " Top K precision = 0.006896551724137932, recall = 0.00226455946096126.\n",
      "Training on epoch 28 minibatch 1901/5000 completed\n",
      " bpr_loss on current minibatch is 0.69389, and regularization loss is 0.000742.\n",
      " Top K precision = 0.013559322033898305, recall = 0.004907176018841023.\n",
      "Training on epoch 28 minibatch 2001/5000 completed\n",
      " bpr_loss on current minibatch is 0.693753, and regularization loss is 0.000606.\n",
      " Top K precision = 0.013333333333333334, recall = 0.007668099647266314.\n",
      "Training on epoch 28 minibatch 2101/5000 completed\n",
      " bpr_loss on current minibatch is 0.693923, and regularization loss is 0.000776.\n",
      " Top K precision = 0.014999999999999998, recall = 0.006456258524756977.\n",
      "Training on epoch 28 minibatch 2201/5000 completed\n",
      " bpr_loss on current minibatch is 0.693891, and regularization loss is 0.000743.\n",
      " Top K precision = 0.006666666666666667, recall = 0.003067396313364055.\n",
      "Training on epoch 28 minibatch 2301/5000 completed\n",
      " bpr_loss on current minibatch is 0.694004, and regularization loss is 0.000857.\n",
      " Top K precision = 0.008333333333333333, recall = 0.007252415458937198.\n",
      "Training on epoch 28 minibatch 2401/5000 completed\n",
      " bpr_loss on current minibatch is 0.693758, and regularization loss is 0.000611.\n",
      " Top K precision = 0.006779661016949153, recall = 0.0029151773703831813.\n",
      "Training on epoch 28 minibatch 2501/5000 completed\n",
      " bpr_loss on current minibatch is 0.693873, and regularization loss is 0.000726.\n",
      " Top K precision = 0.018333333333333333, recall = 0.009270370125633283.\n",
      "Training on epoch 28 minibatch 2601/5000 completed\n",
      " bpr_loss on current minibatch is 0.693862, and regularization loss is 0.000715.\n",
      " Top K precision = 0.015517241379310343, recall = 0.00558623631538606.\n",
      "Training on epoch 28 minibatch 2701/5000 completed\n",
      " bpr_loss on current minibatch is 0.693844, and regularization loss is 0.000697.\n",
      " Top K precision = 0.00847457627118644, recall = 0.0029831423408586653.\n",
      "Training on epoch 28 minibatch 2801/5000 completed\n",
      " bpr_loss on current minibatch is 0.693779, and regularization loss is 0.000632.\n",
      " Top K precision = 0.008333333333333333, recall = 0.0034419034419034414.\n",
      "Training on epoch 28 minibatch 2901/5000 completed\n",
      " bpr_loss on current minibatch is 0.693712, and regularization loss is 0.000565.\n",
      " Top K precision = 0.008333333333333333, recall = 0.002631234851384105.\n",
      "Training on epoch 28 minibatch 3001/5000 completed\n",
      " bpr_loss on current minibatch is 0.693707, and regularization loss is 0.00056.\n",
      " Top K precision = 0.018644067796610167, recall = 0.007804466164349698.\n",
      "Training on epoch 28 minibatch 3101/5000 completed\n",
      " bpr_loss on current minibatch is 0.693815, and regularization loss is 0.000668.\n",
      " Top K precision = 0.008620689655172414, recall = 0.0043770525451559935.\n",
      "Training on epoch 28 minibatch 3201/5000 completed\n",
      " bpr_loss on current minibatch is 0.693742, and regularization loss is 0.000595.\n",
      " Top K precision = 0.01, recall = 0.003386858105007751.\n",
      "Training on epoch 28 minibatch 3301/5000 completed\n",
      " bpr_loss on current minibatch is 0.693649, and regularization loss is 0.000502.\n",
      " Top K precision = 0.005084745762711865, recall = 0.0021625101385819236.\n",
      "Training on epoch 28 minibatch 3401/5000 completed\n",
      " bpr_loss on current minibatch is 0.693923, and regularization loss is 0.000775.\n",
      " Top K precision = 0.016666666666666666, recall = 0.00607256334158508.\n",
      "Training on epoch 28 minibatch 3501/5000 completed\n",
      " bpr_loss on current minibatch is 0.693852, and regularization loss is 0.000705.\n",
      " Top K precision = 0.02033898305084746, recall = 0.009988385594525577.\n",
      "Training on epoch 28 minibatch 3601/5000 completed\n",
      " bpr_loss on current minibatch is 0.693652, and regularization loss is 0.000504.\n",
      " Top K precision = 0.00847457627118644, recall = 0.003941976845634294.\n",
      "Training on epoch 28 minibatch 3701/5000 completed\n",
      " bpr_loss on current minibatch is 0.693759, and regularization loss is 0.000611.\n",
      " Top K precision = 0.014999999999999998, recall = 0.007118116688404481.\n",
      "Training on epoch 28 minibatch 3801/5000 completed\n",
      " bpr_loss on current minibatch is 0.693704, and regularization loss is 0.000557.\n",
      " Top K precision = 0.013333333333333332, recall = 0.008053118908382067.\n",
      "Training on epoch 28 minibatch 3901/5000 completed\n",
      " bpr_loss on current minibatch is 0.693805, and regularization loss is 0.000658.\n",
      " Top K precision = 0.006779661016949153, recall = 0.003709326565757274.\n",
      "Training on epoch 28 minibatch 4001/5000 completed\n",
      " bpr_loss on current minibatch is 0.693765, and regularization loss is 0.000618.\n",
      " Top K precision = 0.023728813559322035, recall = 0.010775649730835187.\n",
      "Training on epoch 28 minibatch 4101/5000 completed\n",
      " bpr_loss on current minibatch is 0.693708, and regularization loss is 0.000561.\n",
      " Top K precision = 0.010169491525423728, recall = 0.00506500758245524.\n",
      "Training on epoch 28 minibatch 4201/5000 completed\n",
      " bpr_loss on current minibatch is 0.693845, and regularization loss is 0.000697.\n",
      " Top K precision = 0.013333333333333332, recall = 0.003644100078859135.\n",
      "Training on epoch 28 minibatch 4301/5000 completed\n",
      " bpr_loss on current minibatch is 0.693736, and regularization loss is 0.000589.\n",
      " Top K precision = 0.01833333333333333, recall = 0.0085902832460886.\n",
      "Training on epoch 28 minibatch 4401/5000 completed\n",
      " bpr_loss on current minibatch is 0.693711, and regularization loss is 0.000564.\n",
      " Top K precision = 0.013333333333333332, recall = 0.004025035587535588.\n",
      "Training on epoch 28 minibatch 4501/5000 completed\n",
      " bpr_loss on current minibatch is 0.693688, and regularization loss is 0.000541.\n",
      " Top K precision = 0.010344827586206896, recall = 0.00402307070149136.\n",
      "Training on epoch 28 minibatch 4601/5000 completed\n",
      " bpr_loss on current minibatch is 0.693751, and regularization loss is 0.000603.\n",
      " Top K precision = 0.01833333333333333, recall = 0.0073792028619815.\n",
      "Training on epoch 28 minibatch 4701/5000 completed\n",
      " bpr_loss on current minibatch is 0.693897, and regularization loss is 0.00075.\n",
      " Top K precision = 0.005084745762711865, recall = 0.0021954740175079155.\n",
      "Training on epoch 28 minibatch 4801/5000 completed\n",
      " bpr_loss on current minibatch is 0.693734, and regularization loss is 0.000587.\n",
      " Top K precision = 0.006779661016949153, recall = 0.002479279468962593.\n",
      "Training on epoch 28 minibatch 4901/5000 completed\n",
      " bpr_loss on current minibatch is 0.693731, and regularization loss is 0.000584.\n",
      " Top K precision = 0.013333333333333332, recall = 0.008941496441496442.\n",
      "\n",
      "Training on 28 epoch completed.\n",
      " Average bpr_loss on train set is 0.011563 for the current epoch.\n",
      " Training top K precision = 0.01403333333333343, recall = 0.005801819883709764.\n",
      " Average bpr_loss on the validation set is 2e-06, and regularization loss is 0.0.\n",
      " Validation top K precision = 0.01500000000000011, recall = 0.006844562795652784.\n",
      "\n",
      "Training on the 29 epoch\n",
      "Training on epoch 29 minibatch 1/5000 completed\n",
      " bpr_loss on current minibatch is 0.693792, and regularization loss is 0.000645.\n",
      " Top K precision = 0.01, recall = 0.005284111060444849.\n",
      "Training on epoch 29 minibatch 101/5000 completed\n",
      " bpr_loss on current minibatch is 0.693733, and regularization loss is 0.000586.\n",
      " Top K precision = 0.015254237288135594, recall = 0.005986270232443004.\n",
      "Training on epoch 29 minibatch 201/5000 completed\n",
      " bpr_loss on current minibatch is 0.693975, and regularization loss is 0.000828.\n",
      " Top K precision = 0.01, recall = 0.005912130944331756.\n",
      "Training on epoch 29 minibatch 301/5000 completed\n",
      " bpr_loss on current minibatch is 0.693833, and regularization loss is 0.000686.\n",
      " Top K precision = 0.010169491525423728, recall = 0.003981661778271948.\n",
      "Training on epoch 29 minibatch 401/5000 completed\n",
      " bpr_loss on current minibatch is 0.693775, and regularization loss is 0.000628.\n",
      " Top K precision = 0.010169491525423728, recall = 0.0035181149145777.\n",
      "Training on epoch 29 minibatch 501/5000 completed\n",
      " bpr_loss on current minibatch is 0.693774, and regularization loss is 0.000627.\n",
      " Top K precision = 0.006779661016949153, recall = 0.002951834731495749.\n",
      "Training on epoch 29 minibatch 601/5000 completed\n",
      " bpr_loss on current minibatch is 0.693929, and regularization loss is 0.000782.\n",
      " Top K precision = 0.011864406779661016, recall = 0.004789522880411505.\n",
      "Training on epoch 29 minibatch 701/5000 completed\n",
      " bpr_loss on current minibatch is 0.693738, and regularization loss is 0.000591.\n",
      " Top K precision = 0.01, recall = 0.0028539352170506667.\n",
      "Training on epoch 29 minibatch 801/5000 completed\n",
      " bpr_loss on current minibatch is 0.693787, and regularization loss is 0.00064.\n",
      " Top K precision = 0.02, recall = 0.007482989096201777.\n",
      "Training on epoch 29 minibatch 901/5000 completed\n",
      " bpr_loss on current minibatch is 0.69376, and regularization loss is 0.000613.\n",
      " Top K precision = 0.01, recall = 0.003987411056376574.\n",
      "Training on epoch 29 minibatch 1001/5000 completed\n",
      " bpr_loss on current minibatch is 0.693779, and regularization loss is 0.000632.\n",
      " Top K precision = 0.006666666666666667, recall = 0.0029836829836829837.\n",
      "Training on epoch 29 minibatch 1101/5000 completed\n",
      " bpr_loss on current minibatch is 0.693829, and regularization loss is 0.000682.\n",
      " Top K precision = 0.006666666666666667, recall = 0.003621417797888387.\n",
      "Training on epoch 29 minibatch 1201/5000 completed\n",
      " bpr_loss on current minibatch is 0.693801, and regularization loss is 0.000654.\n",
      " Top K precision = 0.016949152542372878, recall = 0.006976798440216197.\n",
      "Training on epoch 29 minibatch 1301/5000 completed\n",
      " bpr_loss on current minibatch is 0.693892, and regularization loss is 0.000745.\n",
      " Top K precision = 0.008333333333333333, recall = 0.0035805860805860805.\n",
      "Training on epoch 29 minibatch 1401/5000 completed\n",
      " bpr_loss on current minibatch is 0.693765, and regularization loss is 0.000618.\n",
      " Top K precision = 0.013333333333333332, recall = 0.007217239124888379.\n",
      "Training on epoch 29 minibatch 1501/5000 completed\n",
      " bpr_loss on current minibatch is 0.693734, and regularization loss is 0.000586.\n",
      " Top K precision = 0.01833333333333333, recall = 0.008638693421588158.\n",
      "Training on epoch 29 minibatch 1601/5000 completed\n",
      " bpr_loss on current minibatch is 0.693879, and regularization loss is 0.000732.\n",
      " Top K precision = 0.013333333333333332, recall = 0.004016315088763374.\n",
      "Training on epoch 29 minibatch 1701/5000 completed\n",
      " bpr_loss on current minibatch is 0.693876, and regularization loss is 0.000729.\n",
      " Top K precision = 0.01929824561403509, recall = 0.009050520243143744.\n",
      "Training on epoch 29 minibatch 1801/5000 completed\n",
      " bpr_loss on current minibatch is 0.693779, and regularization loss is 0.000632.\n",
      " Top K precision = 0.011666666666666665, recall = 0.003098354274824863.\n",
      "Training on epoch 29 minibatch 1901/5000 completed\n",
      " bpr_loss on current minibatch is 0.693801, and regularization loss is 0.000654.\n",
      " Top K precision = 0.010169491525423728, recall = 0.003885823792876827.\n",
      "Training on epoch 29 minibatch 2001/5000 completed\n",
      " bpr_loss on current minibatch is 0.693878, and regularization loss is 0.000731.\n",
      " Top K precision = 0.01, recall = 0.00436008436008436.\n",
      "Training on epoch 29 minibatch 2101/5000 completed\n",
      " bpr_loss on current minibatch is 0.693636, and regularization loss is 0.000489.\n",
      " Top K precision = 0.008620689655172414, recall = 0.002501254333150885.\n",
      "Training on epoch 29 minibatch 2201/5000 completed\n",
      " bpr_loss on current minibatch is 0.693823, and regularization loss is 0.000676.\n",
      " Top K precision = 0.00847457627118644, recall = 0.0042859568898387925.\n",
      "Training on epoch 29 minibatch 2301/5000 completed\n",
      " bpr_loss on current minibatch is 0.693959, and regularization loss is 0.000812.\n",
      " Top K precision = 0.011864406779661016, recall = 0.004967226717764579.\n",
      "Training on epoch 29 minibatch 2401/5000 completed\n",
      " bpr_loss on current minibatch is 0.693978, and regularization loss is 0.000831.\n",
      " Top K precision = 0.01, recall = 0.004970656583559809.\n",
      "Training on epoch 29 minibatch 2501/5000 completed\n",
      " bpr_loss on current minibatch is 0.69378, and regularization loss is 0.000632.\n",
      " Top K precision = 0.006896551724137932, recall = 0.0026751814784269144.\n",
      "Training on epoch 29 minibatch 2601/5000 completed\n",
      " bpr_loss on current minibatch is 0.693748, and regularization loss is 0.000601.\n",
      " Top K precision = 0.013333333333333332, recall = 0.005002430910232328.\n",
      "Training on epoch 29 minibatch 2701/5000 completed\n",
      " bpr_loss on current minibatch is 0.693761, and regularization loss is 0.000614.\n",
      " Top K precision = 0.01, recall = 0.004592557084492568.\n",
      "Training on epoch 29 minibatch 2801/5000 completed\n",
      " bpr_loss on current minibatch is 0.693836, and regularization loss is 0.000689.\n",
      " Top K precision = 0.01, recall = 0.004990953490953491.\n",
      "Training on epoch 29 minibatch 2901/5000 completed\n",
      " bpr_loss on current minibatch is 0.693747, and regularization loss is 0.0006.\n",
      " Top K precision = 0.016949152542372878, recall = 0.007703061865574328.\n",
      "Training on epoch 29 minibatch 3001/5000 completed\n",
      " bpr_loss on current minibatch is 0.693907, and regularization loss is 0.00076.\n",
      " Top K precision = 0.01206896551724138, recall = 0.004590200981014195.\n",
      "Training on epoch 29 minibatch 3101/5000 completed\n",
      " bpr_loss on current minibatch is 0.693599, and regularization loss is 0.000452.\n",
      " Top K precision = 0.005000000000000001, recall = 0.002817460317460317.\n",
      "Training on epoch 29 minibatch 3201/5000 completed\n",
      " bpr_loss on current minibatch is 0.69389, and regularization loss is 0.000743.\n",
      " Top K precision = 0.016666666666666666, recall = 0.007988077787306463.\n",
      "Training on epoch 29 minibatch 3301/5000 completed\n",
      " bpr_loss on current minibatch is 0.693823, and regularization loss is 0.000676.\n",
      " Top K precision = 0.008333333333333333, recall = 0.0029663693794128574.\n",
      "Training on epoch 29 minibatch 3401/5000 completed\n",
      " bpr_loss on current minibatch is 0.693696, and regularization loss is 0.000549.\n",
      " Top K precision = 0.005172413793103449, recall = 0.0015911687013636037.\n",
      "Training on epoch 29 minibatch 3501/5000 completed\n",
      " bpr_loss on current minibatch is 0.693712, and regularization loss is 0.000565.\n",
      " Top K precision = 0.01833333333333333, recall = 0.011125220458553792.\n",
      "Training on epoch 29 minibatch 3601/5000 completed\n",
      " bpr_loss on current minibatch is 0.693892, and regularization loss is 0.000745.\n",
      " Top K precision = 0.013333333333333332, recall = 0.00759676970203286.\n",
      "Training on epoch 29 minibatch 3701/5000 completed\n",
      " bpr_loss on current minibatch is 0.693837, and regularization loss is 0.00069.\n",
      " Top K precision = 0.010169491525423728, recall = 0.0064039922313784935.\n",
      "Training on epoch 29 minibatch 3801/5000 completed\n",
      " bpr_loss on current minibatch is 0.693837, and regularization loss is 0.00069.\n",
      " Top K precision = 0.01833333333333333, recall = 0.007413691783257.\n",
      "Training on epoch 29 minibatch 3901/5000 completed\n",
      " bpr_loss on current minibatch is 0.693986, and regularization loss is 0.000839.\n",
      " Top K precision = 0.00847457627118644, recall = 0.0028461788307377928.\n",
      "Training on epoch 29 minibatch 4001/5000 completed\n",
      " bpr_loss on current minibatch is 0.693743, and regularization loss is 0.000595.\n",
      " Top K precision = 0.006779661016949153, recall = 0.0038173358711743556.\n",
      "Training on epoch 29 minibatch 4101/5000 completed\n",
      " bpr_loss on current minibatch is 0.693928, and regularization loss is 0.000781.\n",
      " Top K precision = 0.018965517241379314, recall = 0.006350932202829232.\n",
      "Training on epoch 29 minibatch 4201/5000 completed\n",
      " bpr_loss on current minibatch is 0.693851, and regularization loss is 0.000704.\n",
      " Top K precision = 0.011666666666666665, recall = 0.005482880042662651.\n",
      "Training on epoch 29 minibatch 4301/5000 completed\n",
      " bpr_loss on current minibatch is 0.693853, and regularization loss is 0.000706.\n",
      " Top K precision = 0.013559322033898305, recall = 0.007099930487918697.\n",
      "Training on epoch 29 minibatch 4401/5000 completed\n",
      " bpr_loss on current minibatch is 0.693833, and regularization loss is 0.000686.\n",
      " Top K precision = 0.008333333333333333, recall = 0.005459076240809988.\n",
      "Training on epoch 29 minibatch 4501/5000 completed\n",
      " bpr_loss on current minibatch is 0.693716, and regularization loss is 0.000569.\n",
      " Top K precision = 0.008771929824561403, recall = 0.004526172236638332.\n",
      "Training on epoch 29 minibatch 4601/5000 completed\n",
      " bpr_loss on current minibatch is 0.693816, and regularization loss is 0.000669.\n",
      " Top K precision = 0.013333333333333332, recall = 0.005271773182957393.\n",
      "Training on epoch 29 minibatch 4701/5000 completed\n",
      " bpr_loss on current minibatch is 0.693707, and regularization loss is 0.000559.\n",
      " Top K precision = 0.013559322033898306, recall = 0.0038468313719692065.\n",
      "Training on epoch 29 minibatch 4801/5000 completed\n",
      " bpr_loss on current minibatch is 0.693678, and regularization loss is 0.000531.\n",
      " Top K precision = 0.013333333333333332, recall = 0.005063399863058857.\n",
      "Training on epoch 29 minibatch 4901/5000 completed\n",
      " bpr_loss on current minibatch is 0.693759, and regularization loss is 0.000612.\n",
      " Top K precision = 0.01694915254237288, recall = 0.007206111062811023.\n",
      "\n",
      "Training on 29 epoch completed.\n",
      " Average bpr_loss on train set is 0.011563 for the current epoch.\n",
      " Training top K precision = 0.014633333333333443, recall = 0.006625776715518247.\n",
      " Average bpr_loss on the validation set is 2e-06, and regularization loss is 0.0.\n",
      " Validation top K precision = 0.014133333333333428, recall = 0.006545692024244167.\n",
      "\n",
      "Training on the 30 epoch\n",
      "Training on epoch 30 minibatch 1/5000 completed\n",
      " bpr_loss on current minibatch is 0.693946, and regularization loss is 0.000799.\n",
      " Top K precision = 0.011666666666666665, recall = 0.007723492806213395.\n",
      "Training on epoch 30 minibatch 101/5000 completed\n",
      " bpr_loss on current minibatch is 0.693789, and regularization loss is 0.000642.\n",
      " Top K precision = 0.008333333333333333, recall = 0.0022874902874902873.\n",
      "Training on epoch 30 minibatch 201/5000 completed\n",
      " bpr_loss on current minibatch is 0.693961, and regularization loss is 0.000814.\n",
      " Top K precision = 0.014999999999999998, recall = 0.005809002633945426.\n",
      "Training on epoch 30 minibatch 301/5000 completed\n",
      " bpr_loss on current minibatch is 0.693785, and regularization loss is 0.000638.\n",
      " Top K precision = 0.005084745762711865, recall = 0.0034046981861433246.\n",
      "Training on epoch 30 minibatch 401/5000 completed\n",
      " bpr_loss on current minibatch is 0.69384, and regularization loss is 0.000693.\n",
      " Top K precision = 0.013559322033898305, recall = 0.008299704062415926.\n",
      "Training on epoch 30 minibatch 501/5000 completed\n",
      " bpr_loss on current minibatch is 0.693842, and regularization loss is 0.000695.\n",
      " Top K precision = 0.010169491525423728, recall = 0.005192173143188518.\n",
      "Training on epoch 30 minibatch 601/5000 completed\n",
      " bpr_loss on current minibatch is 0.693721, and regularization loss is 0.000574.\n",
      " Top K precision = 0.011864406779661016, recall = 0.006582963180995172.\n",
      "Training on epoch 30 minibatch 701/5000 completed\n",
      " bpr_loss on current minibatch is 0.693792, and regularization loss is 0.000645.\n",
      " Top K precision = 0.014999999999999998, recall = 0.0060531890495125786.\n",
      "Training on epoch 30 minibatch 801/5000 completed\n",
      " bpr_loss on current minibatch is 0.693733, and regularization loss is 0.000585.\n",
      " Top K precision = 0.014999999999999998, recall = 0.008208170946426431.\n",
      "Training on epoch 30 minibatch 901/5000 completed\n",
      " bpr_loss on current minibatch is 0.693884, and regularization loss is 0.000737.\n",
      " Top K precision = 0.006666666666666667, recall = 0.0036055447820153705.\n",
      "Training on epoch 30 minibatch 1001/5000 completed\n",
      " bpr_loss on current minibatch is 0.693766, and regularization loss is 0.000619.\n",
      " Top K precision = 0.008333333333333333, recall = 0.004311660561660562.\n",
      "Training on epoch 30 minibatch 1101/5000 completed\n",
      " bpr_loss on current minibatch is 0.693985, and regularization loss is 0.000838.\n",
      " Top K precision = 0.010526315789473684, recall = 0.0038055350250472205.\n",
      "Training on epoch 30 minibatch 1201/5000 completed\n",
      " bpr_loss on current minibatch is 0.693783, and regularization loss is 0.000636.\n",
      " Top K precision = 0.006666666666666667, recall = 0.0022505973715651133.\n",
      "Training on epoch 30 minibatch 1301/5000 completed\n",
      " bpr_loss on current minibatch is 0.6937, and regularization loss is 0.000553.\n",
      " Top K precision = 0.011666666666666665, recall = 0.0066429703194409075.\n",
      "Training on epoch 30 minibatch 1401/5000 completed\n",
      " bpr_loss on current minibatch is 0.693631, and regularization loss is 0.000484.\n",
      " Top K precision = 0.008333333333333333, recall = 0.006752613857877015.\n",
      "Training on epoch 30 minibatch 1501/5000 completed\n",
      " bpr_loss on current minibatch is 0.693792, and regularization loss is 0.000644.\n",
      " Top K precision = 0.013559322033898305, recall = 0.00372513237275728.\n",
      "Training on epoch 30 minibatch 1601/5000 completed\n",
      " bpr_loss on current minibatch is 0.693755, and regularization loss is 0.000608.\n",
      " Top K precision = 0.006779661016949153, recall = 0.00503518683714937.\n",
      "Training on epoch 30 minibatch 1701/5000 completed\n",
      " bpr_loss on current minibatch is 0.693852, and regularization loss is 0.000705.\n",
      " Top K precision = 0.011666666666666665, recall = 0.006377896459418197.\n",
      "Training on epoch 30 minibatch 1801/5000 completed\n",
      " bpr_loss on current minibatch is 0.693954, and regularization loss is 0.000807.\n",
      " Top K precision = 0.018644067796610167, recall = 0.0070658064542415975.\n",
      "Training on epoch 30 minibatch 1901/5000 completed\n",
      " bpr_loss on current minibatch is 0.693811, and regularization loss is 0.000664.\n",
      " Top K precision = 0.01379310344827586, recall = 0.009094485495347564.\n",
      "Training on epoch 30 minibatch 2001/5000 completed\n",
      " bpr_loss on current minibatch is 0.693978, and regularization loss is 0.000831.\n",
      " Top K precision = 0.013559322033898305, recall = 0.005600012485605706.\n",
      "Training on epoch 30 minibatch 2101/5000 completed\n",
      " bpr_loss on current minibatch is 0.693791, and regularization loss is 0.000644.\n",
      " Top K precision = 0.015789473684210523, recall = 0.004954395900286418.\n",
      "Training on epoch 30 minibatch 2201/5000 completed\n",
      " bpr_loss on current minibatch is 0.693689, and regularization loss is 0.000542.\n",
      " Top K precision = 0.0033898305084745766, recall = 0.0012943625264557205.\n",
      "Training on epoch 30 minibatch 2301/5000 completed\n",
      " bpr_loss on current minibatch is 0.693753, and regularization loss is 0.000606.\n",
      " Top K precision = 0.023333333333333334, recall = 0.009232358700915348.\n",
      "Training on epoch 30 minibatch 2401/5000 completed\n",
      " bpr_loss on current minibatch is 0.693723, and regularization loss is 0.000576.\n",
      " Top K precision = 0.014999999999999998, recall = 0.006131232898655639.\n",
      "Training on epoch 30 minibatch 2501/5000 completed\n",
      " bpr_loss on current minibatch is 0.693829, and regularization loss is 0.000682.\n",
      " Top K precision = 0.006666666666666667, recall = 0.0033544908544908547.\n",
      "Training on epoch 30 minibatch 2601/5000 completed\n",
      " bpr_loss on current minibatch is 0.693829, and regularization loss is 0.000682.\n",
      " Top K precision = 0.011864406779661016, recall = 0.005342100548906498.\n",
      "Training on epoch 30 minibatch 2701/5000 completed\n",
      " bpr_loss on current minibatch is 0.693834, and regularization loss is 0.000687.\n",
      " Top K precision = 0.014999999999999998, recall = 0.006592657444319315.\n",
      "Training on epoch 30 minibatch 2801/5000 completed\n",
      " bpr_loss on current minibatch is 0.693774, and regularization loss is 0.000627.\n",
      " Top K precision = 0.014999999999999998, recall = 0.0054231475064808405.\n",
      "Training on epoch 30 minibatch 2901/5000 completed\n",
      " bpr_loss on current minibatch is 0.693743, and regularization loss is 0.000596.\n",
      " Top K precision = 0.013333333333333332, recall = 0.0066943525208433005.\n",
      "Training on epoch 30 minibatch 3001/5000 completed\n",
      " bpr_loss on current minibatch is 0.693647, and regularization loss is 0.0005.\n",
      " Top K precision = 0.01, recall = 0.0033883164765517713.\n",
      "Training on epoch 30 minibatch 3101/5000 completed\n",
      " bpr_loss on current minibatch is 0.6937, and regularization loss is 0.000552.\n",
      " Top K precision = 0.011666666666666665, recall = 0.002999151974184723.\n",
      "Training on epoch 30 minibatch 3201/5000 completed\n",
      " bpr_loss on current minibatch is 0.693732, and regularization loss is 0.000585.\n",
      " Top K precision = 0.011666666666666665, recall = 0.0071158394508466245.\n",
      "Training on epoch 30 minibatch 3301/5000 completed\n",
      " bpr_loss on current minibatch is 0.693815, and regularization loss is 0.000668.\n",
      " Top K precision = 0.016666666666666666, recall = 0.007606258117149775.\n",
      "Training on epoch 30 minibatch 3401/5000 completed\n",
      " bpr_loss on current minibatch is 0.693773, and regularization loss is 0.000626.\n",
      " Top K precision = 0.013559322033898305, recall = 0.007730287890070646.\n",
      "Training on epoch 30 minibatch 3501/5000 completed\n",
      " bpr_loss on current minibatch is 0.69379, and regularization loss is 0.000643.\n",
      " Top K precision = 0.022033898305084745, recall = 0.009575467648616623.\n",
      "Training on epoch 30 minibatch 3601/5000 completed\n",
      " bpr_loss on current minibatch is 0.693923, and regularization loss is 0.000776.\n",
      " Top K precision = 0.01, recall = 0.0035321075123706702.\n",
      "Training on epoch 30 minibatch 3701/5000 completed\n",
      " bpr_loss on current minibatch is 0.693717, and regularization loss is 0.00057.\n",
      " Top K precision = 0.013333333333333332, recall = 0.006429719139029925.\n",
      "Training on epoch 30 minibatch 3801/5000 completed\n",
      " bpr_loss on current minibatch is 0.693874, and regularization loss is 0.000726.\n",
      " Top K precision = 0.01694915254237288, recall = 0.008645749386948225.\n",
      "Training on epoch 30 minibatch 3901/5000 completed\n",
      " bpr_loss on current minibatch is 0.69387, and regularization loss is 0.000723.\n",
      " Top K precision = 0.010344827586206896, recall = 0.004983709443979308.\n",
      "Training on epoch 30 minibatch 4001/5000 completed\n",
      " bpr_loss on current minibatch is 0.693845, and regularization loss is 0.000698.\n",
      " Top K precision = 0.007017543859649123, recall = 0.0031798245614035082.\n",
      "Training on epoch 30 minibatch 4101/5000 completed\n",
      " bpr_loss on current minibatch is 0.693733, and regularization loss is 0.000585.\n",
      " Top K precision = 0.013559322033898305, recall = 0.005644362018717214.\n",
      "Training on epoch 30 minibatch 4201/5000 completed\n",
      " bpr_loss on current minibatch is 0.69387, and regularization loss is 0.000722.\n",
      " Top K precision = 0.016666666666666666, recall = 0.0062066770948349895.\n",
      "Training on epoch 30 minibatch 4301/5000 completed\n",
      " bpr_loss on current minibatch is 0.693949, and regularization loss is 0.000801.\n",
      " Top K precision = 0.011864406779661016, recall = 0.002762340062299271.\n",
      "Training on epoch 30 minibatch 4401/5000 completed\n",
      " bpr_loss on current minibatch is 0.693891, and regularization loss is 0.000744.\n",
      " Top K precision = 0.013333333333333332, recall = 0.005986609387344683.\n",
      "Training on epoch 30 minibatch 4501/5000 completed\n",
      " bpr_loss on current minibatch is 0.693821, and regularization loss is 0.000674.\n",
      " Top K precision = 0.005000000000000001, recall = 0.0014369889369889371.\n",
      "Training on epoch 30 minibatch 4601/5000 completed\n",
      " bpr_loss on current minibatch is 0.693802, and regularization loss is 0.000654.\n",
      " Top K precision = 0.013333333333333332, recall = 0.003302219362801204.\n",
      "Training on epoch 30 minibatch 4701/5000 completed\n",
      " bpr_loss on current minibatch is 0.693988, and regularization loss is 0.000841.\n",
      " Top K precision = 0.011666666666666665, recall = 0.004896988640182832.\n",
      "Training on epoch 30 minibatch 4801/5000 completed\n",
      " bpr_loss on current minibatch is 0.693684, and regularization loss is 0.000537.\n",
      " Top K precision = 0.01, recall = 0.0069022279964617425.\n",
      "Training on epoch 30 minibatch 4901/5000 completed\n",
      " bpr_loss on current minibatch is 0.693769, and regularization loss is 0.000622.\n",
      " Top K precision = 0.016666666666666666, recall = 0.005905438246555242.\n",
      "\n",
      "Training on 30 epoch completed.\n",
      " Average bpr_loss on train set is 0.011563 for the current epoch.\n",
      " Training top K precision = 0.012766666666666739, recall = 0.0058242687315910036.\n",
      " Average bpr_loss on the validation set is 2e-06, and regularization loss is 0.0.\n",
      " Validation top K precision = 0.0142000000000001, recall = 0.006256470254443761.\n",
      "\n",
      "Training on the 31 epoch\n",
      "Training on epoch 31 minibatch 1/5000 completed\n",
      " bpr_loss on current minibatch is 0.693771, and regularization loss is 0.000624.\n",
      " Top K precision = 0.008333333333333333, recall = 0.003771252642220384.\n",
      "Training on epoch 31 minibatch 101/5000 completed\n",
      " bpr_loss on current minibatch is 0.693747, and regularization loss is 0.000599.\n",
      " Top K precision = 0.013559322033898305, recall = 0.007204702350243985.\n",
      "Training on epoch 31 minibatch 201/5000 completed\n",
      " bpr_loss on current minibatch is 0.693742, and regularization loss is 0.000595.\n",
      " Top K precision = 0.011864406779661016, recall = 0.00481109539967449.\n",
      "Training on epoch 31 minibatch 301/5000 completed\n",
      " bpr_loss on current minibatch is 0.693733, and regularization loss is 0.000586.\n",
      " Top K precision = 0.0033333333333333335, recall = 0.0011876006441223833.\n",
      "Training on epoch 31 minibatch 401/5000 completed\n",
      " bpr_loss on current minibatch is 0.693789, and regularization loss is 0.000642.\n",
      " Top K precision = 0.013559322033898306, recall = 0.0050619095939656.\n",
      "Training on epoch 31 minibatch 501/5000 completed\n",
      " bpr_loss on current minibatch is 0.693727, and regularization loss is 0.00058.\n",
      " Top K precision = 0.014999999999999998, recall = 0.007034596105088431.\n",
      "Training on epoch 31 minibatch 601/5000 completed\n",
      " bpr_loss on current minibatch is 0.693727, and regularization loss is 0.00058.\n",
      " Top K precision = 0.008333333333333333, recall = 0.0026368303787658626.\n",
      "Training on epoch 31 minibatch 701/5000 completed\n",
      " bpr_loss on current minibatch is 0.693514, and regularization loss is 0.000366.\n",
      " Top K precision = 0.010344827586206896, recall = 0.0040423905694211715.\n",
      "Training on epoch 31 minibatch 801/5000 completed\n",
      " bpr_loss on current minibatch is 0.693762, and regularization loss is 0.000615.\n",
      " Top K precision = 0.010169491525423728, recall = 0.006210299430638414.\n",
      "Training on epoch 31 minibatch 901/5000 completed\n",
      " bpr_loss on current minibatch is 0.693802, and regularization loss is 0.000655.\n",
      " Top K precision = 0.011666666666666665, recall = 0.0036304436304436306.\n",
      "Training on epoch 31 minibatch 1001/5000 completed\n",
      " bpr_loss on current minibatch is 0.693782, and regularization loss is 0.000635.\n",
      " Top K precision = 0.014999999999999998, recall = 0.007335931042425099.\n",
      "Training on epoch 31 minibatch 1101/5000 completed\n",
      " bpr_loss on current minibatch is 0.693843, and regularization loss is 0.000696.\n",
      " Top K precision = 0.011666666666666665, recall = 0.004986865238185299.\n",
      "Training on epoch 31 minibatch 1201/5000 completed\n",
      " bpr_loss on current minibatch is 0.693676, and regularization loss is 0.000529.\n",
      " Top K precision = 0.018333333333333333, recall = 0.0064658968055721685.\n",
      "Training on epoch 31 minibatch 1301/5000 completed\n",
      " bpr_loss on current minibatch is 0.693796, and regularization loss is 0.000648.\n",
      " Top K precision = 0.01, recall = 0.004559799696427604.\n",
      "Training on epoch 31 minibatch 1401/5000 completed\n",
      " bpr_loss on current minibatch is 0.693859, and regularization loss is 0.000712.\n",
      " Top K precision = 0.005000000000000001, recall = 0.0015197262479871175.\n",
      "Training on epoch 31 minibatch 1501/5000 completed\n",
      " bpr_loss on current minibatch is 0.69377, and regularization loss is 0.000623.\n",
      " Top K precision = 0.014999999999999998, recall = 0.005432155584645129.\n",
      "Training on epoch 31 minibatch 1601/5000 completed\n",
      " bpr_loss on current minibatch is 0.693688, and regularization loss is 0.000541.\n",
      " Top K precision = 0.008333333333333333, recall = 0.0030178363847718687.\n",
      "Training on epoch 31 minibatch 1701/5000 completed\n",
      " bpr_loss on current minibatch is 0.693802, and regularization loss is 0.000655.\n",
      " Top K precision = 0.01, recall = 0.005528014398982141.\n",
      "Training on epoch 31 minibatch 1801/5000 completed\n",
      " bpr_loss on current minibatch is 0.693865, and regularization loss is 0.000718.\n",
      " Top K precision = 0.013333333333333332, recall = 0.008222831399549492.\n",
      "Training on epoch 31 minibatch 1901/5000 completed\n",
      " bpr_loss on current minibatch is 0.693679, and regularization loss is 0.000532.\n",
      " Top K precision = 0.021666666666666667, recall = 0.007637107045001782.\n",
      "Training on epoch 31 minibatch 2001/5000 completed\n",
      " bpr_loss on current minibatch is 0.693838, and regularization loss is 0.00069.\n",
      " Top K precision = 0.0033333333333333335, recall = 0.0010763888888888887.\n",
      "Training on epoch 31 minibatch 2101/5000 completed\n",
      " bpr_loss on current minibatch is 0.693837, and regularization loss is 0.000689.\n",
      " Top K precision = 0.008620689655172414, recall = 0.003211161755786502.\n",
      "Training on epoch 31 minibatch 2201/5000 completed\n",
      " bpr_loss on current minibatch is 0.693731, and regularization loss is 0.000584.\n",
      " Top K precision = 0.011864406779661016, recall = 0.003487016335982078.\n",
      "Training on epoch 31 minibatch 2301/5000 completed\n",
      " bpr_loss on current minibatch is 0.693796, and regularization loss is 0.000649.\n",
      " Top K precision = 0.014999999999999998, recall = 0.007416551676355598.\n",
      "Training on epoch 31 minibatch 2401/5000 completed\n",
      " bpr_loss on current minibatch is 0.693852, and regularization loss is 0.000705.\n",
      " Top K precision = 0.011666666666666665, recall = 0.005908276644133163.\n",
      "Training on epoch 31 minibatch 2501/5000 completed\n",
      " bpr_loss on current minibatch is 0.693768, and regularization loss is 0.000621.\n",
      " Top K precision = 0.010169491525423728, recall = 0.004308561652182962.\n",
      "Training on epoch 31 minibatch 2601/5000 completed\n",
      " bpr_loss on current minibatch is 0.69391, and regularization loss is 0.000763.\n",
      " Top K precision = 0.01, recall = 0.005193799256299257.\n",
      "Training on epoch 31 minibatch 2701/5000 completed\n",
      " bpr_loss on current minibatch is 0.69379, and regularization loss is 0.000643.\n",
      " Top K precision = 0.020000000000000004, recall = 0.009729659550110984.\n",
      "Training on epoch 31 minibatch 2801/5000 completed\n",
      " bpr_loss on current minibatch is 0.69381, and regularization loss is 0.000663.\n",
      " Top K precision = 0.01864406779661017, recall = 0.008683306551395834.\n",
      "Training on epoch 31 minibatch 2901/5000 completed\n",
      " bpr_loss on current minibatch is 0.693877, and regularization loss is 0.00073.\n",
      " Top K precision = 0.015000000000000001, recall = 0.0036372338997649684.\n",
      "Training on epoch 31 minibatch 3001/5000 completed\n",
      " bpr_loss on current minibatch is 0.69384, and regularization loss is 0.000693.\n",
      " Top K precision = 0.01833333333333333, recall = 0.008110387084971481.\n",
      "Training on epoch 31 minibatch 3101/5000 completed\n",
      " bpr_loss on current minibatch is 0.693714, and regularization loss is 0.000567.\n",
      " Top K precision = 0.013333333333333332, recall = 0.004158260862288095.\n",
      "Training on epoch 31 minibatch 3201/5000 completed\n",
      " bpr_loss on current minibatch is 0.693729, and regularization loss is 0.000582.\n",
      " Top K precision = 0.01206896551724138, recall = 0.005211273252171698.\n",
      "Training on epoch 31 minibatch 3301/5000 completed\n",
      " bpr_loss on current minibatch is 0.693746, and regularization loss is 0.000599.\n",
      " Top K precision = 0.008333333333333333, recall = 0.005536145617667356.\n",
      "Training on epoch 31 minibatch 3401/5000 completed\n",
      " bpr_loss on current minibatch is 0.693873, and regularization loss is 0.000726.\n",
      " Top K precision = 0.010344827586206896, recall = 0.002982792229616186.\n",
      "Training on epoch 31 minibatch 3501/5000 completed\n",
      " bpr_loss on current minibatch is 0.693947, and regularization loss is 0.0008.\n",
      " Top K precision = 0.01833333333333333, recall = 0.01170532585762471.\n",
      "Training on epoch 31 minibatch 3601/5000 completed\n",
      " bpr_loss on current minibatch is 0.693914, and regularization loss is 0.000767.\n",
      " Top K precision = 0.011864406779661016, recall = 0.0028971853597975225.\n",
      "Training on epoch 31 minibatch 3701/5000 completed\n",
      " bpr_loss on current minibatch is 0.693652, and regularization loss is 0.000505.\n",
      " Top K precision = 0.011864406779661016, recall = 0.005171283280701492.\n",
      "Training on epoch 31 minibatch 3801/5000 completed\n",
      " bpr_loss on current minibatch is 0.693844, and regularization loss is 0.000697.\n",
      " Top K precision = 0.005084745762711865, recall = 0.002860349342464965.\n",
      "Training on epoch 31 minibatch 3901/5000 completed\n",
      " bpr_loss on current minibatch is 0.693586, and regularization loss is 0.000439.\n",
      " Top K precision = 0.011666666666666665, recall = 0.006253561027230257.\n",
      "Training on epoch 31 minibatch 4001/5000 completed\n",
      " bpr_loss on current minibatch is 0.693633, and regularization loss is 0.000486.\n",
      " Top K precision = 0.025423728813559324, recall = 0.008290384022734102.\n",
      "Training on epoch 31 minibatch 4101/5000 completed\n",
      " bpr_loss on current minibatch is 0.693749, and regularization loss is 0.000602.\n",
      " Top K precision = 0.020338983050847456, recall = 0.006932007827455582.\n",
      "Training on epoch 31 minibatch 4201/5000 completed\n",
      " bpr_loss on current minibatch is 0.693852, and regularization loss is 0.000705.\n",
      " Top K precision = 0.010526315789473684, recall = 0.004601514469935522.\n",
      "Training on epoch 31 minibatch 4301/5000 completed\n",
      " bpr_loss on current minibatch is 0.693769, and regularization loss is 0.000622.\n",
      " Top K precision = 0.014999999999999998, recall = 0.0070434975151645205.\n",
      "Training on epoch 31 minibatch 4401/5000 completed\n",
      " bpr_loss on current minibatch is 0.693874, and regularization loss is 0.000727.\n",
      " Top K precision = 0.013559322033898305, recall = 0.005387028226011277.\n",
      "Training on epoch 31 minibatch 4501/5000 completed\n",
      " bpr_loss on current minibatch is 0.693791, and regularization loss is 0.000644.\n",
      " Top K precision = 0.010344827586206896, recall = 0.005637233063055035.\n",
      "Training on epoch 31 minibatch 4601/5000 completed\n",
      " bpr_loss on current minibatch is 0.693796, and regularization loss is 0.000649.\n",
      " Top K precision = 0.015254237288135592, recall = 0.006631857623172414.\n",
      "Training on epoch 31 minibatch 4701/5000 completed\n",
      " bpr_loss on current minibatch is 0.69371, and regularization loss is 0.000563.\n",
      " Top K precision = 0.013333333333333332, recall = 0.00880889755889756.\n",
      "Training on epoch 31 minibatch 4801/5000 completed\n",
      " bpr_loss on current minibatch is 0.693679, and regularization loss is 0.000532.\n",
      " Top K precision = 0.013333333333333332, recall = 0.004428338904084199.\n",
      "Training on epoch 31 minibatch 4901/5000 completed\n",
      " bpr_loss on current minibatch is 0.693947, and regularization loss is 0.000799.\n",
      " Top K precision = 0.011666666666666665, recall = 0.005005371567156464.\n",
      "\n",
      "Training on 31 epoch completed.\n",
      " Average bpr_loss on train set is 0.011563 for the current epoch.\n",
      " Training top K precision = 0.014733333333333444, recall = 0.006492775271814579.\n",
      " Average bpr_loss on the validation set is 2e-06, and regularization loss is 0.0.\n",
      " Validation top K precision = 0.01456666666666677, recall = 0.0064539977107237224.\n",
      "\n",
      "Training on the 32 epoch\n",
      "Training on epoch 32 minibatch 1/5000 completed\n",
      " bpr_loss on current minibatch is 0.693914, and regularization loss is 0.000766.\n",
      " Top K precision = 0.014999999999999998, recall = 0.008967853848604263.\n",
      "Training on epoch 32 minibatch 101/5000 completed\n",
      " bpr_loss on current minibatch is 0.693727, and regularization loss is 0.00058.\n",
      " Top K precision = 0.005000000000000001, recall = 0.0016286799620132955.\n",
      "Training on epoch 32 minibatch 201/5000 completed\n",
      " bpr_loss on current minibatch is 0.693728, and regularization loss is 0.000581.\n",
      " Top K precision = 0.008333333333333333, recall = 0.0026107804232804233.\n",
      "Training on epoch 32 minibatch 301/5000 completed\n",
      " bpr_loss on current minibatch is 0.693901, and regularization loss is 0.000754.\n",
      " Top K precision = 0.013333333333333332, recall = 0.007153228715728716.\n",
      "Training on epoch 32 minibatch 401/5000 completed\n",
      " bpr_loss on current minibatch is 0.693839, and regularization loss is 0.000691.\n",
      " Top K precision = 0.020000000000000004, recall = 0.009503193938677807.\n",
      "Training on epoch 32 minibatch 501/5000 completed\n",
      " bpr_loss on current minibatch is 0.693706, and regularization loss is 0.000559.\n",
      " Top K precision = 0.02, recall = 0.008841388636465362.\n",
      "Training on epoch 32 minibatch 601/5000 completed\n",
      " bpr_loss on current minibatch is 0.693837, and regularization loss is 0.00069.\n",
      " Top K precision = 0.0033333333333333335, recall = 0.001045751633986928.\n",
      "Training on epoch 32 minibatch 701/5000 completed\n",
      " bpr_loss on current minibatch is 0.693817, and regularization loss is 0.00067.\n",
      " Top K precision = 0.02, recall = 0.008817139513550029.\n",
      "Training on epoch 32 minibatch 801/5000 completed\n",
      " bpr_loss on current minibatch is 0.694081, and regularization loss is 0.000934.\n",
      " Top K precision = 0.016666666666666666, recall = 0.008368616677440207.\n",
      "Training on epoch 32 minibatch 901/5000 completed\n",
      " bpr_loss on current minibatch is 0.693848, and regularization loss is 0.000701.\n",
      " Top K precision = 0.01, recall = 0.0050169882767921985.\n",
      "Training on epoch 32 minibatch 1001/5000 completed\n",
      " bpr_loss on current minibatch is 0.693704, and regularization loss is 0.000557.\n",
      " Top K precision = 0.013333333333333332, recall = 0.004485703004724744.\n",
      "Training on epoch 32 minibatch 1101/5000 completed\n",
      " bpr_loss on current minibatch is 0.693851, and regularization loss is 0.000704.\n",
      " Top K precision = 0.006666666666666667, recall = 0.0032692307692307695.\n",
      "Training on epoch 32 minibatch 1201/5000 completed\n",
      " bpr_loss on current minibatch is 0.693734, and regularization loss is 0.000587.\n",
      " Top K precision = 0.013333333333333332, recall = 0.0072232972006522735.\n",
      "Training on epoch 32 minibatch 1301/5000 completed\n",
      " bpr_loss on current minibatch is 0.693746, and regularization loss is 0.000599.\n",
      " Top K precision = 0.01694915254237288, recall = 0.006889345425291401.\n",
      "Training on epoch 32 minibatch 1401/5000 completed\n",
      " bpr_loss on current minibatch is 0.693835, and regularization loss is 0.000688.\n",
      " Top K precision = 0.014999999999999998, recall = 0.00794689861933695.\n",
      "Training on epoch 32 minibatch 1501/5000 completed\n",
      " bpr_loss on current minibatch is 0.693819, and regularization loss is 0.000672.\n",
      " Top K precision = 0.008333333333333333, recall = 0.0023223900472532483.\n",
      "Training on epoch 32 minibatch 1601/5000 completed\n",
      " bpr_loss on current minibatch is 0.693848, and regularization loss is 0.000701.\n",
      " Top K precision = 0.013333333333333332, recall = 0.004767082006212017.\n",
      "Training on epoch 32 minibatch 1701/5000 completed\n",
      " bpr_loss on current minibatch is 0.69366, and regularization loss is 0.000513.\n",
      " Top K precision = 0.016666666666666666, recall = 0.006394405552206971.\n",
      "Training on epoch 32 minibatch 1801/5000 completed\n",
      " bpr_loss on current minibatch is 0.693608, and regularization loss is 0.000461.\n",
      " Top K precision = 0.010344827586206898, recall = 0.004925467325000641.\n",
      "Training on epoch 32 minibatch 1901/5000 completed\n",
      " bpr_loss on current minibatch is 0.693666, and regularization loss is 0.000518.\n",
      " Top K precision = 0.011666666666666665, recall = 0.0033611572909485617.\n",
      "Training on epoch 32 minibatch 2001/5000 completed\n",
      " bpr_loss on current minibatch is 0.693802, and regularization loss is 0.000654.\n",
      " Top K precision = 0.005172413793103449, recall = 0.0017094627289529838.\n",
      "Training on epoch 32 minibatch 2101/5000 completed\n",
      " bpr_loss on current minibatch is 0.693768, and regularization loss is 0.000621.\n",
      " Top K precision = 0.013333333333333332, recall = 0.005639119160550989.\n",
      "Training on epoch 32 minibatch 2201/5000 completed\n",
      " bpr_loss on current minibatch is 0.693991, and regularization loss is 0.000843.\n",
      " Top K precision = 0.010526315789473684, recall = 0.0033869756451496034.\n",
      "Training on epoch 32 minibatch 2301/5000 completed\n",
      " bpr_loss on current minibatch is 0.693757, and regularization loss is 0.00061.\n",
      " Top K precision = 0.01, recall = 0.005423637923637924.\n",
      "Training on epoch 32 minibatch 2401/5000 completed\n",
      " bpr_loss on current minibatch is 0.693848, and regularization loss is 0.000701.\n",
      " Top K precision = 0.01, recall = 0.004600382296320512.\n",
      "Training on epoch 32 minibatch 2501/5000 completed\n",
      " bpr_loss on current minibatch is 0.693799, and regularization loss is 0.000652.\n",
      " Top K precision = 0.01206896551724138, recall = 0.005400016961883088.\n",
      "Training on epoch 32 minibatch 2601/5000 completed\n",
      " bpr_loss on current minibatch is 0.693685, and regularization loss is 0.000538.\n",
      " Top K precision = 0.008620689655172414, recall = 0.0031578462105845474.\n",
      "Training on epoch 32 minibatch 2701/5000 completed\n",
      " bpr_loss on current minibatch is 0.694082, and regularization loss is 0.000935.\n",
      " Top K precision = 0.015254237288135592, recall = 0.006181148825077503.\n",
      "Training on epoch 32 minibatch 2801/5000 completed\n",
      " bpr_loss on current minibatch is 0.693787, and regularization loss is 0.00064.\n",
      " Top K precision = 0.018644067796610167, recall = 0.005653290039164655.\n",
      "Training on epoch 32 minibatch 2901/5000 completed\n",
      " bpr_loss on current minibatch is 0.693841, and regularization loss is 0.000694.\n",
      " Top K precision = 0.01, recall = 0.005831128747795414.\n",
      "Training on epoch 32 minibatch 3001/5000 completed\n",
      " bpr_loss on current minibatch is 0.693676, and regularization loss is 0.000529.\n",
      " Top K precision = 0.010169491525423728, recall = 0.004876145373403598.\n",
      "Training on epoch 32 minibatch 3101/5000 completed\n",
      " bpr_loss on current minibatch is 0.693755, and regularization loss is 0.000608.\n",
      " Top K precision = 0.008333333333333333, recall = 0.004735033485033485.\n",
      "Training on epoch 32 minibatch 3201/5000 completed\n",
      " bpr_loss on current minibatch is 0.693774, and regularization loss is 0.000627.\n",
      " Top K precision = 0.016666666666666666, recall = 0.007935689572905504.\n",
      "Training on epoch 32 minibatch 3301/5000 completed\n",
      " bpr_loss on current minibatch is 0.693719, and regularization loss is 0.000572.\n",
      " Top K precision = 0.008333333333333333, recall = 0.004365079365079364.\n",
      "Training on epoch 32 minibatch 3401/5000 completed\n",
      " bpr_loss on current minibatch is 0.693886, and regularization loss is 0.000739.\n",
      " Top K precision = 0.010169491525423728, recall = 0.003286508674297693.\n",
      "Training on epoch 32 minibatch 3501/5000 completed\n",
      " bpr_loss on current minibatch is 0.69373, and regularization loss is 0.000583.\n",
      " Top K precision = 0.011864406779661017, recall = 0.006426553672316384.\n",
      "Training on epoch 32 minibatch 3601/5000 completed\n",
      " bpr_loss on current minibatch is 0.693769, and regularization loss is 0.000622.\n",
      " Top K precision = 0.01833333333333333, recall = 0.007954089515874414.\n",
      "Training on epoch 32 minibatch 3701/5000 completed\n",
      " bpr_loss on current minibatch is 0.693842, and regularization loss is 0.000695.\n",
      " Top K precision = 0.008333333333333333, recall = 0.004359127714390872.\n",
      "Training on epoch 32 minibatch 3801/5000 completed\n",
      " bpr_loss on current minibatch is 0.693949, and regularization loss is 0.000801.\n",
      " Top K precision = 0.010526315789473684, recall = 0.00693112070821049.\n",
      "Training on epoch 32 minibatch 3901/5000 completed\n",
      " bpr_loss on current minibatch is 0.693871, and regularization loss is 0.000723.\n",
      " Top K precision = 0.01833333333333333, recall = 0.006545995670995672.\n",
      "Training on epoch 32 minibatch 4001/5000 completed\n",
      " bpr_loss on current minibatch is 0.693953, and regularization loss is 0.000806.\n",
      " Top K precision = 0.010169491525423728, recall = 0.006939042213738719.\n",
      "Training on epoch 32 minibatch 4101/5000 completed\n",
      " bpr_loss on current minibatch is 0.69377, and regularization loss is 0.000623.\n",
      " Top K precision = 0.013333333333333332, recall = 0.0050404606286959235.\n",
      "Training on epoch 32 minibatch 4201/5000 completed\n",
      " bpr_loss on current minibatch is 0.694103, and regularization loss is 0.000956.\n",
      " Top K precision = 0.008333333333333333, recall = 0.005686091686091686.\n",
      "Training on epoch 32 minibatch 4301/5000 completed\n",
      " bpr_loss on current minibatch is 0.693763, and regularization loss is 0.000616.\n",
      " Top K precision = 0.010169491525423728, recall = 0.003080743702874871.\n",
      "Training on epoch 32 minibatch 4401/5000 completed\n",
      " bpr_loss on current minibatch is 0.693826, and regularization loss is 0.000679.\n",
      " Top K precision = 0.008333333333333333, recall = 0.00226875463717569.\n",
      "Training on epoch 32 minibatch 4501/5000 completed\n",
      " bpr_loss on current minibatch is 0.693691, and regularization loss is 0.000544.\n",
      " Top K precision = 0.005084745762711865, recall = 0.0028304509548278244.\n",
      "Training on epoch 32 minibatch 4601/5000 completed\n",
      " bpr_loss on current minibatch is 0.693783, and regularization loss is 0.000636.\n",
      " Top K precision = 0.011864406779661016, recall = 0.007860141457195125.\n",
      "Training on epoch 32 minibatch 4701/5000 completed\n",
      " bpr_loss on current minibatch is 0.693594, and regularization loss is 0.000447.\n",
      " Top K precision = 0.01, recall = 0.004617134073655813.\n",
      "Training on epoch 32 minibatch 4801/5000 completed\n",
      " bpr_loss on current minibatch is 0.69391, and regularization loss is 0.000763.\n",
      " Top K precision = 0.008333333333333333, recall = 0.004091154819415689.\n",
      "Training on epoch 32 minibatch 4901/5000 completed\n",
      " bpr_loss on current minibatch is 0.693784, and regularization loss is 0.000636.\n",
      " Top K precision = 0.01, recall = 0.004723517223517225.\n",
      "\n",
      "Training on 32 epoch completed.\n",
      " Average bpr_loss on train set is 0.011563 for the current epoch.\n",
      " Training top K precision = 0.01583333333333346, recall = 0.007097242477939505.\n",
      " Average bpr_loss on the validation set is 2e-06, and regularization loss is 0.0.\n",
      " Validation top K precision = 0.016000000000000125, recall = 0.007151640226236552.\n",
      "\n",
      "Training on the 33 epoch\n",
      "Training on epoch 33 minibatch 1/5000 completed\n",
      " bpr_loss on current minibatch is 0.693823, and regularization loss is 0.000676.\n",
      " Top K precision = 0.011864406779661016, recall = 0.005326663219844143.\n",
      "Training on epoch 33 minibatch 101/5000 completed\n",
      " bpr_loss on current minibatch is 0.693828, and regularization loss is 0.00068.\n",
      " Top K precision = 0.015254237288135592, recall = 0.007025130071947067.\n",
      "Training on epoch 33 minibatch 201/5000 completed\n",
      " bpr_loss on current minibatch is 0.693861, and regularization loss is 0.000714.\n",
      " Top K precision = 0.00847457627118644, recall = 0.00320340737621504.\n",
      "Training on epoch 33 minibatch 301/5000 completed\n",
      " bpr_loss on current minibatch is 0.693866, and regularization loss is 0.000719.\n",
      " Top K precision = 0.013559322033898305, recall = 0.0050062620674469335.\n",
      "Training on epoch 33 minibatch 401/5000 completed\n",
      " bpr_loss on current minibatch is 0.693923, and regularization loss is 0.000776.\n",
      " Top K precision = 0.016949152542372878, recall = 0.0063410465320274025.\n",
      "Training on epoch 33 minibatch 501/5000 completed\n",
      " bpr_loss on current minibatch is 0.693832, and regularization loss is 0.000684.\n",
      " Top K precision = 0.018333333333333333, recall = 0.006543404891386177.\n",
      "Training on epoch 33 minibatch 601/5000 completed\n",
      " bpr_loss on current minibatch is 0.693672, and regularization loss is 0.000525.\n",
      " Top K precision = 0.013333333333333332, recall = 0.006494932042370372.\n",
      "Training on epoch 33 minibatch 701/5000 completed\n",
      " bpr_loss on current minibatch is 0.693895, and regularization loss is 0.000748.\n",
      " Top K precision = 0.006779661016949153, recall = 0.003877760657421675.\n",
      "Training on epoch 33 minibatch 801/5000 completed\n",
      " bpr_loss on current minibatch is 0.693751, and regularization loss is 0.000604.\n",
      " Top K precision = 0.008333333333333333, recall = 0.003371464512924058.\n",
      "Training on epoch 33 minibatch 901/5000 completed\n",
      " bpr_loss on current minibatch is 0.693686, and regularization loss is 0.000539.\n",
      " Top K precision = 0.02, recall = 0.011195855370514365.\n",
      "Training on epoch 33 minibatch 1001/5000 completed\n",
      " bpr_loss on current minibatch is 0.693743, and regularization loss is 0.000596.\n",
      " Top K precision = 0.006666666666666667, recall = 0.0019061542745753273.\n",
      "Training on epoch 33 minibatch 1101/5000 completed\n",
      " bpr_loss on current minibatch is 0.693892, and regularization loss is 0.000745.\n",
      " Top K precision = 0.013333333333333332, recall = 0.010015218617145969.\n",
      "Training on epoch 33 minibatch 1201/5000 completed\n",
      " bpr_loss on current minibatch is 0.693806, and regularization loss is 0.000659.\n",
      " Top K precision = 0.014999999999999998, recall = 0.008342363654863655.\n",
      "Training on epoch 33 minibatch 1301/5000 completed\n",
      " bpr_loss on current minibatch is 0.693886, and regularization loss is 0.000739.\n",
      " Top K precision = 0.013333333333333332, recall = 0.004631199023000099.\n",
      "Training on epoch 33 minibatch 1401/5000 completed\n",
      " bpr_loss on current minibatch is 0.693645, and regularization loss is 0.000498.\n",
      " Top K precision = 0.011666666666666665, recall = 0.00576710315882104.\n",
      "Training on epoch 33 minibatch 1501/5000 completed\n",
      " bpr_loss on current minibatch is 0.693782, and regularization loss is 0.000635.\n",
      " Top K precision = 0.008333333333333333, recall = 0.0024197195195827205.\n",
      "Training on epoch 33 minibatch 1601/5000 completed\n",
      " bpr_loss on current minibatch is 0.693779, and regularization loss is 0.000632.\n",
      " Top K precision = 0.013333333333333332, recall = 0.004867324033990701.\n",
      "Training on epoch 33 minibatch 1701/5000 completed\n",
      " bpr_loss on current minibatch is 0.693715, and regularization loss is 0.000568.\n",
      " Top K precision = 0.013333333333333332, recall = 0.006810601998700495.\n",
      "Training on epoch 33 minibatch 1801/5000 completed\n",
      " bpr_loss on current minibatch is 0.69381, and regularization loss is 0.000663.\n",
      " Top K precision = 0.016949152542372878, recall = 0.005735430379471858.\n",
      "Training on epoch 33 minibatch 1901/5000 completed\n",
      " bpr_loss on current minibatch is 0.693694, and regularization loss is 0.000547.\n",
      " Top K precision = 0.011864406779661016, recall = 0.00868549883211114.\n",
      "Training on epoch 33 minibatch 2001/5000 completed\n",
      " bpr_loss on current minibatch is 0.693758, and regularization loss is 0.000611.\n",
      " Top K precision = 0.011666666666666665, recall = 0.005047420902684061.\n",
      "Training on epoch 33 minibatch 2101/5000 completed\n",
      " bpr_loss on current minibatch is 0.693806, and regularization loss is 0.000659.\n",
      " Top K precision = 0.013559322033898305, recall = 0.007136005192768766.\n",
      "Training on epoch 33 minibatch 2201/5000 completed\n",
      " bpr_loss on current minibatch is 0.693731, and regularization loss is 0.000584.\n",
      " Top K precision = 0.014999999999999998, recall = 0.006245192849703094.\n",
      "Training on epoch 33 minibatch 2301/5000 completed\n",
      " bpr_loss on current minibatch is 0.693744, and regularization loss is 0.000596.\n",
      " Top K precision = 0.010344827586206896, recall = 0.0032121400983933664.\n",
      "Training on epoch 33 minibatch 2401/5000 completed\n",
      " bpr_loss on current minibatch is 0.693925, and regularization loss is 0.000778.\n",
      " Top K precision = 0.006666666666666667, recall = 0.0029669080107676596.\n",
      "Training on epoch 33 minibatch 2501/5000 completed\n",
      " bpr_loss on current minibatch is 0.693713, and regularization loss is 0.000566.\n",
      " Top K precision = 0.012280701754385965, recall = 0.005767721854163654.\n",
      "Training on epoch 33 minibatch 2601/5000 completed\n",
      " bpr_loss on current minibatch is 0.693821, and regularization loss is 0.000674.\n",
      " Top K precision = 0.01694915254237288, recall = 0.006590815912849811.\n",
      "Training on epoch 33 minibatch 2701/5000 completed\n",
      " bpr_loss on current minibatch is 0.693962, and regularization loss is 0.000815.\n",
      " Top K precision = 0.01833333333333333, recall = 0.007950148525091317.\n",
      "Training on epoch 33 minibatch 2801/5000 completed\n",
      " bpr_loss on current minibatch is 0.693818, and regularization loss is 0.00067.\n",
      " Top K precision = 0.014999999999999998, recall = 0.0069915065441381215.\n",
      "Training on epoch 33 minibatch 2901/5000 completed\n",
      " bpr_loss on current minibatch is 0.693946, and regularization loss is 0.000799.\n",
      " Top K precision = 0.01694915254237288, recall = 0.00548014446319531.\n",
      "Training on epoch 33 minibatch 3001/5000 completed\n",
      " bpr_loss on current minibatch is 0.69364, and regularization loss is 0.000493.\n",
      " Top K precision = 0.015254237288135592, recall = 0.010083431841840825.\n",
      "Training on epoch 33 minibatch 3101/5000 completed\n",
      " bpr_loss on current minibatch is 0.693806, and regularization loss is 0.000659.\n",
      " Top K precision = 0.006666666666666667, recall = 0.0018376068376068375.\n",
      "Training on epoch 33 minibatch 3201/5000 completed\n",
      " bpr_loss on current minibatch is 0.693664, and regularization loss is 0.000517.\n",
      " Top K precision = 0.010169491525423728, recall = 0.0049646309570854875.\n",
      "Training on epoch 33 minibatch 3301/5000 completed\n",
      " bpr_loss on current minibatch is 0.693632, and regularization loss is 0.000485.\n",
      " Top K precision = 0.011864406779661016, recall = 0.0034706913025046035.\n",
      "Training on epoch 33 minibatch 3401/5000 completed\n",
      " bpr_loss on current minibatch is 0.693768, and regularization loss is 0.000621.\n",
      " Top K precision = 0.013333333333333332, recall = 0.005607355607355606.\n",
      "Training on epoch 33 minibatch 3501/5000 completed\n",
      " bpr_loss on current minibatch is 0.693785, and regularization loss is 0.000638.\n",
      " Top K precision = 0.01833333333333333, recall = 0.006972614355807088.\n",
      "Training on epoch 33 minibatch 3601/5000 completed\n",
      " bpr_loss on current minibatch is 0.693701, and regularization loss is 0.000554.\n",
      " Top K precision = 0.016666666666666666, recall = 0.007676216411679038.\n",
      "Training on epoch 33 minibatch 3701/5000 completed\n",
      " bpr_loss on current minibatch is 0.693672, and regularization loss is 0.000525.\n",
      " Top K precision = 0.016666666666666666, recall = 0.007160321144141734.\n",
      "Training on epoch 33 minibatch 3801/5000 completed\n",
      " bpr_loss on current minibatch is 0.693893, and regularization loss is 0.000746.\n",
      " Top K precision = 0.015254237288135592, recall = 0.008609456023463998.\n",
      "Training on epoch 33 minibatch 3901/5000 completed\n",
      " bpr_loss on current minibatch is 0.69368, and regularization loss is 0.000533.\n",
      " Top K precision = 0.02, recall = 0.008151861620011266.\n",
      "Training on epoch 33 minibatch 4001/5000 completed\n",
      " bpr_loss on current minibatch is 0.693773, and regularization loss is 0.000626.\n",
      " Top K precision = 0.011666666666666665, recall = 0.004826403574454226.\n",
      "Training on epoch 33 minibatch 4101/5000 completed\n",
      " bpr_loss on current minibatch is 0.693743, and regularization loss is 0.000595.\n",
      " Top K precision = 0.008333333333333333, recall = 0.0030699384130756678.\n",
      "Training on epoch 33 minibatch 4201/5000 completed\n",
      " bpr_loss on current minibatch is 0.693753, and regularization loss is 0.000606.\n",
      " Top K precision = 0.018333333333333333, recall = 0.008562882157115903.\n",
      "Training on epoch 33 minibatch 4301/5000 completed\n",
      " bpr_loss on current minibatch is 0.693713, and regularization loss is 0.000566.\n",
      " Top K precision = 0.01, recall = 0.004562248256213774.\n",
      "Training on epoch 33 minibatch 4401/5000 completed\n",
      " bpr_loss on current minibatch is 0.693746, and regularization loss is 0.000599.\n",
      " Top K precision = 0.013333333333333332, recall = 0.006057338677774782.\n",
      "Training on epoch 33 minibatch 4501/5000 completed\n",
      " bpr_loss on current minibatch is 0.693675, and regularization loss is 0.000527.\n",
      " Top K precision = 0.013333333333333332, recall = 0.007196318342151675.\n",
      "Training on epoch 33 minibatch 4601/5000 completed\n",
      " bpr_loss on current minibatch is 0.693985, and regularization loss is 0.000838.\n",
      " Top K precision = 0.008333333333333333, recall = 0.004320956986398163.\n",
      "Training on epoch 33 minibatch 4701/5000 completed\n",
      " bpr_loss on current minibatch is 0.693838, and regularization loss is 0.00069.\n",
      " Top K precision = 0.01, recall = 0.0057805318509832875.\n",
      "Training on epoch 33 minibatch 4801/5000 completed\n",
      " bpr_loss on current minibatch is 0.693724, and regularization loss is 0.000577.\n",
      " Top K precision = 0.005000000000000001, recall = 0.0015639114724480577.\n",
      "Training on epoch 33 minibatch 4901/5000 completed\n",
      " bpr_loss on current minibatch is 0.693815, and regularization loss is 0.000667.\n",
      " Top K precision = 0.011864406779661016, recall = 0.004245039291743722.\n",
      "\n",
      "Training on 33 epoch completed.\n",
      " Average bpr_loss on train set is 0.011563 for the current epoch.\n",
      " Training top K precision = 0.014400000000000107, recall = 0.006391265072333161.\n",
      " Average bpr_loss on the validation set is 2e-06, and regularization loss is 0.0.\n",
      " Validation top K precision = 0.014666666666666774, recall = 0.006537449028694951.\n",
      "\n",
      "Training on the 34 epoch\n",
      "Training on epoch 34 minibatch 1/5000 completed\n",
      " bpr_loss on current minibatch is 0.693832, and regularization loss is 0.000685.\n",
      " Top K precision = 0.015254237288135592, recall = 0.007174133008181179.\n",
      "Training on epoch 34 minibatch 101/5000 completed\n",
      " bpr_loss on current minibatch is 0.693911, and regularization loss is 0.000764.\n",
      " Top K precision = 0.010169491525423728, recall = 0.00416333502261764.\n",
      "Training on epoch 34 minibatch 201/5000 completed\n",
      " bpr_loss on current minibatch is 0.693763, and regularization loss is 0.000616.\n",
      " Top K precision = 0.013333333333333332, recall = 0.006090909090909091.\n",
      "Training on epoch 34 minibatch 301/5000 completed\n",
      " bpr_loss on current minibatch is 0.693873, and regularization loss is 0.000726.\n",
      " Top K precision = 0.013333333333333332, recall = 0.005359505011803861.\n",
      "Training on epoch 34 minibatch 401/5000 completed\n",
      " bpr_loss on current minibatch is 0.693759, and regularization loss is 0.000612.\n",
      " Top K precision = 0.013333333333333332, recall = 0.005605342116970025.\n",
      "Training on epoch 34 minibatch 501/5000 completed\n",
      " bpr_loss on current minibatch is 0.693914, and regularization loss is 0.000766.\n",
      " Top K precision = 0.013333333333333332, recall = 0.005521264665286404.\n",
      "Training on epoch 34 minibatch 601/5000 completed\n",
      " bpr_loss on current minibatch is 0.693918, and regularization loss is 0.000771.\n",
      " Top K precision = 0.026666666666666672, recall = 0.012737123066630461.\n",
      "Training on epoch 34 minibatch 701/5000 completed\n",
      " bpr_loss on current minibatch is 0.69375, and regularization loss is 0.000603.\n",
      " Top K precision = 0.006896551724137932, recall = 0.003024572757609465.\n",
      "Training on epoch 34 minibatch 801/5000 completed\n",
      " bpr_loss on current minibatch is 0.693866, and regularization loss is 0.000719.\n",
      " Top K precision = 0.016666666666666666, recall = 0.007493252361673415.\n",
      "Training on epoch 34 minibatch 901/5000 completed\n",
      " bpr_loss on current minibatch is 0.693738, and regularization loss is 0.000591.\n",
      " Top K precision = 0.00847457627118644, recall = 0.004412061434743389.\n",
      "Training on epoch 34 minibatch 1001/5000 completed\n",
      " bpr_loss on current minibatch is 0.693899, and regularization loss is 0.000751.\n",
      " Top K precision = 0.013559322033898305, recall = 0.006578661287920606.\n",
      "Training on epoch 34 minibatch 1101/5000 completed\n",
      " bpr_loss on current minibatch is 0.693742, and regularization loss is 0.000595.\n",
      " Top K precision = 0.014999999999999998, recall = 0.009469214852341788.\n",
      "Training on epoch 34 minibatch 1201/5000 completed\n",
      " bpr_loss on current minibatch is 0.693798, and regularization loss is 0.00065.\n",
      " Top K precision = 0.011666666666666665, recall = 0.003499949870917613.\n",
      "Training on epoch 34 minibatch 1301/5000 completed\n",
      " bpr_loss on current minibatch is 0.693752, and regularization loss is 0.000605.\n",
      " Top K precision = 0.010344827586206896, recall = 0.0041021034346191195.\n",
      "Training on epoch 34 minibatch 1401/5000 completed\n",
      " bpr_loss on current minibatch is 0.693805, and regularization loss is 0.000658.\n",
      " Top K precision = 0.021666666666666667, recall = 0.006558656123085157.\n",
      "Training on epoch 34 minibatch 1501/5000 completed\n",
      " bpr_loss on current minibatch is 0.693839, and regularization loss is 0.000692.\n",
      " Top K precision = 0.013333333333333332, recall = 0.006849007124494381.\n",
      "Training on epoch 34 minibatch 1601/5000 completed\n",
      " bpr_loss on current minibatch is 0.69386, and regularization loss is 0.000713.\n",
      " Top K precision = 0.018644067796610167, recall = 0.007762094625176076.\n",
      "Training on epoch 34 minibatch 1701/5000 completed\n",
      " bpr_loss on current minibatch is 0.693996, and regularization loss is 0.000849.\n",
      " Top K precision = 0.016666666666666666, recall = 0.00788255916320881.\n",
      "Training on epoch 34 minibatch 1801/5000 completed\n",
      " bpr_loss on current minibatch is 0.693732, and regularization loss is 0.000585.\n",
      " Top K precision = 0.010344827586206896, recall = 0.00541178080756941.\n",
      "Training on epoch 34 minibatch 1901/5000 completed\n",
      " bpr_loss on current minibatch is 0.693688, and regularization loss is 0.000541.\n",
      " Top K precision = 0.008333333333333333, recall = 0.0024199269692227435.\n",
      "Training on epoch 34 minibatch 2001/5000 completed\n",
      " bpr_loss on current minibatch is 0.693971, and regularization loss is 0.000824.\n",
      " Top K precision = 0.011666666666666665, recall = 0.004192866610629768.\n",
      "Training on epoch 34 minibatch 2101/5000 completed\n",
      " bpr_loss on current minibatch is 0.693736, and regularization loss is 0.000589.\n",
      " Top K precision = 0.011666666666666665, recall = 0.007396793394777265.\n",
      "Training on epoch 34 minibatch 2201/5000 completed\n",
      " bpr_loss on current minibatch is 0.693674, and regularization loss is 0.000527.\n",
      " Top K precision = 0.02166666666666667, recall = 0.010627410697903026.\n",
      "Training on epoch 34 minibatch 2301/5000 completed\n",
      " bpr_loss on current minibatch is 0.693758, and regularization loss is 0.000611.\n",
      " Top K precision = 0.010000000000000002, recall = 0.003052846063598752.\n",
      "Training on epoch 34 minibatch 2401/5000 completed\n",
      " bpr_loss on current minibatch is 0.693891, and regularization loss is 0.000743.\n",
      " Top K precision = 0.010169491525423728, recall = 0.003718854445768531.\n",
      "Training on epoch 34 minibatch 2501/5000 completed\n",
      " bpr_loss on current minibatch is 0.693711, and regularization loss is 0.000564.\n",
      " Top K precision = 0.02241379310344828, recall = 0.00864913242988911.\n",
      "Training on epoch 34 minibatch 2601/5000 completed\n",
      " bpr_loss on current minibatch is 0.693786, and regularization loss is 0.000639.\n",
      " Top K precision = 0.008333333333333333, recall = 0.002755885300642334.\n",
      "Training on epoch 34 minibatch 2701/5000 completed\n",
      " bpr_loss on current minibatch is 0.69375, and regularization loss is 0.000603.\n",
      " Top K precision = 0.01833333333333333, recall = 0.0077374665300028985.\n",
      "Training on epoch 34 minibatch 2801/5000 completed\n",
      " bpr_loss on current minibatch is 0.693716, and regularization loss is 0.000568.\n",
      " Top K precision = 0.013559322033898305, recall = 0.007190893144217382.\n",
      "Training on epoch 34 minibatch 2901/5000 completed\n",
      " bpr_loss on current minibatch is 0.69377, and regularization loss is 0.000623.\n",
      " Top K precision = 0.020689655172413796, recall = 0.00772501688261133.\n",
      "Training on epoch 34 minibatch 3001/5000 completed\n",
      " bpr_loss on current minibatch is 0.693804, and regularization loss is 0.000657.\n",
      " Top K precision = 0.014999999999999998, recall = 0.006405627655627657.\n",
      "Training on epoch 34 minibatch 3101/5000 completed\n",
      " bpr_loss on current minibatch is 0.693818, and regularization loss is 0.000671.\n",
      " Top K precision = 0.010169491525423728, recall = 0.002844528764419204.\n",
      "Training on epoch 34 minibatch 3201/5000 completed\n",
      " bpr_loss on current minibatch is 0.693777, and regularization loss is 0.00063.\n",
      " Top K precision = 0.011666666666666665, recall = 0.005963807209243315.\n",
      "Training on epoch 34 minibatch 3301/5000 completed\n",
      " bpr_loss on current minibatch is 0.693796, and regularization loss is 0.000649.\n",
      " Top K precision = 0.013333333333333332, recall = 0.00575479038288075.\n",
      "Training on epoch 34 minibatch 3401/5000 completed\n",
      " bpr_loss on current minibatch is 0.693821, and regularization loss is 0.000674.\n",
      " Top K precision = 0.020338983050847456, recall = 0.009499796224451004.\n",
      "Training on epoch 34 minibatch 3501/5000 completed\n",
      " bpr_loss on current minibatch is 0.693821, and regularization loss is 0.000674.\n",
      " Top K precision = 0.006666666666666667, recall = 0.0020248015873015873.\n",
      "Training on epoch 34 minibatch 3601/5000 completed\n",
      " bpr_loss on current minibatch is 0.693799, and regularization loss is 0.000652.\n",
      " Top K precision = 0.013333333333333332, recall = 0.004056095797986863.\n",
      "Training on epoch 34 minibatch 3701/5000 completed\n",
      " bpr_loss on current minibatch is 0.693797, and regularization loss is 0.00065.\n",
      " Top K precision = 0.011666666666666665, recall = 0.005638273763273764.\n",
      "Training on epoch 34 minibatch 3801/5000 completed\n",
      " bpr_loss on current minibatch is 0.693798, and regularization loss is 0.000651.\n",
      " Top K precision = 0.013333333333333332, recall = 0.007311711300681889.\n",
      "Training on epoch 34 minibatch 3901/5000 completed\n",
      " bpr_loss on current minibatch is 0.693733, and regularization loss is 0.000586.\n",
      " Top K precision = 0.005084745762711865, recall = 0.0019512889901723402.\n",
      "Training on epoch 34 minibatch 4001/5000 completed\n",
      " bpr_loss on current minibatch is 0.693907, and regularization loss is 0.00076.\n",
      " Top K precision = 0.01, recall = 0.003660483989253428.\n",
      "Training on epoch 34 minibatch 4101/5000 completed\n",
      " bpr_loss on current minibatch is 0.693689, and regularization loss is 0.000542.\n",
      " Top K precision = 0.011864406779661016, recall = 0.007897861354210644.\n",
      "Training on epoch 34 minibatch 4201/5000 completed\n",
      " bpr_loss on current minibatch is 0.693676, and regularization loss is 0.000529.\n",
      " Top K precision = 0.010344827586206898, recall = 0.0030602426647051394.\n",
      "Training on epoch 34 minibatch 4301/5000 completed\n",
      " bpr_loss on current minibatch is 0.693763, and regularization loss is 0.000616.\n",
      " Top K precision = 0.023333333333333334, recall = 0.009487210094212658.\n",
      "Training on epoch 34 minibatch 4401/5000 completed\n",
      " bpr_loss on current minibatch is 0.693713, and regularization loss is 0.000566.\n",
      " Top K precision = 0.015254237288135592, recall = 0.007151904493563726.\n",
      "Training on epoch 34 minibatch 4501/5000 completed\n",
      " bpr_loss on current minibatch is 0.693811, and regularization loss is 0.000664.\n",
      " Top K precision = 0.01, recall = 0.003888148076744568.\n",
      "Training on epoch 34 minibatch 4601/5000 completed\n",
      " bpr_loss on current minibatch is 0.693724, and regularization loss is 0.000576.\n",
      " Top K precision = 0.010169491525423728, recall = 0.003056482940515055.\n",
      "Training on epoch 34 minibatch 4701/5000 completed\n",
      " bpr_loss on current minibatch is 0.693792, and regularization loss is 0.000644.\n",
      " Top K precision = 0.006779661016949153, recall = 0.0035902264715824035.\n",
      "Training on epoch 34 minibatch 4801/5000 completed\n",
      " bpr_loss on current minibatch is 0.693817, and regularization loss is 0.00067.\n",
      " Top K precision = 0.013559322033898305, recall = 0.007421590034097339.\n",
      "Training on epoch 34 minibatch 4901/5000 completed\n",
      " bpr_loss on current minibatch is 0.69392, and regularization loss is 0.000773.\n",
      " Top K precision = 0.021666666666666667, recall = 0.0116375503036489.\n",
      "\n",
      "Training on 34 epoch completed.\n",
      " Average bpr_loss on train set is 0.011563 for the current epoch.\n",
      " Training top K precision = 0.014633333333333443, recall = 0.006472727769272711.\n",
      " Average bpr_loss on the validation set is 2e-06, and regularization loss is 0.0.\n",
      " Validation top K precision = 0.014166666666666767, recall = 0.0060543411504884745.\n",
      "\n",
      "Training on the 35 epoch\n",
      "Training on epoch 35 minibatch 1/5000 completed\n",
      " bpr_loss on current minibatch is 0.693608, and regularization loss is 0.000461.\n",
      " Top K precision = 0.014999999999999998, recall = 0.006905004717504717.\n",
      "Training on epoch 35 minibatch 101/5000 completed\n",
      " bpr_loss on current minibatch is 0.693646, and regularization loss is 0.000499.\n",
      " Top K precision = 0.01379310344827586, recall = 0.0057483803024825616.\n",
      "Training on epoch 35 minibatch 201/5000 completed\n",
      " bpr_loss on current minibatch is 0.693938, and regularization loss is 0.000791.\n",
      " Top K precision = 0.010169491525423728, recall = 0.003578153672207894.\n",
      "Training on epoch 35 minibatch 301/5000 completed\n",
      " bpr_loss on current minibatch is 0.693769, and regularization loss is 0.000622.\n",
      " Top K precision = 0.013333333333333332, recall = 0.004991312674780416.\n",
      "Training on epoch 35 minibatch 401/5000 completed\n",
      " bpr_loss on current minibatch is 0.693841, and regularization loss is 0.000694.\n",
      " Top K precision = 0.013559322033898305, recall = 0.0077259383465764315.\n",
      "Training on epoch 35 minibatch 501/5000 completed\n",
      " bpr_loss on current minibatch is 0.693764, and regularization loss is 0.000616.\n",
      " Top K precision = 0.013333333333333332, recall = 0.005081785330879534.\n",
      "Training on epoch 35 minibatch 601/5000 completed\n",
      " bpr_loss on current minibatch is 0.693957, and regularization loss is 0.00081.\n",
      " Top K precision = 0.013559322033898305, recall = 0.004685153446340357.\n",
      "Training on epoch 35 minibatch 701/5000 completed\n",
      " bpr_loss on current minibatch is 0.69373, and regularization loss is 0.000583.\n",
      " Top K precision = 0.013333333333333332, recall = 0.006256764069264068.\n",
      "Training on epoch 35 minibatch 801/5000 completed\n",
      " bpr_loss on current minibatch is 0.693814, and regularization loss is 0.000667.\n",
      " Top K precision = 0.006779661016949153, recall = 0.00309285817760394.\n",
      "Training on epoch 35 minibatch 901/5000 completed\n",
      " bpr_loss on current minibatch is 0.693854, and regularization loss is 0.000706.\n",
      " Top K precision = 0.013559322033898305, recall = 0.00420514192153113.\n",
      "Training on epoch 35 minibatch 1001/5000 completed\n",
      " bpr_loss on current minibatch is 0.69378, and regularization loss is 0.000633.\n",
      " Top K precision = 0.011864406779661016, recall = 0.005511389807186628.\n",
      "Training on epoch 35 minibatch 1101/5000 completed\n",
      " bpr_loss on current minibatch is 0.69375, and regularization loss is 0.000603.\n",
      " Top K precision = 0.006666666666666667, recall = 0.0038771544653897596.\n",
      "Training on epoch 35 minibatch 1201/5000 completed\n",
      " bpr_loss on current minibatch is 0.69382, and regularization loss is 0.000673.\n",
      " Top K precision = 0.008333333333333333, recall = 0.003339212015682604.\n",
      "Training on epoch 35 minibatch 1301/5000 completed\n",
      " bpr_loss on current minibatch is 0.693824, and regularization loss is 0.000677.\n",
      " Top K precision = 0.008333333333333333, recall = 0.004098290598290598.\n",
      "Training on epoch 35 minibatch 1401/5000 completed\n",
      " bpr_loss on current minibatch is 0.693864, and regularization loss is 0.000717.\n",
      " Top K precision = 0.00847457627118644, recall = 0.0044553665427884874.\n",
      "Training on epoch 35 minibatch 1501/5000 completed\n",
      " bpr_loss on current minibatch is 0.69373, and regularization loss is 0.000583.\n",
      " Top K precision = 0.018644067796610167, recall = 0.010524525652759372.\n",
      "Training on epoch 35 minibatch 1601/5000 completed\n",
      " bpr_loss on current minibatch is 0.693713, and regularization loss is 0.000565.\n",
      " Top K precision = 0.011864406779661016, recall = 0.005379648599987583.\n",
      "Training on epoch 35 minibatch 1701/5000 completed\n",
      " bpr_loss on current minibatch is 0.693788, and regularization loss is 0.000641.\n",
      " Top K precision = 0.01206896551724138, recall = 0.005500352893728575.\n",
      "Training on epoch 35 minibatch 1801/5000 completed\n",
      " bpr_loss on current minibatch is 0.693871, and regularization loss is 0.000724.\n",
      " Top K precision = 0.020689655172413793, recall = 0.009890952271783915.\n",
      "Training on epoch 35 minibatch 1901/5000 completed\n",
      " bpr_loss on current minibatch is 0.693856, and regularization loss is 0.000709.\n",
      " Top K precision = 0.01, recall = 0.0064060245310245305.\n",
      "Training on epoch 35 minibatch 2001/5000 completed\n",
      " bpr_loss on current minibatch is 0.69386, and regularization loss is 0.000713.\n",
      " Top K precision = 0.013333333333333332, recall = 0.008563090418353576.\n",
      "Training on epoch 35 minibatch 2101/5000 completed\n",
      " bpr_loss on current minibatch is 0.693733, and regularization loss is 0.000586.\n",
      " Top K precision = 0.005000000000000001, recall = 0.0022123015873015874.\n",
      "Training on epoch 35 minibatch 2201/5000 completed\n",
      " bpr_loss on current minibatch is 0.693805, and regularization loss is 0.000658.\n",
      " Top K precision = 0.01833333333333333, recall = 0.007818528612846664.\n",
      "Training on epoch 35 minibatch 2301/5000 completed\n",
      " bpr_loss on current minibatch is 0.693805, and regularization loss is 0.000657.\n",
      " Top K precision = 0.005000000000000001, recall = 0.0023162071846282374.\n",
      "Training on epoch 35 minibatch 2401/5000 completed\n",
      " bpr_loss on current minibatch is 0.693789, and regularization loss is 0.000642.\n",
      " Top K precision = 0.011864406779661016, recall = 0.004595686018734656.\n",
      "Training on epoch 35 minibatch 2501/5000 completed\n",
      " bpr_loss on current minibatch is 0.693881, and regularization loss is 0.000734.\n",
      " Top K precision = 0.013333333333333332, recall = 0.005360444496600102.\n",
      "Training on epoch 35 minibatch 2601/5000 completed\n",
      " bpr_loss on current minibatch is 0.693804, and regularization loss is 0.000657.\n",
      " Top K precision = 0.011666666666666665, recall = 0.0047731886441563865.\n",
      "Training on epoch 35 minibatch 2701/5000 completed\n",
      " bpr_loss on current minibatch is 0.693886, and regularization loss is 0.000739.\n",
      " Top K precision = 0.018965517241379307, recall = 0.008256506424609874.\n",
      "Training on epoch 35 minibatch 2801/5000 completed\n",
      " bpr_loss on current minibatch is 0.693721, and regularization loss is 0.000574.\n",
      " Top K precision = 0.01, recall = 0.004911125535410432.\n",
      "Training on epoch 35 minibatch 2901/5000 completed\n",
      " bpr_loss on current minibatch is 0.693997, and regularization loss is 0.00085.\n",
      " Top K precision = 0.01, recall = 0.0031807659932659932.\n",
      "Training on epoch 35 minibatch 3001/5000 completed\n",
      " bpr_loss on current minibatch is 0.693828, and regularization loss is 0.00068.\n",
      " Top K precision = 0.014999999999999998, recall = 0.004747460665223824.\n",
      "Training on epoch 35 minibatch 3101/5000 completed\n",
      " bpr_loss on current minibatch is 0.693812, and regularization loss is 0.000665.\n",
      " Top K precision = 0.006779661016949153, recall = 0.0042054931885440365.\n",
      "Training on epoch 35 minibatch 3201/5000 completed\n",
      " bpr_loss on current minibatch is 0.694116, and regularization loss is 0.000969.\n",
      " Top K precision = 0.011864406779661016, recall = 0.004346686323517926.\n",
      "Training on epoch 35 minibatch 3301/5000 completed\n",
      " bpr_loss on current minibatch is 0.693781, and regularization loss is 0.000634.\n",
      " Top K precision = 0.013559322033898305, recall = 0.004207547892146271.\n",
      "Training on epoch 35 minibatch 3401/5000 completed\n",
      " bpr_loss on current minibatch is 0.693923, and regularization loss is 0.000776.\n",
      " Top K precision = 0.011864406779661016, recall = 0.004812393139272965.\n",
      "Training on epoch 35 minibatch 3501/5000 completed\n",
      " bpr_loss on current minibatch is 0.693767, and regularization loss is 0.00062.\n",
      " Top K precision = 0.016666666666666666, recall = 0.007583734433744313.\n",
      "Training on epoch 35 minibatch 3601/5000 completed\n",
      " bpr_loss on current minibatch is 0.694062, and regularization loss is 0.000915.\n",
      " Top K precision = 0.013333333333333332, recall = 0.0061415386111849535.\n",
      "Training on epoch 35 minibatch 3701/5000 completed\n",
      " bpr_loss on current minibatch is 0.693665, and regularization loss is 0.000518.\n",
      " Top K precision = 0.02, recall = 0.006865726498990042.\n",
      "Training on epoch 35 minibatch 3801/5000 completed\n",
      " bpr_loss on current minibatch is 0.693811, and regularization loss is 0.000663.\n",
      " Top K precision = 0.016666666666666666, recall = 0.007531647368754207.\n",
      "Training on epoch 35 minibatch 3901/5000 completed\n",
      " bpr_loss on current minibatch is 0.693806, and regularization loss is 0.000659.\n",
      " Top K precision = 0.013559322033898306, recall = 0.0053263608118066475.\n",
      "Training on epoch 35 minibatch 4001/5000 completed\n",
      " bpr_loss on current minibatch is 0.693612, and regularization loss is 0.000465.\n",
      " Top K precision = 0.02033898305084746, recall = 0.00845670980280025.\n",
      "Training on epoch 35 minibatch 4101/5000 completed\n",
      " bpr_loss on current minibatch is 0.694237, and regularization loss is 0.00109.\n",
      " Top K precision = 0.01206896551724138, recall = 0.00487654905758354.\n",
      "Training on epoch 35 minibatch 4201/5000 completed\n",
      " bpr_loss on current minibatch is 0.693827, and regularization loss is 0.00068.\n",
      " Top K precision = 0.011666666666666665, recall = 0.005361735273819673.\n",
      "Training on epoch 35 minibatch 4301/5000 completed\n",
      " bpr_loss on current minibatch is 0.693702, and regularization loss is 0.000555.\n",
      " Top K precision = 0.011666666666666665, recall = 0.005343372751909338.\n",
      "Training on epoch 35 minibatch 4401/5000 completed\n",
      " bpr_loss on current minibatch is 0.693842, and regularization loss is 0.000695.\n",
      " Top K precision = 0.006666666666666667, recall = 0.0026347664867800292.\n",
      "Training on epoch 35 minibatch 4501/5000 completed\n",
      " bpr_loss on current minibatch is 0.693675, and regularization loss is 0.000528.\n",
      " Top K precision = 0.016949152542372878, recall = 0.010191820092462991.\n",
      "Training on epoch 35 minibatch 4601/5000 completed\n",
      " bpr_loss on current minibatch is 0.693935, and regularization loss is 0.000788.\n",
      " Top K precision = 0.021666666666666667, recall = 0.006904220617251112.\n",
      "Training on epoch 35 minibatch 4701/5000 completed\n",
      " bpr_loss on current minibatch is 0.69395, and regularization loss is 0.000803.\n",
      " Top K precision = 0.008333333333333333, recall = 0.004036248337718926.\n",
      "Training on epoch 35 minibatch 4801/5000 completed\n",
      " bpr_loss on current minibatch is 0.693697, and regularization loss is 0.00055.\n",
      " Top K precision = 0.016949152542372878, recall = 0.009641433241285857.\n",
      "Training on epoch 35 minibatch 4901/5000 completed\n",
      " bpr_loss on current minibatch is 0.693601, and regularization loss is 0.000454.\n",
      " Top K precision = 0.010169491525423728, recall = 0.003971803390408042.\n",
      "\n",
      "Training on 35 epoch completed.\n",
      " Average bpr_loss on train set is 0.011563 for the current epoch.\n",
      " Training top K precision = 0.013233333333333422, recall = 0.005987614391170284.\n",
      " Average bpr_loss on the validation set is 2e-06, and regularization loss is 0.0.\n",
      " Validation top K precision = 0.0140000000000001, recall = 0.006002413759671649.\n",
      "\n",
      "Training on the 36 epoch\n",
      "Training on epoch 36 minibatch 1/5000 completed\n",
      " bpr_loss on current minibatch is 0.693824, and regularization loss is 0.000677.\n",
      " Top K precision = 0.006666666666666667, recall = 0.002614616324448715.\n",
      "Training on epoch 36 minibatch 101/5000 completed\n",
      " bpr_loss on current minibatch is 0.693891, and regularization loss is 0.000744.\n",
      " Top K precision = 0.011864406779661016, recall = 0.0054755732135724.\n",
      "Training on epoch 36 minibatch 201/5000 completed\n",
      " bpr_loss on current minibatch is 0.693801, and regularization loss is 0.000653.\n",
      " Top K precision = 0.013333333333333332, recall = 0.005546481517312461.\n",
      "Training on epoch 36 minibatch 301/5000 completed\n",
      " bpr_loss on current minibatch is 0.693898, and regularization loss is 0.000751.\n",
      " Top K precision = 0.016949152542372878, recall = 0.01044926935984028.\n",
      "Training on epoch 36 minibatch 401/5000 completed\n",
      " bpr_loss on current minibatch is 0.693686, and regularization loss is 0.000539.\n",
      " Top K precision = 0.01, recall = 0.003756950234253198.\n",
      "Training on epoch 36 minibatch 501/5000 completed\n",
      " bpr_loss on current minibatch is 0.693875, and regularization loss is 0.000728.\n",
      " Top K precision = 0.006666666666666667, recall = 0.001901462982056406.\n",
      "Training on epoch 36 minibatch 601/5000 completed\n",
      " bpr_loss on current minibatch is 0.693845, and regularization loss is 0.000697.\n",
      " Top K precision = 0.02542372881355933, recall = 0.011708763136419895.\n",
      "Training on epoch 36 minibatch 701/5000 completed\n",
      " bpr_loss on current minibatch is 0.693799, and regularization loss is 0.000652.\n",
      " Top K precision = 0.011864406779661016, recall = 0.004052001543248731.\n",
      "Training on epoch 36 minibatch 801/5000 completed\n",
      " bpr_loss on current minibatch is 0.69391, and regularization loss is 0.000763.\n",
      " Top K precision = 0.013333333333333332, recall = 0.008093750050271789.\n",
      "Training on epoch 36 minibatch 901/5000 completed\n",
      " bpr_loss on current minibatch is 0.693731, and regularization loss is 0.000584.\n",
      " Top K precision = 0.023728813559322035, recall = 0.014358257040733806.\n",
      "Training on epoch 36 minibatch 1001/5000 completed\n",
      " bpr_loss on current minibatch is 0.693611, and regularization loss is 0.000463.\n",
      " Top K precision = 0.011666666666666665, recall = 0.004316895518456685.\n",
      "Training on epoch 36 minibatch 1101/5000 completed\n",
      " bpr_loss on current minibatch is 0.693653, and regularization loss is 0.000506.\n",
      " Top K precision = 0.020689655172413793, recall = 0.009136905050751532.\n",
      "Training on epoch 36 minibatch 1201/5000 completed\n",
      " bpr_loss on current minibatch is 0.693768, and regularization loss is 0.00062.\n",
      " Top K precision = 0.013333333333333332, recall = 0.006681996027192379.\n",
      "Training on epoch 36 minibatch 1301/5000 completed\n",
      " bpr_loss on current minibatch is 0.693824, and regularization loss is 0.000676.\n",
      " Top K precision = 0.005000000000000001, recall = 0.0031849551414768807.\n",
      "Training on epoch 36 minibatch 1401/5000 completed\n",
      " bpr_loss on current minibatch is 0.693808, and regularization loss is 0.000661.\n",
      " Top K precision = 0.011864406779661016, recall = 0.005007067561265433.\n",
      "Training on epoch 36 minibatch 1501/5000 completed\n",
      " bpr_loss on current minibatch is 0.693903, and regularization loss is 0.000756.\n",
      " Top K precision = 0.014999999999999998, recall = 0.006522811003182688.\n",
      "Training on epoch 36 minibatch 1601/5000 completed\n",
      " bpr_loss on current minibatch is 0.693915, and regularization loss is 0.000768.\n",
      " Top K precision = 0.011864406779661016, recall = 0.006102080316935751.\n",
      "Training on epoch 36 minibatch 1701/5000 completed\n",
      " bpr_loss on current minibatch is 0.693737, and regularization loss is 0.00059.\n",
      " Top K precision = 0.016666666666666666, recall = 0.006008367928578186.\n",
      "Training on epoch 36 minibatch 1801/5000 completed\n",
      " bpr_loss on current minibatch is 0.693869, and regularization loss is 0.000722.\n",
      " Top K precision = 0.011864406779661016, recall = 0.005272891301856644.\n",
      "Training on epoch 36 minibatch 1901/5000 completed\n",
      " bpr_loss on current minibatch is 0.693793, and regularization loss is 0.000646.\n",
      " Top K precision = 0.008333333333333333, recall = 0.0026356131625863374.\n",
      "Training on epoch 36 minibatch 2001/5000 completed\n",
      " bpr_loss on current minibatch is 0.693872, and regularization loss is 0.000725.\n",
      " Top K precision = 0.011666666666666665, recall = 0.004996741609644835.\n",
      "Training on epoch 36 minibatch 2101/5000 completed\n",
      " bpr_loss on current minibatch is 0.693758, and regularization loss is 0.000611.\n",
      " Top K precision = 0.01, recall = 0.004346409773080766.\n",
      "Training on epoch 36 minibatch 2201/5000 completed\n",
      " bpr_loss on current minibatch is 0.693791, and regularization loss is 0.000644.\n",
      " Top K precision = 0.018644067796610167, recall = 0.009488890167897933.\n",
      "Training on epoch 36 minibatch 2301/5000 completed\n",
      " bpr_loss on current minibatch is 0.693741, and regularization loss is 0.000593.\n",
      " Top K precision = 0.006666666666666667, recall = 0.00471210706504824.\n",
      "Training on epoch 36 minibatch 2401/5000 completed\n",
      " bpr_loss on current minibatch is 0.693743, and regularization loss is 0.000596.\n",
      " Top K precision = 0.011666666666666665, recall = 0.004292535670324716.\n",
      "Training on epoch 36 minibatch 2501/5000 completed\n",
      " bpr_loss on current minibatch is 0.693746, and regularization loss is 0.000599.\n",
      " Top K precision = 0.011666666666666667, recall = 0.004563572910771552.\n",
      "Training on epoch 36 minibatch 2601/5000 completed\n",
      " bpr_loss on current minibatch is 0.693749, and regularization loss is 0.000602.\n",
      " Top K precision = 0.01379310344827586, recall = 0.0052537344687979895.\n",
      "Training on epoch 36 minibatch 2701/5000 completed\n",
      " bpr_loss on current minibatch is 0.693762, and regularization loss is 0.000615.\n",
      " Top K precision = 0.014999999999999998, recall = 0.004893904370116621.\n",
      "Training on epoch 36 minibatch 2801/5000 completed\n",
      " bpr_loss on current minibatch is 0.693697, and regularization loss is 0.00055.\n",
      " Top K precision = 0.017241379310344827, recall = 0.009842658586920357.\n",
      "Training on epoch 36 minibatch 2901/5000 completed\n",
      " bpr_loss on current minibatch is 0.693635, and regularization loss is 0.000488.\n",
      " Top K precision = 0.013559322033898305, recall = 0.006408949148100116.\n",
      "Training on epoch 36 minibatch 3001/5000 completed\n",
      " bpr_loss on current minibatch is 0.693787, and regularization loss is 0.00064.\n",
      " Top K precision = 0.014999999999999998, recall = 0.005777932829331229.\n",
      "Training on epoch 36 minibatch 3101/5000 completed\n",
      " bpr_loss on current minibatch is 0.693861, and regularization loss is 0.000714.\n",
      " Top K precision = 0.01206896551724138, recall = 0.0073184873597167445.\n",
      "Training on epoch 36 minibatch 3201/5000 completed\n",
      " bpr_loss on current minibatch is 0.694053, and regularization loss is 0.000906.\n",
      " Top K precision = 0.015254237288135592, recall = 0.008517156406640128.\n",
      "Training on epoch 36 minibatch 3301/5000 completed\n",
      " bpr_loss on current minibatch is 0.693905, and regularization loss is 0.000758.\n",
      " Top K precision = 0.011666666666666665, recall = 0.004620705547176136.\n",
      "Training on epoch 36 minibatch 3401/5000 completed\n",
      " bpr_loss on current minibatch is 0.693841, and regularization loss is 0.000694.\n",
      " Top K precision = 0.011666666666666665, recall = 0.006327690504361497.\n",
      "Training on epoch 36 minibatch 3501/5000 completed\n",
      " bpr_loss on current minibatch is 0.693799, and regularization loss is 0.000652.\n",
      " Top K precision = 0.005000000000000001, recall = 0.0015409788902075018.\n",
      "Training on epoch 36 minibatch 3601/5000 completed\n",
      " bpr_loss on current minibatch is 0.693842, and regularization loss is 0.000695.\n",
      " Top K precision = 0.013559322033898305, recall = 0.005382054837076867.\n",
      "Training on epoch 36 minibatch 3701/5000 completed\n",
      " bpr_loss on current minibatch is 0.693934, and regularization loss is 0.000787.\n",
      " Top K precision = 0.005357142857142858, recall = 0.00271092132505176.\n",
      "Training on epoch 36 minibatch 3801/5000 completed\n",
      " bpr_loss on current minibatch is 0.693831, and regularization loss is 0.000684.\n",
      " Top K precision = 0.022033898305084745, recall = 0.010019542220519932.\n",
      "Training on epoch 36 minibatch 3901/5000 completed\n",
      " bpr_loss on current minibatch is 0.69379, and regularization loss is 0.000643.\n",
      " Top K precision = 0.023728813559322035, recall = 0.011958627228160653.\n",
      "Training on epoch 36 minibatch 4001/5000 completed\n",
      " bpr_loss on current minibatch is 0.693749, and regularization loss is 0.000602.\n",
      " Top K precision = 0.006666666666666667, recall = 0.0029955229955229952.\n",
      "Training on epoch 36 minibatch 4101/5000 completed\n",
      " bpr_loss on current minibatch is 0.693843, and regularization loss is 0.000696.\n",
      " Top K precision = 0.02, recall = 0.008045863817566853.\n",
      "Training on epoch 36 minibatch 4201/5000 completed\n",
      " bpr_loss on current minibatch is 0.693785, and regularization loss is 0.000638.\n",
      " Top K precision = 0.008333333333333333, recall = 0.0033040919070330835.\n",
      "Training on epoch 36 minibatch 4301/5000 completed\n",
      " bpr_loss on current minibatch is 0.693722, and regularization loss is 0.000574.\n",
      " Top K precision = 0.011666666666666665, recall = 0.0075960025960025955.\n",
      "Training on epoch 36 minibatch 4401/5000 completed\n",
      " bpr_loss on current minibatch is 0.693659, and regularization loss is 0.000511.\n",
      " Top K precision = 0.011666666666666665, recall = 0.004248874811310312.\n",
      "Training on epoch 36 minibatch 4501/5000 completed\n",
      " bpr_loss on current minibatch is 0.693678, and regularization loss is 0.000531.\n",
      " Top K precision = 0.013559322033898305, recall = 0.006189564816898656.\n",
      "Training on epoch 36 minibatch 4601/5000 completed\n",
      " bpr_loss on current minibatch is 0.693912, and regularization loss is 0.000765.\n",
      " Top K precision = 0.016666666666666666, recall = 0.006986423328909979.\n",
      "Training on epoch 36 minibatch 4701/5000 completed\n",
      " bpr_loss on current minibatch is 0.693886, and regularization loss is 0.000738.\n",
      " Top K precision = 0.016666666666666666, recall = 0.005418675887863563.\n",
      "Training on epoch 36 minibatch 4801/5000 completed\n",
      " bpr_loss on current minibatch is 0.693792, and regularization loss is 0.000645.\n",
      " Top K precision = 0.008333333333333333, recall = 0.0023676184926184926.\n",
      "Training on epoch 36 minibatch 4901/5000 completed\n",
      " bpr_loss on current minibatch is 0.693881, and regularization loss is 0.000734.\n",
      " Top K precision = 0.01, recall = 0.0032219500929178352.\n",
      "\n",
      "Training on 36 epoch completed.\n",
      " Average bpr_loss on train set is 0.011563 for the current epoch.\n",
      " Training top K precision = 0.01536666666666678, recall = 0.0067524889686142175.\n",
      " Average bpr_loss on the validation set is 2e-06, and regularization loss is 0.0.\n",
      " Validation top K precision = 0.014666666666666774, recall = 0.00623047334280534.\n",
      "\n",
      "Training on the 37 epoch\n",
      "Training on epoch 37 minibatch 1/5000 completed\n",
      " bpr_loss on current minibatch is 0.693821, and regularization loss is 0.000674.\n",
      " Top K precision = 0.0033333333333333335, recall = 0.0010780885780885781.\n",
      "Training on epoch 37 minibatch 101/5000 completed\n",
      " bpr_loss on current minibatch is 0.693901, and regularization loss is 0.000754.\n",
      " Top K precision = 0.01, recall = 0.004106047937569677.\n",
      "Training on epoch 37 minibatch 201/5000 completed\n",
      " bpr_loss on current minibatch is 0.693758, and regularization loss is 0.000611.\n",
      " Top K precision = 0.00847457627118644, recall = 0.005304681194511704.\n",
      "Training on epoch 37 minibatch 301/5000 completed\n",
      " bpr_loss on current minibatch is 0.693745, and regularization loss is 0.000598.\n",
      " Top K precision = 0.015000000000000001, recall = 0.004772254710851202.\n",
      "Training on epoch 37 minibatch 401/5000 completed\n",
      " bpr_loss on current minibatch is 0.693864, and regularization loss is 0.000717.\n",
      " Top K precision = 0.014999999999999998, recall = 0.006793160888310141.\n",
      "Training on epoch 37 minibatch 501/5000 completed\n",
      " bpr_loss on current minibatch is 0.693704, and regularization loss is 0.000556.\n",
      " Top K precision = 0.014999999999999998, recall = 0.006131141168856685.\n",
      "Training on epoch 37 minibatch 601/5000 completed\n",
      " bpr_loss on current minibatch is 0.693796, and regularization loss is 0.000648.\n",
      " Top K precision = 0.010344827586206896, recall = 0.003332991242474001.\n",
      "Training on epoch 37 minibatch 701/5000 completed\n",
      " bpr_loss on current minibatch is 0.693844, and regularization loss is 0.000697.\n",
      " Top K precision = 0.023728813559322035, recall = 0.00940358770972066.\n",
      "Training on epoch 37 minibatch 801/5000 completed\n",
      " bpr_loss on current minibatch is 0.693856, and regularization loss is 0.000709.\n",
      " Top K precision = 0.013333333333333332, recall = 0.007352041341011929.\n",
      "Training on epoch 37 minibatch 901/5000 completed\n",
      " bpr_loss on current minibatch is 0.69395, and regularization loss is 0.000803.\n",
      " Top K precision = 0.013333333333333332, recall = 0.006370089451611192.\n",
      "Training on epoch 37 minibatch 1001/5000 completed\n",
      " bpr_loss on current minibatch is 0.693836, and regularization loss is 0.000689.\n",
      " Top K precision = 0.014999999999999998, recall = 0.0066169079167795065.\n",
      "Training on epoch 37 minibatch 1101/5000 completed\n",
      " bpr_loss on current minibatch is 0.693816, and regularization loss is 0.000669.\n",
      " Top K precision = 0.008333333333333333, recall = 0.0024797575959495.\n",
      "Training on epoch 37 minibatch 1201/5000 completed\n",
      " bpr_loss on current minibatch is 0.693794, and regularization loss is 0.000647.\n",
      " Top K precision = 0.005000000000000001, recall = 0.001975089968511021.\n",
      "Training on epoch 37 minibatch 1301/5000 completed\n",
      " bpr_loss on current minibatch is 0.69379, and regularization loss is 0.000643.\n",
      " Top K precision = 0.013333333333333332, recall = 0.005003699609347973.\n",
      "Training on epoch 37 minibatch 1401/5000 completed\n",
      " bpr_loss on current minibatch is 0.693868, and regularization loss is 0.000721.\n",
      " Top K precision = 0.016666666666666666, recall = 0.0075920786850781855.\n",
      "Training on epoch 37 minibatch 1501/5000 completed\n",
      " bpr_loss on current minibatch is 0.693657, and regularization loss is 0.00051.\n",
      " Top K precision = 0.010344827586206896, recall = 0.0049062614969177815.\n",
      "Training on epoch 37 minibatch 1601/5000 completed\n",
      " bpr_loss on current minibatch is 0.693782, and regularization loss is 0.000634.\n",
      " Top K precision = 0.014999999999999998, recall = 0.008870701724803892.\n",
      "Training on epoch 37 minibatch 1701/5000 completed\n",
      " bpr_loss on current minibatch is 0.693696, and regularization loss is 0.000549.\n",
      " Top K precision = 0.014999999999999998, recall = 0.0066608311173528565.\n",
      "Training on epoch 37 minibatch 1801/5000 completed\n",
      " bpr_loss on current minibatch is 0.693884, and regularization loss is 0.000737.\n",
      " Top K precision = 0.011864406779661016, recall = 0.004027182408811714.\n",
      "Training on epoch 37 minibatch 1901/5000 completed\n",
      " bpr_loss on current minibatch is 0.693864, and regularization loss is 0.000717.\n",
      " Top K precision = 0.01, recall = 0.0035775349847357958.\n",
      "Training on epoch 37 minibatch 2001/5000 completed\n",
      " bpr_loss on current minibatch is 0.693856, and regularization loss is 0.000709.\n",
      " Top K precision = 0.010169491525423728, recall = 0.007245304882669428.\n",
      "Training on epoch 37 minibatch 2101/5000 completed\n",
      " bpr_loss on current minibatch is 0.693797, and regularization loss is 0.00065.\n",
      " Top K precision = 0.020000000000000004, recall = 0.00847724108250424.\n",
      "Training on epoch 37 minibatch 2201/5000 completed\n",
      " bpr_loss on current minibatch is 0.693779, and regularization loss is 0.000632.\n",
      " Top K precision = 0.014999999999999998, recall = 0.007042963534191604.\n",
      "Training on epoch 37 minibatch 2301/5000 completed\n",
      " bpr_loss on current minibatch is 0.693773, and regularization loss is 0.000625.\n",
      " Top K precision = 0.006666666666666667, recall = 0.0022752639517345397.\n",
      "Training on epoch 37 minibatch 2401/5000 completed\n",
      " bpr_loss on current minibatch is 0.693688, and regularization loss is 0.00054.\n",
      " Top K precision = 0.018965517241379307, recall = 0.007310095373372785.\n",
      "Training on epoch 37 minibatch 2501/5000 completed\n",
      " bpr_loss on current minibatch is 0.693767, and regularization loss is 0.00062.\n",
      " Top K precision = 0.011864406779661016, recall = 0.005310137947239281.\n",
      "Training on epoch 37 minibatch 2601/5000 completed\n",
      " bpr_loss on current minibatch is 0.693963, and regularization loss is 0.000816.\n",
      " Top K precision = 0.013333333333333332, recall = 0.006953872782517285.\n",
      "Training on epoch 37 minibatch 2701/5000 completed\n",
      " bpr_loss on current minibatch is 0.693771, and regularization loss is 0.000624.\n",
      " Top K precision = 0.011666666666666665, recall = 0.00803709362532892.\n",
      "Training on epoch 37 minibatch 2801/5000 completed\n",
      " bpr_loss on current minibatch is 0.693741, and regularization loss is 0.000594.\n",
      " Top K precision = 0.018644067796610167, recall = 0.010771823082260193.\n",
      "Training on epoch 37 minibatch 2901/5000 completed\n",
      " bpr_loss on current minibatch is 0.693784, and regularization loss is 0.000637.\n",
      " Top K precision = 0.011666666666666665, recall = 0.004991853753481661.\n",
      "Training on epoch 37 minibatch 3001/5000 completed\n",
      " bpr_loss on current minibatch is 0.693921, and regularization loss is 0.000774.\n",
      " Top K precision = 0.010344827586206896, recall = 0.003797718068156379.\n",
      "Training on epoch 37 minibatch 3101/5000 completed\n",
      " bpr_loss on current minibatch is 0.693807, and regularization loss is 0.000659.\n",
      " Top K precision = 0.006896551724137932, recall = 0.0038877620013522646.\n",
      "Training on epoch 37 minibatch 3201/5000 completed\n",
      " bpr_loss on current minibatch is 0.693743, and regularization loss is 0.000596.\n",
      " Top K precision = 0.013559322033898305, recall = 0.005938340171527705.\n",
      "Training on epoch 37 minibatch 3301/5000 completed\n",
      " bpr_loss on current minibatch is 0.69366, and regularization loss is 0.000513.\n",
      " Top K precision = 0.011864406779661016, recall = 0.004102818085868933.\n",
      "Training on epoch 37 minibatch 3401/5000 completed\n",
      " bpr_loss on current minibatch is 0.693705, and regularization loss is 0.000558.\n",
      " Top K precision = 0.010169491525423728, recall = 0.0046732306919487305.\n",
      "Training on epoch 37 minibatch 3501/5000 completed\n",
      " bpr_loss on current minibatch is 0.693811, and regularization loss is 0.000663.\n",
      " Top K precision = 0.01, recall = 0.005242877492877493.\n",
      "Training on epoch 37 minibatch 3601/5000 completed\n",
      " bpr_loss on current minibatch is 0.69386, and regularization loss is 0.000713.\n",
      " Top K precision = 0.00847457627118644, recall = 0.003675914140173536.\n",
      "Training on epoch 37 minibatch 3701/5000 completed\n",
      " bpr_loss on current minibatch is 0.693977, and regularization loss is 0.00083.\n",
      " Top K precision = 0.02, recall = 0.009164545258779003.\n",
      "Training on epoch 37 minibatch 3801/5000 completed\n",
      " bpr_loss on current minibatch is 0.693821, and regularization loss is 0.000673.\n",
      " Top K precision = 0.021666666666666667, recall = 0.008501319491386572.\n",
      "Training on epoch 37 minibatch 3901/5000 completed\n",
      " bpr_loss on current minibatch is 0.693724, and regularization loss is 0.000577.\n",
      " Top K precision = 0.013333333333333332, recall = 0.00729134130296921.\n",
      "Training on epoch 37 minibatch 4001/5000 completed\n",
      " bpr_loss on current minibatch is 0.693834, and regularization loss is 0.000687.\n",
      " Top K precision = 0.016666666666666666, recall = 0.00892925157417911.\n",
      "Training on epoch 37 minibatch 4101/5000 completed\n",
      " bpr_loss on current minibatch is 0.693907, and regularization loss is 0.00076.\n",
      " Top K precision = 0.010344827586206896, recall = 0.005880549431672852.\n",
      "Training on epoch 37 minibatch 4201/5000 completed\n",
      " bpr_loss on current minibatch is 0.69384, and regularization loss is 0.000693.\n",
      " Top K precision = 0.006779661016949153, recall = 0.002841979113165554.\n",
      "Training on epoch 37 minibatch 4301/5000 completed\n",
      " bpr_loss on current minibatch is 0.693941, and regularization loss is 0.000794.\n",
      " Top K precision = 0.01, recall = 0.006093541020011608.\n",
      "Training on epoch 37 minibatch 4401/5000 completed\n",
      " bpr_loss on current minibatch is 0.693691, and regularization loss is 0.000544.\n",
      " Top K precision = 0.020338983050847456, recall = 0.012075613177176907.\n",
      "Training on epoch 37 minibatch 4501/5000 completed\n",
      " bpr_loss on current minibatch is 0.693735, and regularization loss is 0.000588.\n",
      " Top K precision = 0.01, recall = 0.004008511617207269.\n",
      "Training on epoch 37 minibatch 4601/5000 completed\n",
      " bpr_loss on current minibatch is 0.693772, and regularization loss is 0.000625.\n",
      " Top K precision = 0.01, recall = 0.003428023665437853.\n",
      "Training on epoch 37 minibatch 4701/5000 completed\n",
      " bpr_loss on current minibatch is 0.693746, and regularization loss is 0.000598.\n",
      " Top K precision = 0.008333333333333333, recall = 0.0046665752548105495.\n",
      "Training on epoch 37 minibatch 4801/5000 completed\n",
      " bpr_loss on current minibatch is 0.69379, and regularization loss is 0.000643.\n",
      " Top K precision = 0.006666666666666667, recall = 0.002980895915678524.\n",
      "Training on epoch 37 minibatch 4901/5000 completed\n",
      " bpr_loss on current minibatch is 0.693918, and regularization loss is 0.000771.\n",
      " Top K precision = 0.011666666666666665, recall = 0.00497171039838139.\n",
      "\n",
      "Training on 37 epoch completed.\n",
      " Average bpr_loss on train set is 0.011563 for the current epoch.\n",
      " Training top K precision = 0.013933333333333422, recall = 0.006542615015607056.\n",
      " Average bpr_loss on the validation set is 2e-06, and regularization loss is 0.0.\n",
      " Validation top K precision = 0.015133333333333446, recall = 0.006392949207900928.\n",
      "\n",
      "Training on the 38 epoch\n",
      "Training on epoch 38 minibatch 1/5000 completed\n",
      " bpr_loss on current minibatch is 0.693817, and regularization loss is 0.00067.\n",
      " Top K precision = 0.008333333333333333, recall = 0.0025768608222969274.\n",
      "Training on epoch 38 minibatch 101/5000 completed\n",
      " bpr_loss on current minibatch is 0.693721, and regularization loss is 0.000574.\n",
      " Top K precision = 0.008333333333333333, recall = 0.0035475297060662916.\n",
      "Training on epoch 38 minibatch 201/5000 completed\n",
      " bpr_loss on current minibatch is 0.693874, and regularization loss is 0.000727.\n",
      " Top K precision = 0.020338983050847456, recall = 0.0084539000742851.\n",
      "Training on epoch 38 minibatch 301/5000 completed\n",
      " bpr_loss on current minibatch is 0.693816, and regularization loss is 0.000669.\n",
      " Top K precision = 0.006779661016949153, recall = 0.0025416280135991966.\n",
      "Training on epoch 38 minibatch 401/5000 completed\n",
      " bpr_loss on current minibatch is 0.693955, and regularization loss is 0.000808.\n",
      " Top K precision = 0.016666666666666666, recall = 0.007074370823067583.\n",
      "Training on epoch 38 minibatch 501/5000 completed\n",
      " bpr_loss on current minibatch is 0.693725, and regularization loss is 0.000578.\n",
      " Top K precision = 0.014999999999999998, recall = 0.007771758198228786.\n",
      "Training on epoch 38 minibatch 601/5000 completed\n",
      " bpr_loss on current minibatch is 0.693739, and regularization loss is 0.000592.\n",
      " Top K precision = 0.010169491525423728, recall = 0.0038382207873733296.\n",
      "Training on epoch 38 minibatch 701/5000 completed\n",
      " bpr_loss on current minibatch is 0.693781, and regularization loss is 0.000633.\n",
      " Top K precision = 0.011864406779661016, recall = 0.0030742555770918952.\n",
      "Training on epoch 38 minibatch 801/5000 completed\n",
      " bpr_loss on current minibatch is 0.693874, and regularization loss is 0.000727.\n",
      " Top K precision = 0.011666666666666667, recall = 0.003694317120787709.\n",
      "Training on epoch 38 minibatch 901/5000 completed\n",
      " bpr_loss on current minibatch is 0.693774, and regularization loss is 0.000627.\n",
      " Top K precision = 0.015254237288135592, recall = 0.005621618884524675.\n",
      "Training on epoch 38 minibatch 1001/5000 completed\n",
      " bpr_loss on current minibatch is 0.69394, and regularization loss is 0.000793.\n",
      " Top K precision = 0.015254237288135592, recall = 0.006159008749624.\n",
      "Training on epoch 38 minibatch 1101/5000 completed\n",
      " bpr_loss on current minibatch is 0.693833, and regularization loss is 0.000685.\n",
      " Top K precision = 0.01, recall = 0.0038578264544615348.\n",
      "Training on epoch 38 minibatch 1201/5000 completed\n",
      " bpr_loss on current minibatch is 0.693885, and regularization loss is 0.000738.\n",
      " Top K precision = 0.010169491525423728, recall = 0.0057770280992902.\n",
      "Training on epoch 38 minibatch 1301/5000 completed\n",
      " bpr_loss on current minibatch is 0.693687, and regularization loss is 0.00054.\n",
      " Top K precision = 0.006779661016949153, recall = 0.0033510579372992132.\n",
      "Training on epoch 38 minibatch 1401/5000 completed\n",
      " bpr_loss on current minibatch is 0.69393, and regularization loss is 0.000783.\n",
      " Top K precision = 0.013559322033898305, recall = 0.0056355476967647564.\n",
      "Training on epoch 38 minibatch 1501/5000 completed\n",
      " bpr_loss on current minibatch is 0.693823, and regularization loss is 0.000675.\n",
      " Top K precision = 0.01, recall = 0.0031232492997198876.\n",
      "Training on epoch 38 minibatch 1601/5000 completed\n",
      " bpr_loss on current minibatch is 0.693893, and regularization loss is 0.000746.\n",
      " Top K precision = 0.01, recall = 0.004653363205994785.\n",
      "Training on epoch 38 minibatch 1701/5000 completed\n",
      " bpr_loss on current minibatch is 0.693686, and regularization loss is 0.000539.\n",
      " Top K precision = 0.016666666666666666, recall = 0.007877839329809564.\n",
      "Training on epoch 38 minibatch 1801/5000 completed\n",
      " bpr_loss on current minibatch is 0.693877, and regularization loss is 0.00073.\n",
      " Top K precision = 0.020000000000000004, recall = 0.009111829528496195.\n",
      "Training on epoch 38 minibatch 1901/5000 completed\n",
      " bpr_loss on current minibatch is 0.693695, and regularization loss is 0.000548.\n",
      " Top K precision = 0.01, recall = 0.0036994242141300962.\n",
      "Training on epoch 38 minibatch 2001/5000 completed\n",
      " bpr_loss on current minibatch is 0.693709, and regularization loss is 0.000562.\n",
      " Top K precision = 0.006779661016949153, recall = 0.0031508039982616255.\n",
      "Training on epoch 38 minibatch 2101/5000 completed\n",
      " bpr_loss on current minibatch is 0.693705, and regularization loss is 0.000557.\n",
      " Top K precision = 0.006666666666666667, recall = 0.002911706349206349.\n",
      "Training on epoch 38 minibatch 2201/5000 completed\n",
      " bpr_loss on current minibatch is 0.693818, and regularization loss is 0.000671.\n",
      " Top K precision = 0.011666666666666665, recall = 0.0045568808023169075.\n",
      "Training on epoch 38 minibatch 2301/5000 completed\n",
      " bpr_loss on current minibatch is 0.693835, and regularization loss is 0.000687.\n",
      " Top K precision = 0.010169491525423728, recall = 0.0045338535651251715.\n",
      "Training on epoch 38 minibatch 2401/5000 completed\n",
      " bpr_loss on current minibatch is 0.69375, and regularization loss is 0.000603.\n",
      " Top K precision = 0.010169491525423728, recall = 0.003135098132184729.\n",
      "Training on epoch 38 minibatch 2501/5000 completed\n",
      " bpr_loss on current minibatch is 0.693786, and regularization loss is 0.000639.\n",
      " Top K precision = 0.02, recall = 0.0074256744029040055.\n",
      "Training on epoch 38 minibatch 2601/5000 completed\n",
      " bpr_loss on current minibatch is 0.693806, and regularization loss is 0.000658.\n",
      " Top K precision = 0.010169491525423728, recall = 0.005645894397009473.\n",
      "Training on epoch 38 minibatch 2701/5000 completed\n",
      " bpr_loss on current minibatch is 0.693898, and regularization loss is 0.000751.\n",
      " Top K precision = 0.02166666666666667, recall = 0.007057598735327689.\n",
      "Training on epoch 38 minibatch 2801/5000 completed\n",
      " bpr_loss on current minibatch is 0.693821, and regularization loss is 0.000674.\n",
      " Top K precision = 0.013333333333333334, recall = 0.004160112818606051.\n",
      "Training on epoch 38 minibatch 2901/5000 completed\n",
      " bpr_loss on current minibatch is 0.693961, and regularization loss is 0.000814.\n",
      " Top K precision = 0.008333333333333333, recall = 0.002811536416799575.\n",
      "Training on epoch 38 minibatch 3001/5000 completed\n",
      " bpr_loss on current minibatch is 0.693755, and regularization loss is 0.000608.\n",
      " Top K precision = 0.006666666666666667, recall = 0.002738534915005503.\n",
      "Training on epoch 38 minibatch 3101/5000 completed\n",
      " bpr_loss on current minibatch is 0.693875, and regularization loss is 0.000728.\n",
      " Top K precision = 0.005084745762711865, recall = 0.004573580844767286.\n",
      "Training on epoch 38 minibatch 3201/5000 completed\n",
      " bpr_loss on current minibatch is 0.693722, and regularization loss is 0.000575.\n",
      " Top K precision = 0.00847457627118644, recall = 0.004320122339747675.\n",
      "Training on epoch 38 minibatch 3301/5000 completed\n",
      " bpr_loss on current minibatch is 0.693888, and regularization loss is 0.000741.\n",
      " Top K precision = 0.00847457627118644, recall = 0.004475797272407442.\n",
      "Training on epoch 38 minibatch 3401/5000 completed\n",
      " bpr_loss on current minibatch is 0.693839, and regularization loss is 0.000691.\n",
      " Top K precision = 0.005084745762711865, recall = 0.002777095444744671.\n",
      "Training on epoch 38 minibatch 3501/5000 completed\n",
      " bpr_loss on current minibatch is 0.693939, and regularization loss is 0.000792.\n",
      " Top K precision = 0.013333333333333332, recall = 0.006365275501788659.\n",
      "Training on epoch 38 minibatch 3601/5000 completed\n",
      " bpr_loss on current minibatch is 0.693864, and regularization loss is 0.000717.\n",
      " Top K precision = 0.006779661016949153, recall = 0.0028041638211129738.\n",
      "Training on epoch 38 minibatch 3701/5000 completed\n",
      " bpr_loss on current minibatch is 0.693819, and regularization loss is 0.000672.\n",
      " Top K precision = 0.013333333333333332, recall = 0.006432467162883204.\n",
      "Training on epoch 38 minibatch 3801/5000 completed\n",
      " bpr_loss on current minibatch is 0.693734, and regularization loss is 0.000587.\n",
      " Top K precision = 0.005000000000000001, recall = 0.0014713064713064712.\n",
      "Training on epoch 38 minibatch 3901/5000 completed\n",
      " bpr_loss on current minibatch is 0.69379, and regularization loss is 0.000642.\n",
      " Top K precision = 0.020000000000000007, recall = 0.006707374715367044.\n",
      "Training on epoch 38 minibatch 4001/5000 completed\n",
      " bpr_loss on current minibatch is 0.693919, and regularization loss is 0.000772.\n",
      " Top K precision = 0.00847457627118644, recall = 0.004352645923585279.\n",
      "Training on epoch 38 minibatch 4101/5000 completed\n",
      " bpr_loss on current minibatch is 0.693857, and regularization loss is 0.000709.\n",
      " Top K precision = 0.016949152542372878, recall = 0.00792190907515665.\n",
      "Training on epoch 38 minibatch 4201/5000 completed\n",
      " bpr_loss on current minibatch is 0.693946, and regularization loss is 0.000799.\n",
      " Top K precision = 0.015254237288135594, recall = 0.007974969435207742.\n",
      "Training on epoch 38 minibatch 4301/5000 completed\n",
      " bpr_loss on current minibatch is 0.693767, and regularization loss is 0.00062.\n",
      " Top K precision = 0.01, recall = 0.004709600559734969.\n",
      "Training on epoch 38 minibatch 4401/5000 completed\n",
      " bpr_loss on current minibatch is 0.693686, and regularization loss is 0.000539.\n",
      " Top K precision = 0.021666666666666667, recall = 0.009833958744967454.\n",
      "Training on epoch 38 minibatch 4501/5000 completed\n",
      " bpr_loss on current minibatch is 0.693767, and regularization loss is 0.00062.\n",
      " Top K precision = 0.006779661016949153, recall = 0.0032989609260795703.\n",
      "Training on epoch 38 minibatch 4601/5000 completed\n",
      " bpr_loss on current minibatch is 0.693827, and regularization loss is 0.00068.\n",
      " Top K precision = 0.020338983050847456, recall = 0.008089204986998449.\n",
      "Training on epoch 38 minibatch 4701/5000 completed\n",
      " bpr_loss on current minibatch is 0.693809, and regularization loss is 0.000662.\n",
      " Top K precision = 0.0033333333333333335, recall = 0.0013888888888888887.\n",
      "Training on epoch 38 minibatch 4801/5000 completed\n",
      " bpr_loss on current minibatch is 0.69369, and regularization loss is 0.000543.\n",
      " Top K precision = 0.006666666666666667, recall = 0.0019530646105258508.\n",
      "Training on epoch 38 minibatch 4901/5000 completed\n",
      " bpr_loss on current minibatch is 0.693771, and regularization loss is 0.000624.\n",
      " Top K precision = 0.015254237288135592, recall = 0.006469706771496648.\n",
      "\n",
      "Training on 38 epoch completed.\n",
      " Average bpr_loss on train set is 0.011563 for the current epoch.\n",
      " Training top K precision = 0.016133333333333454, recall = 0.007135020170008411.\n",
      " Average bpr_loss on the validation set is 2e-06, and regularization loss is 0.0.\n",
      " Validation top K precision = 0.01566666666666678, recall = 0.006929841055696866.\n",
      "\n",
      "Training on the 39 epoch\n",
      "Training on epoch 39 minibatch 1/5000 completed\n",
      " bpr_loss on current minibatch is 0.693703, and regularization loss is 0.000555.\n",
      " Top K precision = 0.02542372881355933, recall = 0.0073882996365548705.\n",
      "Training on epoch 39 minibatch 101/5000 completed\n",
      " bpr_loss on current minibatch is 0.693795, and regularization loss is 0.000648.\n",
      " Top K precision = 0.016666666666666666, recall = 0.008126062305793548.\n",
      "Training on epoch 39 minibatch 201/5000 completed\n",
      " bpr_loss on current minibatch is 0.693733, and regularization loss is 0.000586.\n",
      " Top K precision = 0.010169491525423728, recall = 0.003560181114378986.\n",
      "Training on epoch 39 minibatch 301/5000 completed\n",
      " bpr_loss on current minibatch is 0.693639, and regularization loss is 0.000492.\n",
      " Top K precision = 0.015789473684210523, recall = 0.007935209520232325.\n",
      "Training on epoch 39 minibatch 401/5000 completed\n",
      " bpr_loss on current minibatch is 0.693768, and regularization loss is 0.000621.\n",
      " Top K precision = 0.011666666666666665, recall = 0.005921249976041248.\n",
      "Training on epoch 39 minibatch 501/5000 completed\n",
      " bpr_loss on current minibatch is 0.693858, and regularization loss is 0.000711.\n",
      " Top K precision = 0.006666666666666667, recall = 0.0019577691592388468.\n",
      "Training on epoch 39 minibatch 601/5000 completed\n",
      " bpr_loss on current minibatch is 0.693765, and regularization loss is 0.000618.\n",
      " Top K precision = 0.017241379310344827, recall = 0.008649942642982295.\n",
      "Training on epoch 39 minibatch 701/5000 completed\n",
      " bpr_loss on current minibatch is 0.693862, and regularization loss is 0.000715.\n",
      " Top K precision = 0.00847457627118644, recall = 0.005984143718309642.\n",
      "Training on epoch 39 minibatch 801/5000 completed\n",
      " bpr_loss on current minibatch is 0.693835, and regularization loss is 0.000688.\n",
      " Top K precision = 0.006666666666666667, recall = 0.0027818627450980397.\n",
      "Training on epoch 39 minibatch 901/5000 completed\n",
      " bpr_loss on current minibatch is 0.693712, and regularization loss is 0.000565.\n",
      " Top K precision = 0.006896551724137932, recall = 0.0025822115125174864.\n",
      "Training on epoch 39 minibatch 1001/5000 completed\n",
      " bpr_loss on current minibatch is 0.693831, and regularization loss is 0.000684.\n",
      " Top K precision = 0.01, recall = 0.004976501122334455.\n",
      "Training on epoch 39 minibatch 1101/5000 completed\n",
      " bpr_loss on current minibatch is 0.693822, and regularization loss is 0.000675.\n",
      " Top K precision = 0.011864406779661016, recall = 0.005868577469731455.\n",
      "Training on epoch 39 minibatch 1201/5000 completed\n",
      " bpr_loss on current minibatch is 0.693677, and regularization loss is 0.00053.\n",
      " Top K precision = 0.01206896551724138, recall = 0.005018787397744979.\n",
      "Training on epoch 39 minibatch 1301/5000 completed\n",
      " bpr_loss on current minibatch is 0.693923, and regularization loss is 0.000776.\n",
      " Top K precision = 0.021666666666666667, recall = 0.007784036153507198.\n",
      "Training on epoch 39 minibatch 1401/5000 completed\n",
      " bpr_loss on current minibatch is 0.693625, and regularization loss is 0.000478.\n",
      " Top K precision = 0.016666666666666666, recall = 0.006894464241662884.\n",
      "Training on epoch 39 minibatch 1501/5000 completed\n",
      " bpr_loss on current minibatch is 0.693922, and regularization loss is 0.000775.\n",
      " Top K precision = 0.01, recall = 0.003377896722857963.\n",
      "Training on epoch 39 minibatch 1601/5000 completed\n",
      " bpr_loss on current minibatch is 0.693714, and regularization loss is 0.000567.\n",
      " Top K precision = 0.014999999999999998, recall = 0.008985929573449764.\n",
      "Training on epoch 39 minibatch 1701/5000 completed\n",
      " bpr_loss on current minibatch is 0.69389, and regularization loss is 0.000743.\n",
      " Top K precision = 0.006896551724137932, recall = 0.003472979419381219.\n",
      "Training on epoch 39 minibatch 1801/5000 completed\n",
      " bpr_loss on current minibatch is 0.693623, and regularization loss is 0.000476.\n",
      " Top K precision = 0.011666666666666665, recall = 0.0038609373152383906.\n",
      "Training on epoch 39 minibatch 1901/5000 completed\n",
      " bpr_loss on current minibatch is 0.694032, and regularization loss is 0.000885.\n",
      " Top K precision = 0.016949152542372878, recall = 0.008097327629383635.\n",
      "Training on epoch 39 minibatch 2001/5000 completed\n",
      " bpr_loss on current minibatch is 0.693696, and regularization loss is 0.000549.\n",
      " Top K precision = 0.013333333333333332, recall = 0.007122023650192203.\n",
      "Training on epoch 39 minibatch 2101/5000 completed\n",
      " bpr_loss on current minibatch is 0.693796, and regularization loss is 0.000649.\n",
      " Top K precision = 0.005000000000000001, recall = 0.002560460372960373.\n",
      "Training on epoch 39 minibatch 2201/5000 completed\n",
      " bpr_loss on current minibatch is 0.693691, and regularization loss is 0.000544.\n",
      " Top K precision = 0.014999999999999998, recall = 0.004986933214435317.\n",
      "Training on epoch 39 minibatch 2301/5000 completed\n",
      " bpr_loss on current minibatch is 0.693698, and regularization loss is 0.00055.\n",
      " Top K precision = 0.0033333333333333335, recall = 0.001626984126984127.\n",
      "Training on epoch 39 minibatch 2401/5000 completed\n",
      " bpr_loss on current minibatch is 0.693757, and regularization loss is 0.00061.\n",
      " Top K precision = 0.014999999999999998, recall = 0.005612520282042926.\n",
      "Training on epoch 39 minibatch 2501/5000 completed\n",
      " bpr_loss on current minibatch is 0.693879, and regularization loss is 0.000732.\n",
      " Top K precision = 0.010344827586206896, recall = 0.00796014330497089.\n",
      "Training on epoch 39 minibatch 2601/5000 completed\n",
      " bpr_loss on current minibatch is 0.693751, and regularization loss is 0.000603.\n",
      " Top K precision = 0.005000000000000001, recall = 0.002560903149138443.\n",
      "Training on epoch 39 minibatch 2701/5000 completed\n",
      " bpr_loss on current minibatch is 0.693819, and regularization loss is 0.000672.\n",
      " Top K precision = 0.017241379310344827, recall = 0.006534191487017899.\n",
      "Training on epoch 39 minibatch 2801/5000 completed\n",
      " bpr_loss on current minibatch is 0.693839, and regularization loss is 0.000692.\n",
      " Top K precision = 0.006666666666666667, recall = 0.004553840767076061.\n",
      "Training on epoch 39 minibatch 2901/5000 completed\n",
      " bpr_loss on current minibatch is 0.693889, and regularization loss is 0.000742.\n",
      " Top K precision = 0.01206896551724138, recall = 0.004393675635265206.\n",
      "Training on epoch 39 minibatch 3001/5000 completed\n",
      " bpr_loss on current minibatch is 0.693895, and regularization loss is 0.000747.\n",
      " Top K precision = 0.00847457627118644, recall = 0.0030595910680656442.\n",
      "Training on epoch 39 minibatch 3101/5000 completed\n",
      " bpr_loss on current minibatch is 0.693711, and regularization loss is 0.000563.\n",
      " Top K precision = 0.011864406779661016, recall = 0.005345623672386804.\n",
      "Training on epoch 39 minibatch 3201/5000 completed\n",
      " bpr_loss on current minibatch is 0.693693, and regularization loss is 0.000546.\n",
      " Top K precision = 0.011864406779661016, recall = 0.0032155454239202997.\n",
      "Training on epoch 39 minibatch 3301/5000 completed\n",
      " bpr_loss on current minibatch is 0.693831, and regularization loss is 0.000684.\n",
      " Top K precision = 0.014999999999999998, recall = 0.005662857987026785.\n",
      "Training on epoch 39 minibatch 3401/5000 completed\n",
      " bpr_loss on current minibatch is 0.693949, and regularization loss is 0.000802.\n",
      " Top K precision = 0.006779661016949153, recall = 0.00262673517907815.\n",
      "Training on epoch 39 minibatch 3501/5000 completed\n",
      " bpr_loss on current minibatch is 0.693688, and regularization loss is 0.000541.\n",
      " Top K precision = 0.02, recall = 0.00691836223755209.\n",
      "Training on epoch 39 minibatch 3601/5000 completed\n",
      " bpr_loss on current minibatch is 0.693924, and regularization loss is 0.000777.\n",
      " Top K precision = 0.008333333333333333, recall = 0.0030373677248677253.\n",
      "Training on epoch 39 minibatch 3701/5000 completed\n",
      " bpr_loss on current minibatch is 0.693931, and regularization loss is 0.000784.\n",
      " Top K precision = 0.0033333333333333335, recall = 0.0007121212121212121.\n",
      "Training on epoch 39 minibatch 3801/5000 completed\n",
      " bpr_loss on current minibatch is 0.693813, and regularization loss is 0.000665.\n",
      " Top K precision = 0.0016666666666666668, recall = 0.0010416666666666667.\n",
      "Training on epoch 39 minibatch 3901/5000 completed\n",
      " bpr_loss on current minibatch is 0.693626, and regularization loss is 0.000479.\n",
      " Top K precision = 0.020338983050847456, recall = 0.00930248954662556.\n",
      "Training on epoch 39 minibatch 4001/5000 completed\n",
      " bpr_loss on current minibatch is 0.694136, and regularization loss is 0.000989.\n",
      " Top K precision = 0.011666666666666665, recall = 0.005389843131778616.\n",
      "Training on epoch 39 minibatch 4101/5000 completed\n",
      " bpr_loss on current minibatch is 0.693634, and regularization loss is 0.000487.\n",
      " Top K precision = 0.011666666666666665, recall = 0.003806421376935797.\n",
      "Training on epoch 39 minibatch 4201/5000 completed\n",
      " bpr_loss on current minibatch is 0.693759, and regularization loss is 0.000612.\n",
      " Top K precision = 0.01, recall = 0.004436392914653784.\n",
      "Training on epoch 39 minibatch 4301/5000 completed\n",
      " bpr_loss on current minibatch is 0.693664, and regularization loss is 0.000517.\n",
      " Top K precision = 0.016949152542372878, recall = 0.008164167569104932.\n",
      "Training on epoch 39 minibatch 4401/5000 completed\n",
      " bpr_loss on current minibatch is 0.693851, and regularization loss is 0.000704.\n",
      " Top K precision = 0.02, recall = 0.011116020177805075.\n",
      "Training on epoch 39 minibatch 4501/5000 completed\n",
      " bpr_loss on current minibatch is 0.693774, and regularization loss is 0.000627.\n",
      " Top K precision = 0.010169491525423728, recall = 0.0035849660475782102.\n",
      "Training on epoch 39 minibatch 4601/5000 completed\n",
      " bpr_loss on current minibatch is 0.693791, and regularization loss is 0.000643.\n",
      " Top K precision = 0.02, recall = 0.00710813371634156.\n",
      "Training on epoch 39 minibatch 4701/5000 completed\n",
      " bpr_loss on current minibatch is 0.693796, and regularization loss is 0.000649.\n",
      " Top K precision = 0.01, recall = 0.004598457098457099.\n",
      "Training on epoch 39 minibatch 4801/5000 completed\n",
      " bpr_loss on current minibatch is 0.693784, and regularization loss is 0.000637.\n",
      " Top K precision = 0.006779661016949153, recall = 0.0020195086488142802.\n",
      "Training on epoch 39 minibatch 4901/5000 completed\n",
      " bpr_loss on current minibatch is 0.693833, and regularization loss is 0.000686.\n",
      " Top K precision = 0.008333333333333333, recall = 0.002927350427350427.\n",
      "\n",
      "Training on 39 epoch completed.\n",
      " Average bpr_loss on train set is 0.011563 for the current epoch.\n",
      " Training top K precision = 0.014233333333333435, recall = 0.006343564391003755.\n",
      " Average bpr_loss on the validation set is 2e-06, and regularization loss is 0.0.\n",
      " Validation top K precision = 0.014166666666666768, recall = 0.0063542249245803015.\n",
      "\n",
      "Training on the 40 epoch\n",
      "Training on epoch 40 minibatch 1/5000 completed\n",
      " bpr_loss on current minibatch is 0.693628, and regularization loss is 0.000481.\n",
      " Top K precision = 0.014999999999999998, recall = 0.007175842968379337.\n",
      "Training on epoch 40 minibatch 101/5000 completed\n",
      " bpr_loss on current minibatch is 0.693848, and regularization loss is 0.000701.\n",
      " Top K precision = 0.013333333333333332, recall = 0.006753045429516017.\n",
      "Training on epoch 40 minibatch 201/5000 completed\n",
      " bpr_loss on current minibatch is 0.693666, and regularization loss is 0.000519.\n",
      " Top K precision = 0.013333333333333334, recall = 0.005506081220366935.\n",
      "Training on epoch 40 minibatch 301/5000 completed\n",
      " bpr_loss on current minibatch is 0.693767, and regularization loss is 0.00062.\n",
      " Top K precision = 0.008771929824561403, recall = 0.0033974950872457796.\n",
      "Training on epoch 40 minibatch 401/5000 completed\n",
      " bpr_loss on current minibatch is 0.693785, and regularization loss is 0.000638.\n",
      " Top K precision = 0.005000000000000001, recall = 0.0019845034788108793.\n",
      "Training on epoch 40 minibatch 501/5000 completed\n",
      " bpr_loss on current minibatch is 0.693721, and regularization loss is 0.000574.\n",
      " Top K precision = 0.006896551724137932, recall = 0.007198331336262371.\n",
      "Training on epoch 40 minibatch 601/5000 completed\n",
      " bpr_loss on current minibatch is 0.693825, and regularization loss is 0.000677.\n",
      " Top K precision = 0.011666666666666665, recall = 0.004249939874939875.\n",
      "Training on epoch 40 minibatch 701/5000 completed\n",
      " bpr_loss on current minibatch is 0.693792, and regularization loss is 0.000645.\n",
      " Top K precision = 0.014999999999999998, recall = 0.004751261631484009.\n",
      "Training on epoch 40 minibatch 801/5000 completed\n",
      " bpr_loss on current minibatch is 0.693811, and regularization loss is 0.000664.\n",
      " Top K precision = 0.013559322033898305, recall = 0.006133327213108463.\n",
      "Training on epoch 40 minibatch 901/5000 completed\n",
      " bpr_loss on current minibatch is 0.6938, and regularization loss is 0.000653.\n",
      " Top K precision = 0.013333333333333332, recall = 0.004317385123836737.\n",
      "Training on epoch 40 minibatch 1001/5000 completed\n",
      " bpr_loss on current minibatch is 0.694132, and regularization loss is 0.000985.\n",
      " Top K precision = 0.006896551724137932, recall = 0.001866447728516694.\n",
      "Training on epoch 40 minibatch 1101/5000 completed\n",
      " bpr_loss on current minibatch is 0.693756, and regularization loss is 0.000609.\n",
      " Top K precision = 0.013333333333333332, recall = 0.005244469215608646.\n",
      "Training on epoch 40 minibatch 1201/5000 completed\n",
      " bpr_loss on current minibatch is 0.693656, and regularization loss is 0.000509.\n",
      " Top K precision = 0.013559322033898305, recall = 0.004430509500643925.\n",
      "Training on epoch 40 minibatch 1301/5000 completed\n",
      " bpr_loss on current minibatch is 0.6938, and regularization loss is 0.000653.\n",
      " Top K precision = 0.020000000000000004, recall = 0.007915920660386096.\n",
      "Training on epoch 40 minibatch 1401/5000 completed\n",
      " bpr_loss on current minibatch is 0.693676, and regularization loss is 0.000528.\n",
      " Top K precision = 0.018644067796610167, recall = 0.010581948562150572.\n",
      "Training on epoch 40 minibatch 1501/5000 completed\n",
      " bpr_loss on current minibatch is 0.693827, and regularization loss is 0.00068.\n",
      " Top K precision = 0.017241379310344827, recall = 0.007632918226923962.\n",
      "Training on epoch 40 minibatch 1601/5000 completed\n",
      " bpr_loss on current minibatch is 0.693668, and regularization loss is 0.000521.\n",
      " Top K precision = 0.013333333333333332, recall = 0.005510477772941742.\n",
      "Training on epoch 40 minibatch 1701/5000 completed\n",
      " bpr_loss on current minibatch is 0.693704, and regularization loss is 0.000557.\n",
      " Top K precision = 0.01, recall = 0.005359364719996903.\n",
      "Training on epoch 40 minibatch 1801/5000 completed\n",
      " bpr_loss on current minibatch is 0.693842, and regularization loss is 0.000695.\n",
      " Top K precision = 0.006896551724137932, recall = 0.0032166567578279823.\n",
      "Training on epoch 40 minibatch 1901/5000 completed\n",
      " bpr_loss on current minibatch is 0.693808, and regularization loss is 0.000661.\n",
      " Top K precision = 0.016666666666666666, recall = 0.007673363537334126.\n",
      "Training on epoch 40 minibatch 2001/5000 completed\n",
      " bpr_loss on current minibatch is 0.693793, and regularization loss is 0.000646.\n",
      " Top K precision = 0.011666666666666665, recall = 0.005013919650547557.\n",
      "Training on epoch 40 minibatch 2101/5000 completed\n",
      " bpr_loss on current minibatch is 0.693847, and regularization loss is 0.0007.\n",
      " Top K precision = 0.0033333333333333335, recall = 0.0015873015873015873.\n",
      "Training on epoch 40 minibatch 2201/5000 completed\n",
      " bpr_loss on current minibatch is 0.693782, and regularization loss is 0.000635.\n",
      " Top K precision = 0.013333333333333332, recall = 0.005780632119963906.\n",
      "Training on epoch 40 minibatch 2301/5000 completed\n",
      " bpr_loss on current minibatch is 0.693703, and regularization loss is 0.000556.\n",
      " Top K precision = 0.011666666666666665, recall = 0.003987912382839919.\n",
      "Training on epoch 40 minibatch 2401/5000 completed\n",
      " bpr_loss on current minibatch is 0.693707, and regularization loss is 0.00056.\n",
      " Top K precision = 0.006896551724137932, recall = 0.0031092120663188784.\n",
      "Training on epoch 40 minibatch 2501/5000 completed\n",
      " bpr_loss on current minibatch is 0.693715, and regularization loss is 0.000568.\n",
      " Top K precision = 0.010169491525423728, recall = 0.004318205335154488.\n",
      "Training on epoch 40 minibatch 2601/5000 completed\n",
      " bpr_loss on current minibatch is 0.693762, and regularization loss is 0.000614.\n",
      " Top K precision = 0.021666666666666667, recall = 0.010621791362282076.\n",
      "Training on epoch 40 minibatch 2701/5000 completed\n",
      " bpr_loss on current minibatch is 0.693887, and regularization loss is 0.00074.\n",
      " Top K precision = 0.008333333333333333, recall = 0.0032957742740351435.\n",
      "Training on epoch 40 minibatch 2801/5000 completed\n",
      " bpr_loss on current minibatch is 0.693664, and regularization loss is 0.000517.\n",
      " Top K precision = 0.005084745762711865, recall = 0.001880721471947793.\n",
      "Training on epoch 40 minibatch 2901/5000 completed\n",
      " bpr_loss on current minibatch is 0.69373, and regularization loss is 0.000583.\n",
      " Top K precision = 0.011864406779661016, recall = 0.005221507892114494.\n",
      "Training on epoch 40 minibatch 3001/5000 completed\n",
      " bpr_loss on current minibatch is 0.693823, and regularization loss is 0.000675.\n",
      " Top K precision = 0.01, recall = 0.004146723229715032.\n",
      "Training on epoch 40 minibatch 3101/5000 completed\n",
      " bpr_loss on current minibatch is 0.69371, and regularization loss is 0.000563.\n",
      " Top K precision = 0.010169491525423728, recall = 0.0038567333229717043.\n",
      "Training on epoch 40 minibatch 3201/5000 completed\n",
      " bpr_loss on current minibatch is 0.693847, and regularization loss is 0.0007.\n",
      " Top K precision = 0.00847457627118644, recall = 0.00363620916698526.\n",
      "Training on epoch 40 minibatch 3301/5000 completed\n",
      " bpr_loss on current minibatch is 0.693868, and regularization loss is 0.000721.\n",
      " Top K precision = 0.010169491525423728, recall = 0.0061333985891834095.\n",
      "Training on epoch 40 minibatch 3401/5000 completed\n",
      " bpr_loss on current minibatch is 0.693736, and regularization loss is 0.000589.\n",
      " Top K precision = 0.01833333333333333, recall = 0.007083138811079988.\n",
      "Training on epoch 40 minibatch 3501/5000 completed\n",
      " bpr_loss on current minibatch is 0.693766, and regularization loss is 0.000619.\n",
      " Top K precision = 0.008333333333333333, recall = 0.0038164641804151276.\n",
      "Training on epoch 40 minibatch 3601/5000 completed\n",
      " bpr_loss on current minibatch is 0.693835, and regularization loss is 0.000688.\n",
      " Top K precision = 0.00847457627118644, recall = 0.005187568640231247.\n",
      "Training on epoch 40 minibatch 3701/5000 completed\n",
      " bpr_loss on current minibatch is 0.693744, and regularization loss is 0.000597.\n",
      " Top K precision = 0.016666666666666666, recall = 0.007670776235242429.\n",
      "Training on epoch 40 minibatch 3801/5000 completed\n",
      " bpr_loss on current minibatch is 0.693885, and regularization loss is 0.000738.\n",
      " Top K precision = 0.011666666666666665, recall = 0.006515903261339367.\n",
      "Training on epoch 40 minibatch 3901/5000 completed\n",
      " bpr_loss on current minibatch is 0.693748, and regularization loss is 0.000601.\n",
      " Top K precision = 0.005000000000000001, recall = 0.0025608400608400613.\n",
      "Training on epoch 40 minibatch 4001/5000 completed\n",
      " bpr_loss on current minibatch is 0.693843, and regularization loss is 0.000696.\n",
      " Top K precision = 0.008333333333333333, recall = 0.003179129741565242.\n",
      "Training on epoch 40 minibatch 4101/5000 completed\n",
      " bpr_loss on current minibatch is 0.693806, and regularization loss is 0.000659.\n",
      " Top K precision = 0.021666666666666667, recall = 0.00711818870148594.\n",
      "Training on epoch 40 minibatch 4201/5000 completed\n",
      " bpr_loss on current minibatch is 0.693873, and regularization loss is 0.000726.\n",
      " Top K precision = 0.006666666666666667, recall = 0.0030416666666666665.\n",
      "Training on epoch 40 minibatch 4301/5000 completed\n",
      " bpr_loss on current minibatch is 0.693713, and regularization loss is 0.000566.\n",
      " Top K precision = 0.016949152542372878, recall = 0.008536691512763298.\n",
      "Training on epoch 40 minibatch 4401/5000 completed\n",
      " bpr_loss on current minibatch is 0.693716, and regularization loss is 0.000568.\n",
      " Top K precision = 0.013559322033898305, recall = 0.005194266548290859.\n",
      "Training on epoch 40 minibatch 4501/5000 completed\n",
      " bpr_loss on current minibatch is 0.693831, and regularization loss is 0.000684.\n",
      " Top K precision = 0.016666666666666666, recall = 0.006025363525363525.\n",
      "Training on epoch 40 minibatch 4601/5000 completed\n",
      " bpr_loss on current minibatch is 0.693814, and regularization loss is 0.000667.\n",
      " Top K precision = 0.015254237288135592, recall = 0.00533281915006307.\n",
      "Training on epoch 40 minibatch 4701/5000 completed\n",
      " bpr_loss on current minibatch is 0.693808, and regularization loss is 0.000661.\n",
      " Top K precision = 0.014999999999999998, recall = 0.006080162867797275.\n",
      "Training on epoch 40 minibatch 4801/5000 completed\n",
      " bpr_loss on current minibatch is 0.693811, and regularization loss is 0.000664.\n",
      " Top K precision = 0.013559322033898305, recall = 0.005643404220259466.\n",
      "Training on epoch 40 minibatch 4901/5000 completed\n",
      " bpr_loss on current minibatch is 0.693898, and regularization loss is 0.000751.\n",
      " Top K precision = 0.011666666666666665, recall = 0.004473362410826316.\n",
      "\n",
      "Training on 40 epoch completed.\n",
      " Average bpr_loss on train set is 0.011563 for the current epoch.\n",
      " Training top K precision = 0.013500000000000085, recall = 0.005890475316326009.\n",
      " Average bpr_loss on the validation set is 2e-06, and regularization loss is 0.0.\n",
      " Validation top K precision = 0.01436666666666677, recall = 0.006862373005055892.\n",
      "\n",
      "Training on the 41 epoch\n",
      "Training on epoch 41 minibatch 1/5000 completed\n",
      " bpr_loss on current minibatch is 0.69376, and regularization loss is 0.000613.\n",
      " Top K precision = 0.013559322033898305, recall = 0.005825664827463778.\n",
      "Training on epoch 41 minibatch 101/5000 completed\n",
      " bpr_loss on current minibatch is 0.693868, and regularization loss is 0.000721.\n",
      " Top K precision = 0.005084745762711865, recall = 0.0027162103433289874.\n",
      "Training on epoch 41 minibatch 201/5000 completed\n",
      " bpr_loss on current minibatch is 0.693794, and regularization loss is 0.000647.\n",
      " Top K precision = 0.016666666666666666, recall = 0.007613952083447174.\n",
      "Training on epoch 41 minibatch 301/5000 completed\n",
      " bpr_loss on current minibatch is 0.693874, and regularization loss is 0.000727.\n",
      " Top K precision = 0.006779661016949153, recall = 0.004193109893377512.\n",
      "Training on epoch 41 minibatch 401/5000 completed\n",
      " bpr_loss on current minibatch is 0.693622, and regularization loss is 0.000475.\n",
      " Top K precision = 0.014999999999999998, recall = 0.006691185999281525.\n",
      "Training on epoch 41 minibatch 501/5000 completed\n",
      " bpr_loss on current minibatch is 0.69379, and regularization loss is 0.000643.\n",
      " Top K precision = 0.013333333333333334, recall = 0.004930166116760319.\n",
      "Training on epoch 41 minibatch 601/5000 completed\n",
      " bpr_loss on current minibatch is 0.69379, and regularization loss is 0.000643.\n",
      " Top K precision = 0.016666666666666666, recall = 0.008708756245401662.\n",
      "Training on epoch 41 minibatch 701/5000 completed\n",
      " bpr_loss on current minibatch is 0.693861, and regularization loss is 0.000714.\n",
      " Top K precision = 0.013333333333333332, recall = 0.0068307199475898675.\n",
      "Training on epoch 41 minibatch 801/5000 completed\n",
      " bpr_loss on current minibatch is 0.693875, and regularization loss is 0.000728.\n",
      " Top K precision = 0.012727272727272726, recall = 0.0057757937056356025.\n",
      "Training on epoch 41 minibatch 901/5000 completed\n",
      " bpr_loss on current minibatch is 0.693781, and regularization loss is 0.000634.\n",
      " Top K precision = 0.01, recall = 0.005368047473310631.\n",
      "Training on epoch 41 minibatch 1001/5000 completed\n",
      " bpr_loss on current minibatch is 0.693858, and regularization loss is 0.00071.\n",
      " Top K precision = 0.010169491525423728, recall = 0.007874811538015475.\n",
      "Training on epoch 41 minibatch 1101/5000 completed\n",
      " bpr_loss on current minibatch is 0.693726, and regularization loss is 0.000579.\n",
      " Top K precision = 0.014285714285714285, recall = 0.005052777406765853.\n",
      "Training on epoch 41 minibatch 1201/5000 completed\n",
      " bpr_loss on current minibatch is 0.693796, and regularization loss is 0.000649.\n",
      " Top K precision = 0.011666666666666665, recall = 0.005291134972507522.\n",
      "Training on epoch 41 minibatch 1301/5000 completed\n",
      " bpr_loss on current minibatch is 0.693738, and regularization loss is 0.000591.\n",
      " Top K precision = 0.015254237288135592, recall = 0.005356811556633144.\n",
      "Training on epoch 41 minibatch 1401/5000 completed\n",
      " bpr_loss on current minibatch is 0.693793, and regularization loss is 0.000646.\n",
      " Top K precision = 0.016666666666666666, recall = 0.007366660174385131.\n",
      "Training on epoch 41 minibatch 1501/5000 completed\n",
      " bpr_loss on current minibatch is 0.693879, and regularization loss is 0.000732.\n",
      " Top K precision = 0.016666666666666666, recall = 0.005791607748129487.\n",
      "Training on epoch 41 minibatch 1601/5000 completed\n",
      " bpr_loss on current minibatch is 0.693706, and regularization loss is 0.000559.\n",
      " Top K precision = 0.005172413793103449, recall = 0.003900736035491026.\n",
      "Training on epoch 41 minibatch 1701/5000 completed\n",
      " bpr_loss on current minibatch is 0.693945, and regularization loss is 0.000798.\n",
      " Top K precision = 0.01833333333333333, recall = 0.007558165969858486.\n",
      "Training on epoch 41 minibatch 1801/5000 completed\n",
      " bpr_loss on current minibatch is 0.693644, and regularization loss is 0.000497.\n",
      " Top K precision = 0.00847457627118644, recall = 0.00500085908048068.\n",
      "Training on epoch 41 minibatch 1901/5000 completed\n",
      " bpr_loss on current minibatch is 0.694053, and regularization loss is 0.000906.\n",
      " Top K precision = 0.01833333333333333, recall = 0.006601805854661831.\n",
      "Training on epoch 41 minibatch 2001/5000 completed\n",
      " bpr_loss on current minibatch is 0.6941, and regularization loss is 0.000953.\n",
      " Top K precision = 0.00847457627118644, recall = 0.003362422939648709.\n",
      "Training on epoch 41 minibatch 2101/5000 completed\n",
      " bpr_loss on current minibatch is 0.693765, and regularization loss is 0.000618.\n",
      " Top K precision = 0.008333333333333333, recall = 0.0029143909514753505.\n",
      "Training on epoch 41 minibatch 2201/5000 completed\n",
      " bpr_loss on current minibatch is 0.693799, and regularization loss is 0.000652.\n",
      " Top K precision = 0.014999999999999998, recall = 0.007140849530839011.\n",
      "Training on epoch 41 minibatch 2301/5000 completed\n",
      " bpr_loss on current minibatch is 0.693796, and regularization loss is 0.000648.\n",
      " Top K precision = 0.00847457627118644, recall = 0.005641901699381434.\n",
      "Training on epoch 41 minibatch 2401/5000 completed\n",
      " bpr_loss on current minibatch is 0.693811, and regularization loss is 0.000664.\n",
      " Top K precision = 0.018644067796610167, recall = 0.008364499619216977.\n",
      "Training on epoch 41 minibatch 2501/5000 completed\n",
      " bpr_loss on current minibatch is 0.693782, and regularization loss is 0.000635.\n",
      " Top K precision = 0.008333333333333333, recall = 0.00463018077601411.\n",
      "Training on epoch 41 minibatch 2601/5000 completed\n",
      " bpr_loss on current minibatch is 0.693855, and regularization loss is 0.000708.\n",
      " Top K precision = 0.016666666666666666, recall = 0.007068785007381498.\n",
      "Training on epoch 41 minibatch 2701/5000 completed\n",
      " bpr_loss on current minibatch is 0.69373, and regularization loss is 0.000583.\n",
      " Top K precision = 0.00847457627118644, recall = 0.0022831633881650795.\n",
      "Training on epoch 41 minibatch 2801/5000 completed\n",
      " bpr_loss on current minibatch is 0.693792, and regularization loss is 0.000645.\n",
      " Top K precision = 0.010169491525423728, recall = 0.006019122120817035.\n",
      "Training on epoch 41 minibatch 2901/5000 completed\n",
      " bpr_loss on current minibatch is 0.693862, and regularization loss is 0.000715.\n",
      " Top K precision = 0.014999999999999998, recall = 0.006207749340741668.\n",
      "Training on epoch 41 minibatch 3001/5000 completed\n",
      " bpr_loss on current minibatch is 0.69388, and regularization loss is 0.000733.\n",
      " Top K precision = 0.011666666666666665, recall = 0.0067646086553649586.\n",
      "Training on epoch 41 minibatch 3101/5000 completed\n",
      " bpr_loss on current minibatch is 0.693876, and regularization loss is 0.000729.\n",
      " Top K precision = 0.006666666666666667, recall = 0.003710411367612179.\n",
      "Training on epoch 41 minibatch 3201/5000 completed\n",
      " bpr_loss on current minibatch is 0.693914, and regularization loss is 0.000767.\n",
      " Top K precision = 0.016666666666666666, recall = 0.009344218750208574.\n",
      "Training on epoch 41 minibatch 3301/5000 completed\n",
      " bpr_loss on current minibatch is 0.693883, and regularization loss is 0.000736.\n",
      " Top K precision = 0.0033898305084745766, recall = 0.0013983050847457628.\n",
      "Training on epoch 41 minibatch 3401/5000 completed\n",
      " bpr_loss on current minibatch is 0.693855, and regularization loss is 0.000708.\n",
      " Top K precision = 0.010169491525423728, recall = 0.003033753645565277.\n",
      "Training on epoch 41 minibatch 3501/5000 completed\n",
      " bpr_loss on current minibatch is 0.693859, and regularization loss is 0.000712.\n",
      " Top K precision = 0.003448275862068966, recall = 0.0011843740292016153.\n",
      "Training on epoch 41 minibatch 3601/5000 completed\n",
      " bpr_loss on current minibatch is 0.693804, and regularization loss is 0.000656.\n",
      " Top K precision = 0.0033333333333333335, recall = 0.0015046296296296296.\n",
      "Training on epoch 41 minibatch 3701/5000 completed\n",
      " bpr_loss on current minibatch is 0.693823, and regularization loss is 0.000676.\n",
      " Top K precision = 0.013333333333333332, recall = 0.005703117281886721.\n",
      "Training on epoch 41 minibatch 3801/5000 completed\n",
      " bpr_loss on current minibatch is 0.693726, and regularization loss is 0.000578.\n",
      " Top K precision = 0.02, recall = 0.010289389020291565.\n",
      "Training on epoch 41 minibatch 3901/5000 completed\n",
      " bpr_loss on current minibatch is 0.69369, and regularization loss is 0.000543.\n",
      " Top K precision = 0.02, recall = 0.008263871536130672.\n",
      "Training on epoch 41 minibatch 4001/5000 completed\n",
      " bpr_loss on current minibatch is 0.693726, and regularization loss is 0.000579.\n",
      " Top K precision = 0.00847457627118644, recall = 0.0030790615536378245.\n",
      "Training on epoch 41 minibatch 4101/5000 completed\n",
      " bpr_loss on current minibatch is 0.693774, and regularization loss is 0.000627.\n",
      " Top K precision = 0.01379310344827586, recall = 0.0052988779616135765.\n",
      "Training on epoch 41 minibatch 4201/5000 completed\n",
      " bpr_loss on current minibatch is 0.693905, and regularization loss is 0.000758.\n",
      " Top K precision = 0.013333333333333332, recall = 0.005521815811670884.\n",
      "Training on epoch 41 minibatch 4301/5000 completed\n",
      " bpr_loss on current minibatch is 0.693804, and regularization loss is 0.000657.\n",
      " Top K precision = 0.015254237288135592, recall = 0.005161711511412408.\n",
      "Training on epoch 41 minibatch 4401/5000 completed\n",
      " bpr_loss on current minibatch is 0.693591, and regularization loss is 0.000444.\n",
      " Top K precision = 0.01206896551724138, recall = 0.006011532327321802.\n",
      "Training on epoch 41 minibatch 4501/5000 completed\n",
      " bpr_loss on current minibatch is 0.693717, and regularization loss is 0.00057.\n",
      " Top K precision = 0.011666666666666665, recall = 0.004586292119186856.\n",
      "Training on epoch 41 minibatch 4601/5000 completed\n",
      " bpr_loss on current minibatch is 0.693814, and regularization loss is 0.000667.\n",
      " Top K precision = 0.008333333333333333, recall = 0.0035712464300285598.\n",
      "Training on epoch 41 minibatch 4701/5000 completed\n",
      " bpr_loss on current minibatch is 0.693651, and regularization loss is 0.000504.\n",
      " Top K precision = 0.013559322033898305, recall = 0.006742217275021038.\n",
      "Training on epoch 41 minibatch 4801/5000 completed\n",
      " bpr_loss on current minibatch is 0.693747, and regularization loss is 0.0006.\n",
      " Top K precision = 0.005000000000000001, recall = 0.0015277777777777779.\n",
      "Training on epoch 41 minibatch 4901/5000 completed\n",
      " bpr_loss on current minibatch is 0.693931, and regularization loss is 0.000784.\n",
      " Top K precision = 0.010169491525423728, recall = 0.005157987359209779.\n",
      "\n",
      "Training on 41 epoch completed.\n",
      " Average bpr_loss on train set is 0.011563 for the current epoch.\n",
      " Training top K precision = 0.01580000000000012, recall = 0.006875596952612679.\n",
      " Average bpr_loss on the validation set is 2e-06, and regularization loss is 0.0.\n",
      " Validation top K precision = 0.014233333333333435, recall = 0.006730868659529294.\n",
      "\n",
      "Training on the 42 epoch\n",
      "Training on epoch 42 minibatch 1/5000 completed\n",
      " bpr_loss on current minibatch is 0.693786, and regularization loss is 0.000639.\n",
      " Top K precision = 0.016666666666666666, recall = 0.007505670199168651.\n",
      "Training on epoch 42 minibatch 101/5000 completed\n",
      " bpr_loss on current minibatch is 0.693678, and regularization loss is 0.000531.\n",
      " Top K precision = 0.013333333333333332, recall = 0.0063752372560089195.\n",
      "Training on epoch 42 minibatch 201/5000 completed\n",
      " bpr_loss on current minibatch is 0.693866, and regularization loss is 0.000718.\n",
      " Top K precision = 0.006779661016949153, recall = 0.001859508639169656.\n",
      "Training on epoch 42 minibatch 301/5000 completed\n",
      " bpr_loss on current minibatch is 0.693819, and regularization loss is 0.000672.\n",
      " Top K precision = 0.01, recall = 0.0032067165342060154.\n",
      "Training on epoch 42 minibatch 401/5000 completed\n",
      " bpr_loss on current minibatch is 0.693717, and regularization loss is 0.00057.\n",
      " Top K precision = 0.014999999999999998, recall = 0.008577679129149718.\n",
      "Training on epoch 42 minibatch 501/5000 completed\n",
      " bpr_loss on current minibatch is 0.693891, and regularization loss is 0.000744.\n",
      " Top K precision = 0.013333333333333332, recall = 0.005332609474766337.\n",
      "Training on epoch 42 minibatch 601/5000 completed\n",
      " bpr_loss on current minibatch is 0.693795, and regularization loss is 0.000648.\n",
      " Top K precision = 0.02, recall = 0.009926150786718472.\n",
      "Training on epoch 42 minibatch 701/5000 completed\n",
      " bpr_loss on current minibatch is 0.693883, and regularization loss is 0.000736.\n",
      " Top K precision = 0.01, recall = 0.004891219891219891.\n",
      "Training on epoch 42 minibatch 801/5000 completed\n",
      " bpr_loss on current minibatch is 0.693828, and regularization loss is 0.000681.\n",
      " Top K precision = 0.011666666666666665, recall = 0.005098233737939621.\n",
      "Training on epoch 42 minibatch 901/5000 completed\n",
      " bpr_loss on current minibatch is 0.69383, and regularization loss is 0.000683.\n",
      " Top K precision = 0.005084745762711865, recall = 0.001128124746820897.\n",
      "Training on epoch 42 minibatch 1001/5000 completed\n",
      " bpr_loss on current minibatch is 0.693691, and regularization loss is 0.000544.\n",
      " Top K precision = 0.00847457627118644, recall = 0.0040277519091078415.\n",
      "Training on epoch 42 minibatch 1101/5000 completed\n",
      " bpr_loss on current minibatch is 0.693738, and regularization loss is 0.000591.\n",
      " Top K precision = 0.01, recall = 0.0037629403560900023.\n",
      "Training on epoch 42 minibatch 1201/5000 completed\n",
      " bpr_loss on current minibatch is 0.693784, and regularization loss is 0.000637.\n",
      " Top K precision = 0.008333333333333333, recall = 0.0019686663347920955.\n",
      "Training on epoch 42 minibatch 1301/5000 completed\n",
      " bpr_loss on current minibatch is 0.693879, and regularization loss is 0.000732.\n",
      " Top K precision = 0.00847457627118644, recall = 0.0061633281972265025.\n",
      "Training on epoch 42 minibatch 1401/5000 completed\n",
      " bpr_loss on current minibatch is 0.693746, and regularization loss is 0.000599.\n",
      " Top K precision = 0.00847457627118644, recall = 0.0025623075217501546.\n",
      "Training on epoch 42 minibatch 1501/5000 completed\n",
      " bpr_loss on current minibatch is 0.694019, and regularization loss is 0.000872.\n",
      " Top K precision = 0.014999999999999998, recall = 0.0045267902503076515.\n",
      "Training on epoch 42 minibatch 1601/5000 completed\n",
      " bpr_loss on current minibatch is 0.693857, and regularization loss is 0.00071.\n",
      " Top K precision = 0.014999999999999998, recall = 0.005243612596553773.\n",
      "Training on epoch 42 minibatch 1701/5000 completed\n",
      " bpr_loss on current minibatch is 0.693786, and regularization loss is 0.000639.\n",
      " Top K precision = 0.006779661016949153, recall = 0.0031746031746031746.\n",
      "Training on epoch 42 minibatch 1801/5000 completed\n",
      " bpr_loss on current minibatch is 0.693763, and regularization loss is 0.000616.\n",
      " Top K precision = 0.015254237288135592, recall = 0.006303317742448624.\n",
      "Training on epoch 42 minibatch 1901/5000 completed\n",
      " bpr_loss on current minibatch is 0.693592, and regularization loss is 0.000445.\n",
      " Top K precision = 0.01, recall = 0.004078557211549539.\n",
      "Training on epoch 42 minibatch 2001/5000 completed\n",
      " bpr_loss on current minibatch is 0.693873, and regularization loss is 0.000726.\n",
      " Top K precision = 0.01, recall = 0.0026316540045244453.\n",
      "Training on epoch 42 minibatch 2101/5000 completed\n",
      " bpr_loss on current minibatch is 0.693712, and regularization loss is 0.000565.\n",
      " Top K precision = 0.01, recall = 0.006465277777777778.\n",
      "Training on epoch 42 minibatch 2201/5000 completed\n",
      " bpr_loss on current minibatch is 0.693881, and regularization loss is 0.000734.\n",
      " Top K precision = 0.016666666666666666, recall = 0.00844415970049347.\n",
      "Training on epoch 42 minibatch 2301/5000 completed\n",
      " bpr_loss on current minibatch is 0.693837, and regularization loss is 0.00069.\n",
      " Top K precision = 0.0, recall = 0.0.\n",
      "Training on epoch 42 minibatch 2401/5000 completed\n",
      " bpr_loss on current minibatch is 0.693749, and regularization loss is 0.000602.\n",
      " Top K precision = 0.01, recall = 0.005888528138528138.\n",
      "Training on epoch 42 minibatch 2501/5000 completed\n",
      " bpr_loss on current minibatch is 0.69379, and regularization loss is 0.000643.\n",
      " Top K precision = 0.015254237288135592, recall = 0.00953463351991452.\n",
      "Training on epoch 42 minibatch 2601/5000 completed\n",
      " bpr_loss on current minibatch is 0.693801, and regularization loss is 0.000654.\n",
      " Top K precision = 0.00847457627118644, recall = 0.006015287470920571.\n",
      "Training on epoch 42 minibatch 2701/5000 completed\n",
      " bpr_loss on current minibatch is 0.693716, and regularization loss is 0.000569.\n",
      " Top K precision = 0.011666666666666665, recall = 0.004830898582109822.\n",
      "Training on epoch 42 minibatch 2801/5000 completed\n",
      " bpr_loss on current minibatch is 0.693848, and regularization loss is 0.000701.\n",
      " Top K precision = 0.005000000000000001, recall = 0.001546092796092796.\n",
      "Training on epoch 42 minibatch 2901/5000 completed\n",
      " bpr_loss on current minibatch is 0.693785, and regularization loss is 0.000638.\n",
      " Top K precision = 0.017241379310344827, recall = 0.00876568799771811.\n",
      "Training on epoch 42 minibatch 3001/5000 completed\n",
      " bpr_loss on current minibatch is 0.693855, and regularization loss is 0.000708.\n",
      " Top K precision = 0.008333333333333333, recall = 0.005394481249744409.\n",
      "Training on epoch 42 minibatch 3101/5000 completed\n",
      " bpr_loss on current minibatch is 0.693831, and regularization loss is 0.000684.\n",
      " Top K precision = 0.011666666666666665, recall = 0.004185961709217523.\n",
      "Training on epoch 42 minibatch 3201/5000 completed\n",
      " bpr_loss on current minibatch is 0.693805, and regularization loss is 0.000658.\n",
      " Top K precision = 0.01, recall = 0.004112476963707863.\n",
      "Training on epoch 42 minibatch 3301/5000 completed\n",
      " bpr_loss on current minibatch is 0.693814, and regularization loss is 0.000667.\n",
      " Top K precision = 0.00847457627118644, recall = 0.003238345787911235.\n",
      "Training on epoch 42 minibatch 3401/5000 completed\n",
      " bpr_loss on current minibatch is 0.693982, and regularization loss is 0.000835.\n",
      " Top K precision = 0.010526315789473686, recall = 0.005373573794626427.\n",
      "Training on epoch 42 minibatch 3501/5000 completed\n",
      " bpr_loss on current minibatch is 0.693792, and regularization loss is 0.000645.\n",
      " Top K precision = 0.01, recall = 0.004514921471443211.\n",
      "Training on epoch 42 minibatch 3601/5000 completed\n",
      " bpr_loss on current minibatch is 0.693752, and regularization loss is 0.000605.\n",
      " Top K precision = 0.013333333333333332, recall = 0.007941074308009792.\n",
      "Training on epoch 42 minibatch 3701/5000 completed\n",
      " bpr_loss on current minibatch is 0.693659, and regularization loss is 0.000512.\n",
      " Top K precision = 0.010169491525423728, recall = 0.004140820762141012.\n",
      "Training on epoch 42 minibatch 3801/5000 completed\n",
      " bpr_loss on current minibatch is 0.693716, and regularization loss is 0.000568.\n",
      " Top K precision = 0.016666666666666666, recall = 0.007740252513877325.\n",
      "Training on epoch 42 minibatch 3901/5000 completed\n",
      " bpr_loss on current minibatch is 0.693788, and regularization loss is 0.00064.\n",
      " Top K precision = 0.015254237288135592, recall = 0.005389261195923655.\n",
      "Training on epoch 42 minibatch 4001/5000 completed\n",
      " bpr_loss on current minibatch is 0.693651, and regularization loss is 0.000504.\n",
      " Top K precision = 0.014999999999999998, recall = 0.008198125622421396.\n",
      "Training on epoch 42 minibatch 4101/5000 completed\n",
      " bpr_loss on current minibatch is 0.693725, and regularization loss is 0.000578.\n",
      " Top K precision = 0.00847457627118644, recall = 0.00397291014503226.\n",
      "Training on epoch 42 minibatch 4201/5000 completed\n",
      " bpr_loss on current minibatch is 0.693759, and regularization loss is 0.000611.\n",
      " Top K precision = 0.008333333333333333, recall = 0.00409963768115942.\n",
      "Training on epoch 42 minibatch 4301/5000 completed\n",
      " bpr_loss on current minibatch is 0.69373, and regularization loss is 0.000583.\n",
      " Top K precision = 0.010169491525423728, recall = 0.0040743678176762685.\n",
      "Training on epoch 42 minibatch 4401/5000 completed\n",
      " bpr_loss on current minibatch is 0.693988, and regularization loss is 0.000841.\n",
      " Top K precision = 0.015254237288135592, recall = 0.0056537310685392745.\n",
      "Training on epoch 42 minibatch 4501/5000 completed\n",
      " bpr_loss on current minibatch is 0.693891, and regularization loss is 0.000744.\n",
      " Top K precision = 0.01833333333333333, recall = 0.0064317751511545436.\n",
      "Training on epoch 42 minibatch 4601/5000 completed\n",
      " bpr_loss on current minibatch is 0.693871, and regularization loss is 0.000724.\n",
      " Top K precision = 0.005000000000000001, recall = 0.0013458508403361342.\n",
      "Training on epoch 42 minibatch 4701/5000 completed\n",
      " bpr_loss on current minibatch is 0.693805, and regularization loss is 0.000658.\n",
      " Top K precision = 0.008333333333333333, recall = 0.003064793626578523.\n",
      "Training on epoch 42 minibatch 4801/5000 completed\n",
      " bpr_loss on current minibatch is 0.693897, and regularization loss is 0.00075.\n",
      " Top K precision = 0.00847457627118644, recall = 0.004327716007892868.\n",
      "Training on epoch 42 minibatch 4901/5000 completed\n",
      " bpr_loss on current minibatch is 0.693731, and regularization loss is 0.000583.\n",
      " Top K precision = 0.016666666666666666, recall = 0.007849055678356753.\n",
      "\n",
      "Training on 42 epoch completed.\n",
      " Average bpr_loss on train set is 0.011563 for the current epoch.\n",
      " Training top K precision = 0.0145000000000001, recall = 0.0061579952079880715.\n",
      " Average bpr_loss on the validation set is 2e-06, and regularization loss is 0.0.\n",
      " Validation top K precision = 0.013766666666666759, recall = 0.005984272717191351.\n",
      "\n",
      "Training on the 43 epoch\n",
      "Training on epoch 43 minibatch 1/5000 completed\n",
      " bpr_loss on current minibatch is 0.693701, and regularization loss is 0.000554.\n",
      " Top K precision = 0.008333333333333333, recall = 0.002787649322737042.\n",
      "Training on epoch 43 minibatch 101/5000 completed\n",
      " bpr_loss on current minibatch is 0.693684, and regularization loss is 0.000537.\n",
      " Top K precision = 0.011864406779661016, recall = 0.005098239448636533.\n",
      "Training on epoch 43 minibatch 201/5000 completed\n",
      " bpr_loss on current minibatch is 0.693899, and regularization loss is 0.000752.\n",
      " Top K precision = 0.00847457627118644, recall = 0.0035796998114629264.\n",
      "Training on epoch 43 minibatch 301/5000 completed\n",
      " bpr_loss on current minibatch is 0.693762, and regularization loss is 0.000615.\n",
      " Top K precision = 0.011864406779661016, recall = 0.00375457280775808.\n",
      "Training on epoch 43 minibatch 401/5000 completed\n",
      " bpr_loss on current minibatch is 0.693962, and regularization loss is 0.000815.\n",
      " Top K precision = 0.010169491525423728, recall = 0.0052011269283793815.\n",
      "Training on epoch 43 minibatch 501/5000 completed\n",
      " bpr_loss on current minibatch is 0.693791, and regularization loss is 0.000644.\n",
      " Top K precision = 0.016666666666666666, recall = 0.006189231638400437.\n",
      "Training on epoch 43 minibatch 601/5000 completed\n",
      " bpr_loss on current minibatch is 0.693819, and regularization loss is 0.000671.\n",
      " Top K precision = 0.01, recall = 0.007678804855275443.\n",
      "Training on epoch 43 minibatch 701/5000 completed\n",
      " bpr_loss on current minibatch is 0.693858, and regularization loss is 0.000711.\n",
      " Top K precision = 0.011864406779661016, recall = 0.0036977049688914094.\n",
      "Training on epoch 43 minibatch 801/5000 completed\n",
      " bpr_loss on current minibatch is 0.693794, and regularization loss is 0.000647.\n",
      " Top K precision = 0.006666666666666667, recall = 0.0041755698005698.\n",
      "Training on epoch 43 minibatch 901/5000 completed\n",
      " bpr_loss on current minibatch is 0.69388, and regularization loss is 0.000733.\n",
      " Top K precision = 0.015000000000000001, recall = 0.0064487796066743435.\n",
      "Training on epoch 43 minibatch 1001/5000 completed\n",
      " bpr_loss on current minibatch is 0.693692, and regularization loss is 0.000544.\n",
      " Top K precision = 0.006779661016949153, recall = 0.0016263810652510074.\n",
      "Training on epoch 43 minibatch 1101/5000 completed\n",
      " bpr_loss on current minibatch is 0.693868, and regularization loss is 0.00072.\n",
      " Top K precision = 0.005357142857142858, recall = 0.0018353174603174605.\n",
      "Training on epoch 43 minibatch 1201/5000 completed\n",
      " bpr_loss on current minibatch is 0.693829, and regularization loss is 0.000682.\n",
      " Top K precision = 0.010169491525423728, recall = 0.005298290508312616.\n",
      "Training on epoch 43 minibatch 1301/5000 completed\n",
      " bpr_loss on current minibatch is 0.693731, and regularization loss is 0.000584.\n",
      " Top K precision = 0.011864406779661016, recall = 0.003213149358101598.\n",
      "Training on epoch 43 minibatch 1401/5000 completed\n",
      " bpr_loss on current minibatch is 0.693901, and regularization loss is 0.000754.\n",
      " Top K precision = 0.00847457627118644, recall = 0.0025501663592349764.\n",
      "Training on epoch 43 minibatch 1501/5000 completed\n",
      " bpr_loss on current minibatch is 0.693938, and regularization loss is 0.000791.\n",
      " Top K precision = 0.008333333333333333, recall = 0.004783521935906145.\n",
      "Training on epoch 43 minibatch 1601/5000 completed\n",
      " bpr_loss on current minibatch is 0.693665, and regularization loss is 0.000518.\n",
      " Top K precision = 0.008620689655172414, recall = 0.005295079732860843.\n",
      "Training on epoch 43 minibatch 1701/5000 completed\n",
      " bpr_loss on current minibatch is 0.693759, and regularization loss is 0.000612.\n",
      " Top K precision = 0.008333333333333333, recall = 0.004539558410526153.\n",
      "Training on epoch 43 minibatch 1801/5000 completed\n",
      " bpr_loss on current minibatch is 0.693716, and regularization loss is 0.000569.\n",
      " Top K precision = 0.01, recall = 0.004199724314293398.\n",
      "Training on epoch 43 minibatch 1901/5000 completed\n",
      " bpr_loss on current minibatch is 0.693812, and regularization loss is 0.000665.\n",
      " Top K precision = 0.006779661016949153, recall = 0.00281250404630265.\n",
      "Training on epoch 43 minibatch 2001/5000 completed\n",
      " bpr_loss on current minibatch is 0.693729, and regularization loss is 0.000582.\n",
      " Top K precision = 0.016666666666666666, recall = 0.005732458831651349.\n",
      "Training on epoch 43 minibatch 2101/5000 completed\n",
      " bpr_loss on current minibatch is 0.693741, and regularization loss is 0.000594.\n",
      " Top K precision = 0.013559322033898305, recall = 0.006606835164106897.\n",
      "Training on epoch 43 minibatch 2201/5000 completed\n",
      " bpr_loss on current minibatch is 0.693777, and regularization loss is 0.00063.\n",
      " Top K precision = 0.008620689655172414, recall = 0.003868178090441959.\n",
      "Training on epoch 43 minibatch 2301/5000 completed\n",
      " bpr_loss on current minibatch is 0.693773, and regularization loss is 0.000626.\n",
      " Top K precision = 0.008333333333333333, recall = 0.004865196078431372.\n",
      "Training on epoch 43 minibatch 2401/5000 completed\n",
      " bpr_loss on current minibatch is 0.693699, and regularization loss is 0.000552.\n",
      " Top K precision = 0.013333333333333332, recall = 0.004782976627823119.\n",
      "Training on epoch 43 minibatch 2501/5000 completed\n",
      " bpr_loss on current minibatch is 0.693955, and regularization loss is 0.000808.\n",
      " Top K precision = 0.01, recall = 0.0048252688172043005.\n",
      "Training on epoch 43 minibatch 2601/5000 completed\n",
      " bpr_loss on current minibatch is 0.693827, and regularization loss is 0.000679.\n",
      " Top K precision = 0.02, recall = 0.009043456271397448.\n",
      "Training on epoch 43 minibatch 2701/5000 completed\n",
      " bpr_loss on current minibatch is 0.694087, and regularization loss is 0.00094.\n",
      " Top K precision = 0.016666666666666666, recall = 0.007786812667563081.\n",
      "Training on epoch 43 minibatch 2801/5000 completed\n",
      " bpr_loss on current minibatch is 0.693925, and regularization loss is 0.000778.\n",
      " Top K precision = 0.015254237288135592, recall = 0.007015974895488528.\n",
      "Training on epoch 43 minibatch 2901/5000 completed\n",
      " bpr_loss on current minibatch is 0.693838, and regularization loss is 0.000691.\n",
      " Top K precision = 0.015254237288135592, recall = 0.007764824862216898.\n",
      "Training on epoch 43 minibatch 3001/5000 completed\n",
      " bpr_loss on current minibatch is 0.693744, and regularization loss is 0.000597.\n",
      " Top K precision = 0.01, recall = 0.0037110832637148434.\n",
      "Training on epoch 43 minibatch 3101/5000 completed\n",
      " bpr_loss on current minibatch is 0.693864, and regularization loss is 0.000717.\n",
      " Top K precision = 0.00847457627118644, recall = 0.003025347137746781.\n",
      "Training on epoch 43 minibatch 3201/5000 completed\n",
      " bpr_loss on current minibatch is 0.693973, and regularization loss is 0.000826.\n",
      " Top K precision = 0.00847457627118644, recall = 0.00298775644772138.\n",
      "Training on epoch 43 minibatch 3301/5000 completed\n",
      " bpr_loss on current minibatch is 0.693752, and regularization loss is 0.000605.\n",
      " Top K precision = 0.013333333333333332, recall = 0.0057639130281674136.\n",
      "Training on epoch 43 minibatch 3401/5000 completed\n",
      " bpr_loss on current minibatch is 0.693914, and regularization loss is 0.000767.\n",
      " Top K precision = 0.01, recall = 0.005472582972582972.\n",
      "Training on epoch 43 minibatch 3501/5000 completed\n",
      " bpr_loss on current minibatch is 0.69385, and regularization loss is 0.000703.\n",
      " Top K precision = 0.019298245614035085, recall = 0.009123667421554082.\n",
      "Training on epoch 43 minibatch 3601/5000 completed\n",
      " bpr_loss on current minibatch is 0.693598, and regularization loss is 0.000451.\n",
      " Top K precision = 0.015254237288135592, recall = 0.0059646144156929514.\n",
      "Training on epoch 43 minibatch 3701/5000 completed\n",
      " bpr_loss on current minibatch is 0.693794, and regularization loss is 0.000647.\n",
      " Top K precision = 0.016666666666666666, recall = 0.006264823081789633.\n",
      "Training on epoch 43 minibatch 3801/5000 completed\n",
      " bpr_loss on current minibatch is 0.693769, and regularization loss is 0.000622.\n",
      " Top K precision = 0.0016666666666666668, recall = 0.0004901960784313725.\n",
      "Training on epoch 43 minibatch 3901/5000 completed\n",
      " bpr_loss on current minibatch is 0.693811, and regularization loss is 0.000664.\n",
      " Top K precision = 0.005000000000000001, recall = 0.0019397269397269398.\n",
      "Training on epoch 43 minibatch 4001/5000 completed\n",
      " bpr_loss on current minibatch is 0.693933, and regularization loss is 0.000786.\n",
      " Top K precision = 0.01, recall = 0.006148708720288784.\n",
      "Training on epoch 43 minibatch 4101/5000 completed\n",
      " bpr_loss on current minibatch is 0.693908, and regularization loss is 0.000761.\n",
      " Top K precision = 0.011666666666666665, recall = 0.00419902013436701.\n",
      "Training on epoch 43 minibatch 4201/5000 completed\n",
      " bpr_loss on current minibatch is 0.693852, and regularization loss is 0.000704.\n",
      " Top K precision = 0.016666666666666666, recall = 0.009428514686507013.\n",
      "Training on epoch 43 minibatch 4301/5000 completed\n",
      " bpr_loss on current minibatch is 0.693795, and regularization loss is 0.000648.\n",
      " Top K precision = 0.02, recall = 0.00801122805598509.\n",
      "Training on epoch 43 minibatch 4401/5000 completed\n",
      " bpr_loss on current minibatch is 0.693763, and regularization loss is 0.000616.\n",
      " Top K precision = 0.008333333333333333, recall = 0.003415103415103415.\n",
      "Training on epoch 43 minibatch 4501/5000 completed\n",
      " bpr_loss on current minibatch is 0.693805, and regularization loss is 0.000658.\n",
      " Top K precision = 0.014999999999999998, recall = 0.0056122033424665.\n",
      "Training on epoch 43 minibatch 4601/5000 completed\n",
      " bpr_loss on current minibatch is 0.693829, and regularization loss is 0.000682.\n",
      " Top K precision = 0.015254237288135592, recall = 0.006566609694725349.\n",
      "Training on epoch 43 minibatch 4701/5000 completed\n",
      " bpr_loss on current minibatch is 0.69377, and regularization loss is 0.000623.\n",
      " Top K precision = 0.013333333333333332, recall = 0.006793890410781475.\n",
      "Training on epoch 43 minibatch 4801/5000 completed\n",
      " bpr_loss on current minibatch is 0.693708, and regularization loss is 0.000561.\n",
      " Top K precision = 0.01833333333333333, recall = 0.008746850392714242.\n",
      "Training on epoch 43 minibatch 4901/5000 completed\n",
      " bpr_loss on current minibatch is 0.693762, and regularization loss is 0.000615.\n",
      " Top K precision = 0.008333333333333333, recall = 0.004719566125458574.\n",
      "\n",
      "Training on 43 epoch completed.\n",
      " Average bpr_loss on train set is 0.011563 for the current epoch.\n",
      " Training top K precision = 0.014000000000000094, recall = 0.006055874850119721.\n",
      " Average bpr_loss on the validation set is 2e-06, and regularization loss is 0.0.\n",
      " Validation top K precision = 0.013800000000000083, recall = 0.0061714947116881585.\n",
      "\n",
      "Training on the 44 epoch\n",
      "Training on epoch 44 minibatch 1/5000 completed\n",
      " bpr_loss on current minibatch is 0.693892, and regularization loss is 0.000745.\n",
      " Top K precision = 0.011864406779661016, recall = 0.005013089546987852.\n",
      "Training on epoch 44 minibatch 101/5000 completed\n",
      " bpr_loss on current minibatch is 0.693591, and regularization loss is 0.000444.\n",
      " Top K precision = 0.010344827586206896, recall = 0.008555242961936674.\n",
      "Training on epoch 44 minibatch 201/5000 completed\n",
      " bpr_loss on current minibatch is 0.693856, and regularization loss is 0.000709.\n",
      " Top K precision = 0.014999999999999998, recall = 0.005861721971805649.\n",
      "Training on epoch 44 minibatch 301/5000 completed\n",
      " bpr_loss on current minibatch is 0.693913, and regularization loss is 0.000766.\n",
      " Top K precision = 0.01, recall = 0.0061701857834412675.\n",
      "Training on epoch 44 minibatch 401/5000 completed\n",
      " bpr_loss on current minibatch is 0.693997, and regularization loss is 0.000849.\n",
      " Top K precision = 0.01206896551724138, recall = 0.004806383577935301.\n",
      "Training on epoch 44 minibatch 501/5000 completed\n",
      " bpr_loss on current minibatch is 0.693739, and regularization loss is 0.000592.\n",
      " Top K precision = 0.008333333333333333, recall = 0.0030212332602038484.\n",
      "Training on epoch 44 minibatch 601/5000 completed\n",
      " bpr_loss on current minibatch is 0.693785, and regularization loss is 0.000638.\n",
      " Top K precision = 0.013333333333333332, recall = 0.006510271800126872.\n",
      "Training on epoch 44 minibatch 701/5000 completed\n",
      " bpr_loss on current minibatch is 0.693773, and regularization loss is 0.000626.\n",
      " Top K precision = 0.013793103448275864, recall = 0.007484942706665243.\n",
      "Training on epoch 44 minibatch 801/5000 completed\n",
      " bpr_loss on current minibatch is 0.693831, and regularization loss is 0.000684.\n",
      " Top K precision = 0.014999999999999998, recall = 0.006334756227178967.\n",
      "Training on epoch 44 minibatch 901/5000 completed\n",
      " bpr_loss on current minibatch is 0.693673, and regularization loss is 0.000525.\n",
      " Top K precision = 0.010169491525423728, recall = 0.0047876084722068505.\n",
      "Training on epoch 44 minibatch 1001/5000 completed\n",
      " bpr_loss on current minibatch is 0.69391, and regularization loss is 0.000762.\n",
      " Top K precision = 0.017241379310344827, recall = 0.008002438174851969.\n",
      "Training on epoch 44 minibatch 1101/5000 completed\n",
      " bpr_loss on current minibatch is 0.693948, and regularization loss is 0.0008.\n",
      " Top K precision = 0.013333333333333332, recall = 0.005367170168640757.\n",
      "Training on epoch 44 minibatch 1201/5000 completed\n",
      " bpr_loss on current minibatch is 0.693761, and regularization loss is 0.000614.\n",
      " Top K precision = 0.01, recall = 0.003051305722113176.\n",
      "Training on epoch 44 minibatch 1301/5000 completed\n",
      " bpr_loss on current minibatch is 0.693759, and regularization loss is 0.000612.\n",
      " Top K precision = 0.011864406779661016, recall = 0.0058766241192646194.\n",
      "Training on epoch 44 minibatch 1401/5000 completed\n",
      " bpr_loss on current minibatch is 0.693811, and regularization loss is 0.000664.\n",
      " Top K precision = 0.006666666666666667, recall = 0.0028190049023382358.\n",
      "Training on epoch 44 minibatch 1501/5000 completed\n",
      " bpr_loss on current minibatch is 0.693734, and regularization loss is 0.000587.\n",
      " Top K precision = 0.005084745762711865, recall = 0.0025646743978590546.\n",
      "Training on epoch 44 minibatch 1601/5000 completed\n",
      " bpr_loss on current minibatch is 0.693631, and regularization loss is 0.000483.\n",
      " Top K precision = 0.013559322033898305, recall = 0.007673568243759843.\n",
      "Training on epoch 44 minibatch 1701/5000 completed\n",
      " bpr_loss on current minibatch is 0.693883, and regularization loss is 0.000735.\n",
      " Top K precision = 0.015000000000000001, recall = 0.007253233179703767.\n",
      "Training on epoch 44 minibatch 1801/5000 completed\n",
      " bpr_loss on current minibatch is 0.693783, and regularization loss is 0.000636.\n",
      " Top K precision = 0.013559322033898305, recall = 0.0033636277271133566.\n",
      "Training on epoch 44 minibatch 1901/5000 completed\n",
      " bpr_loss on current minibatch is 0.693798, and regularization loss is 0.000651.\n",
      " Top K precision = 0.016666666666666666, recall = 0.0083617253847517.\n",
      "Training on epoch 44 minibatch 2001/5000 completed\n",
      " bpr_loss on current minibatch is 0.693827, and regularization loss is 0.00068.\n",
      " Top K precision = 0.00847457627118644, recall = 0.0029581999920982975.\n",
      "Training on epoch 44 minibatch 2101/5000 completed\n",
      " bpr_loss on current minibatch is 0.69391, and regularization loss is 0.000763.\n",
      " Top K precision = 0.014999999999999998, recall = 0.0059035645739201024.\n",
      "Training on epoch 44 minibatch 2201/5000 completed\n",
      " bpr_loss on current minibatch is 0.69377, and regularization loss is 0.000623.\n",
      " Top K precision = 0.01206896551724138, recall = 0.00507083729374447.\n",
      "Training on epoch 44 minibatch 2301/5000 completed\n",
      " bpr_loss on current minibatch is 0.693843, and regularization loss is 0.000696.\n",
      " Top K precision = 0.01, recall = 0.0033018613851947187.\n",
      "Training on epoch 44 minibatch 2401/5000 completed\n",
      " bpr_loss on current minibatch is 0.693717, and regularization loss is 0.00057.\n",
      " Top K precision = 0.005084745762711865, recall = 0.0023627274857455282.\n",
      "Training on epoch 44 minibatch 2501/5000 completed\n",
      " bpr_loss on current minibatch is 0.693705, and regularization loss is 0.000558.\n",
      " Top K precision = 0.008333333333333333, recall = 0.0027941341066341067.\n",
      "Training on epoch 44 minibatch 2601/5000 completed\n",
      " bpr_loss on current minibatch is 0.693809, and regularization loss is 0.000662.\n",
      " Top K precision = 0.011864406779661016, recall = 0.0055580785012405995.\n",
      "Training on epoch 44 minibatch 2701/5000 completed\n",
      " bpr_loss on current minibatch is 0.69363, and regularization loss is 0.000482.\n",
      " Top K precision = 0.01379310344827586, recall = 0.004760773696516837.\n",
      "Training on epoch 44 minibatch 2801/5000 completed\n",
      " bpr_loss on current minibatch is 0.693801, and regularization loss is 0.000653.\n",
      " Top K precision = 0.013559322033898306, recall = 0.004261666754123594.\n",
      "Training on epoch 44 minibatch 2901/5000 completed\n",
      " bpr_loss on current minibatch is 0.693686, and regularization loss is 0.000539.\n",
      " Top K precision = 0.011666666666666665, recall = 0.00494839265672599.\n",
      "Training on epoch 44 minibatch 3001/5000 completed\n",
      " bpr_loss on current minibatch is 0.693754, and regularization loss is 0.000607.\n",
      " Top K precision = 0.005084745762711865, recall = 0.0011048695300351463.\n",
      "Training on epoch 44 minibatch 3101/5000 completed\n",
      " bpr_loss on current minibatch is 0.693799, and regularization loss is 0.000652.\n",
      " Top K precision = 0.013333333333333332, recall = 0.004353704050666442.\n",
      "Training on epoch 44 minibatch 3201/5000 completed\n",
      " bpr_loss on current minibatch is 0.693831, and regularization loss is 0.000684.\n",
      " Top K precision = 0.013333333333333332, recall = 0.0049616247511785035.\n",
      "Training on epoch 44 minibatch 3301/5000 completed\n",
      " bpr_loss on current minibatch is 0.693775, and regularization loss is 0.000628.\n",
      " Top K precision = 0.01, recall = 0.006679445042700528.\n",
      "Training on epoch 44 minibatch 3401/5000 completed\n",
      " bpr_loss on current minibatch is 0.693759, and regularization loss is 0.000612.\n",
      " Top K precision = 0.014999999999999998, recall = 0.006341981208872273.\n",
      "Training on epoch 44 minibatch 3501/5000 completed\n",
      " bpr_loss on current minibatch is 0.693879, and regularization loss is 0.000732.\n",
      " Top K precision = 0.014999999999999998, recall = 0.0062661743714375285.\n",
      "Training on epoch 44 minibatch 3601/5000 completed\n",
      " bpr_loss on current minibatch is 0.693708, and regularization loss is 0.000561.\n",
      " Top K precision = 0.005000000000000001, recall = 0.0016468253968253967.\n",
      "Training on epoch 44 minibatch 3701/5000 completed\n",
      " bpr_loss on current minibatch is 0.69393, and regularization loss is 0.000783.\n",
      " Top K precision = 0.011666666666666665, recall = 0.0033689542515499002.\n",
      "Training on epoch 44 minibatch 3801/5000 completed\n",
      " bpr_loss on current minibatch is 0.693788, and regularization loss is 0.000641.\n",
      " Top K precision = 0.006666666666666667, recall = 0.0017754286776025905.\n",
      "Training on epoch 44 minibatch 3901/5000 completed\n",
      " bpr_loss on current minibatch is 0.693797, and regularization loss is 0.00065.\n",
      " Top K precision = 0.018965517241379307, recall = 0.005566414653635749.\n",
      "Training on epoch 44 minibatch 4001/5000 completed\n",
      " bpr_loss on current minibatch is 0.693728, and regularization loss is 0.000581.\n",
      " Top K precision = 0.006896551724137932, recall = 0.002896654351395731.\n",
      "Training on epoch 44 minibatch 4101/5000 completed\n",
      " bpr_loss on current minibatch is 0.693715, and regularization loss is 0.000568.\n",
      " Top K precision = 0.006779661016949153, recall = 0.0018464463563947718.\n",
      "Training on epoch 44 minibatch 4201/5000 completed\n",
      " bpr_loss on current minibatch is 0.693786, and regularization loss is 0.000639.\n",
      " Top K precision = 0.013559322033898305, recall = 0.004873113937225949.\n",
      "Training on epoch 44 minibatch 4301/5000 completed\n",
      " bpr_loss on current minibatch is 0.69382, and regularization loss is 0.000673.\n",
      " Top K precision = 0.011864406779661016, recall = 0.005357109887269409.\n",
      "Training on epoch 44 minibatch 4401/5000 completed\n",
      " bpr_loss on current minibatch is 0.693893, and regularization loss is 0.000746.\n",
      " Top K precision = 0.013333333333333332, recall = 0.009200036805299964.\n",
      "Training on epoch 44 minibatch 4501/5000 completed\n",
      " bpr_loss on current minibatch is 0.693752, and regularization loss is 0.000605.\n",
      " Top K precision = 0.014999999999999998, recall = 0.008296641224272804.\n",
      "Training on epoch 44 minibatch 4601/5000 completed\n",
      " bpr_loss on current minibatch is 0.693998, and regularization loss is 0.000851.\n",
      " Top K precision = 0.011666666666666665, recall = 0.005134853839756708.\n",
      "Training on epoch 44 minibatch 4701/5000 completed\n",
      " bpr_loss on current minibatch is 0.69399, and regularization loss is 0.000843.\n",
      " Top K precision = 0.013333333333333332, recall = 0.005586794621882341.\n",
      "Training on epoch 44 minibatch 4801/5000 completed\n",
      " bpr_loss on current minibatch is 0.693801, and regularization loss is 0.000654.\n",
      " Top K precision = 0.010526315789473684, recall = 0.004797401539424857.\n",
      "Training on epoch 44 minibatch 4901/5000 completed\n",
      " bpr_loss on current minibatch is 0.693811, and regularization loss is 0.000664.\n",
      " Top K precision = 0.014999999999999998, recall = 0.004752795475345384.\n",
      "\n",
      "Training on 44 epoch completed.\n",
      " Average bpr_loss on train set is 0.011563 for the current epoch.\n",
      " Training top K precision = 0.015266666666666784, recall = 0.006918070526256311.\n",
      " Average bpr_loss on the validation set is 2e-06, and regularization loss is 0.0.\n",
      " Validation top K precision = 0.014066666666666765, recall = 0.0063065763390957675.\n",
      "\n",
      "Training on the 45 epoch\n",
      "Training on epoch 45 minibatch 1/5000 completed\n",
      " bpr_loss on current minibatch is 0.693826, and regularization loss is 0.000679.\n",
      " Top K precision = 0.005000000000000001, recall = 0.0011443764568764567.\n",
      "Training on epoch 45 minibatch 101/5000 completed\n",
      " bpr_loss on current minibatch is 0.693756, and regularization loss is 0.000609.\n",
      " Top K precision = 0.010344827586206896, recall = 0.002894139820135449.\n",
      "Training on epoch 45 minibatch 201/5000 completed\n",
      " bpr_loss on current minibatch is 0.693778, and regularization loss is 0.000631.\n",
      " Top K precision = 0.022413793103448276, recall = 0.011555472240675553.\n",
      "Training on epoch 45 minibatch 301/5000 completed\n",
      " bpr_loss on current minibatch is 0.693913, and regularization loss is 0.000766.\n",
      " Top K precision = 0.008771929824561403, recall = 0.006022818484118794.\n",
      "Training on epoch 45 minibatch 401/5000 completed\n",
      " bpr_loss on current minibatch is 0.693679, and regularization loss is 0.000532.\n",
      " Top K precision = 0.010169491525423728, recall = 0.006107683095107917.\n",
      "Training on epoch 45 minibatch 501/5000 completed\n",
      " bpr_loss on current minibatch is 0.693644, and regularization loss is 0.000497.\n",
      " Top K precision = 0.005172413793103449, recall = 0.0015570551828158318.\n",
      "Training on epoch 45 minibatch 601/5000 completed\n",
      " bpr_loss on current minibatch is 0.693751, and regularization loss is 0.000604.\n",
      " Top K precision = 0.01, recall = 0.0054481681362666306.\n",
      "Training on epoch 45 minibatch 701/5000 completed\n",
      " bpr_loss on current minibatch is 0.693901, and regularization loss is 0.000754.\n",
      " Top K precision = 0.008333333333333333, recall = 0.003092796092796093.\n",
      "Training on epoch 45 minibatch 801/5000 completed\n",
      " bpr_loss on current minibatch is 0.693784, and regularization loss is 0.000637.\n",
      " Top K precision = 0.013333333333333332, recall = 0.004768677175877987.\n",
      "Training on epoch 45 minibatch 901/5000 completed\n",
      " bpr_loss on current minibatch is 0.693677, and regularization loss is 0.00053.\n",
      " Top K precision = 0.01864406779661017, recall = 0.00736121252838494.\n",
      "Training on epoch 45 minibatch 1001/5000 completed\n",
      " bpr_loss on current minibatch is 0.693595, and regularization loss is 0.000448.\n",
      " Top K precision = 0.014999999999999998, recall = 0.005675711457445204.\n",
      "Training on epoch 45 minibatch 1101/5000 completed\n",
      " bpr_loss on current minibatch is 0.693806, and regularization loss is 0.000658.\n",
      " Top K precision = 0.01833333333333333, recall = 0.010665038279621612.\n",
      "Training on epoch 45 minibatch 1201/5000 completed\n",
      " bpr_loss on current minibatch is 0.6938, and regularization loss is 0.000653.\n",
      " Top K precision = 0.015000000000000001, recall = 0.005209198445460056.\n",
      "Training on epoch 45 minibatch 1301/5000 completed\n",
      " bpr_loss on current minibatch is 0.693823, and regularization loss is 0.000676.\n",
      " Top K precision = 0.006779661016949153, recall = 0.00248114441568562.\n",
      "Training on epoch 45 minibatch 1401/5000 completed\n",
      " bpr_loss on current minibatch is 0.69357, and regularization loss is 0.000423.\n",
      " Top K precision = 0.014999999999999998, recall = 0.004297128033227354.\n",
      "Training on epoch 45 minibatch 1501/5000 completed\n",
      " bpr_loss on current minibatch is 0.693662, and regularization loss is 0.000515.\n",
      " Top K precision = 0.015254237288135592, recall = 0.006177779605323062.\n",
      "Training on epoch 45 minibatch 1601/5000 completed\n",
      " bpr_loss on current minibatch is 0.693727, and regularization loss is 0.00058.\n",
      " Top K precision = 0.011666666666666665, recall = 0.004859359382501037.\n",
      "Training on epoch 45 minibatch 1701/5000 completed\n",
      " bpr_loss on current minibatch is 0.693811, and regularization loss is 0.000664.\n",
      " Top K precision = 0.013333333333333332, recall = 0.007148396689143717.\n",
      "Training on epoch 45 minibatch 1801/5000 completed\n",
      " bpr_loss on current minibatch is 0.693819, and regularization loss is 0.000671.\n",
      " Top K precision = 0.015254237288135592, recall = 0.009505857280359858.\n",
      "Training on epoch 45 minibatch 1901/5000 completed\n",
      " bpr_loss on current minibatch is 0.693766, and regularization loss is 0.000619.\n",
      " Top K precision = 0.016666666666666666, recall = 0.00643152974740168.\n",
      "Training on epoch 45 minibatch 2001/5000 completed\n",
      " bpr_loss on current minibatch is 0.693911, and regularization loss is 0.000764.\n",
      " Top K precision = 0.011864406779661016, recall = 0.005414731613095048.\n",
      "Training on epoch 45 minibatch 2101/5000 completed\n",
      " bpr_loss on current minibatch is 0.69389, and regularization loss is 0.000743.\n",
      " Top K precision = 0.013559322033898305, recall = 0.004682471005065192.\n",
      "Training on epoch 45 minibatch 2201/5000 completed\n",
      " bpr_loss on current minibatch is 0.693682, and regularization loss is 0.000535.\n",
      " Top K precision = 0.005172413793103449, recall = 0.001815103000447828.\n",
      "Training on epoch 45 minibatch 2301/5000 completed\n",
      " bpr_loss on current minibatch is 0.693858, and regularization loss is 0.000711.\n",
      " Top K precision = 0.01379310344827586, recall = 0.006214322494900701.\n",
      "Training on epoch 45 minibatch 2401/5000 completed\n",
      " bpr_loss on current minibatch is 0.693751, and regularization loss is 0.000604.\n",
      " Top K precision = 0.014999999999999998, recall = 0.005807169983640572.\n",
      "Training on epoch 45 minibatch 2501/5000 completed\n",
      " bpr_loss on current minibatch is 0.693687, and regularization loss is 0.000539.\n",
      " Top K precision = 0.018644067796610167, recall = 0.00686379808256814.\n",
      "Training on epoch 45 minibatch 2601/5000 completed\n",
      " bpr_loss on current minibatch is 0.693742, and regularization loss is 0.000595.\n",
      " Top K precision = 0.008333333333333333, recall = 0.004052605890841185.\n",
      "Training on epoch 45 minibatch 2701/5000 completed\n",
      " bpr_loss on current minibatch is 0.693653, and regularization loss is 0.000506.\n",
      " Top K precision = 0.016666666666666666, recall = 0.007178368157470324.\n",
      "Training on epoch 45 minibatch 2801/5000 completed\n",
      " bpr_loss on current minibatch is 0.693871, and regularization loss is 0.000724.\n",
      " Top K precision = 0.01833333333333333, recall = 0.010326816284581545.\n",
      "Training on epoch 45 minibatch 2901/5000 completed\n",
      " bpr_loss on current minibatch is 0.693749, and regularization loss is 0.000601.\n",
      " Top K precision = 0.013559322033898305, recall = 0.006501776288069582.\n",
      "Training on epoch 45 minibatch 3001/5000 completed\n",
      " bpr_loss on current minibatch is 0.693789, and regularization loss is 0.000642.\n",
      " Top K precision = 0.021666666666666664, recall = 0.007441418983955354.\n",
      "Training on epoch 45 minibatch 3101/5000 completed\n",
      " bpr_loss on current minibatch is 0.693807, and regularization loss is 0.00066.\n",
      " Top K precision = 0.00847457627118644, recall = 0.004764350527062391.\n",
      "Training on epoch 45 minibatch 3201/5000 completed\n",
      " bpr_loss on current minibatch is 0.693868, and regularization loss is 0.000721.\n",
      " Top K precision = 0.00847457627118644, recall = 0.0029430937955364674.\n",
      "Training on epoch 45 minibatch 3301/5000 completed\n",
      " bpr_loss on current minibatch is 0.693699, and regularization loss is 0.000552.\n",
      " Top K precision = 0.01833333333333333, recall = 0.008564015349069778.\n",
      "Training on epoch 45 minibatch 3401/5000 completed\n",
      " bpr_loss on current minibatch is 0.693789, and regularization loss is 0.000642.\n",
      " Top K precision = 0.008333333333333333, recall = 0.0027798427540429603.\n",
      "Training on epoch 45 minibatch 3501/5000 completed\n",
      " bpr_loss on current minibatch is 0.693756, and regularization loss is 0.000609.\n",
      " Top K precision = 0.014999999999999998, recall = 0.0053384696442199935.\n",
      "Training on epoch 45 minibatch 3601/5000 completed\n",
      " bpr_loss on current minibatch is 0.693614, and regularization loss is 0.000467.\n",
      " Top K precision = 0.006896551724137932, recall = 0.003231940718445331.\n",
      "Training on epoch 45 minibatch 3701/5000 completed\n",
      " bpr_loss on current minibatch is 0.693766, and regularization loss is 0.000619.\n",
      " Top K precision = 0.01864406779661017, recall = 0.00673744390621927.\n",
      "Training on epoch 45 minibatch 3801/5000 completed\n",
      " bpr_loss on current minibatch is 0.693775, and regularization loss is 0.000628.\n",
      " Top K precision = 0.01379310344827586, recall = 0.005334062097964043.\n",
      "Training on epoch 45 minibatch 3901/5000 completed\n",
      " bpr_loss on current minibatch is 0.693729, and regularization loss is 0.000582.\n",
      " Top K precision = 0.013559322033898306, recall = 0.0055244178460057145.\n",
      "Training on epoch 45 minibatch 4001/5000 completed\n",
      " bpr_loss on current minibatch is 0.69373, and regularization loss is 0.000583.\n",
      " Top K precision = 0.01, recall = 0.0030769985697927963.\n",
      "Training on epoch 45 minibatch 4101/5000 completed\n",
      " bpr_loss on current minibatch is 0.693751, and regularization loss is 0.000604.\n",
      " Top K precision = 0.013333333333333332, recall = 0.005750695237423912.\n",
      "Training on epoch 45 minibatch 4201/5000 completed\n",
      " bpr_loss on current minibatch is 0.693725, and regularization loss is 0.000577.\n",
      " Top K precision = 0.011666666666666665, recall = 0.00446071776663882.\n",
      "Training on epoch 45 minibatch 4301/5000 completed\n",
      " bpr_loss on current minibatch is 0.693844, and regularization loss is 0.000696.\n",
      " Top K precision = 0.017241379310344827, recall = 0.006057872777839408.\n",
      "Training on epoch 45 minibatch 4401/5000 completed\n",
      " bpr_loss on current minibatch is 0.693762, and regularization loss is 0.000615.\n",
      " Top K precision = 0.010000000000000002, recall = 0.0038980383545600943.\n",
      "Training on epoch 45 minibatch 4501/5000 completed\n",
      " bpr_loss on current minibatch is 0.693744, and regularization loss is 0.000597.\n",
      " Top K precision = 0.01864406779661017, recall = 0.00817414210360372.\n",
      "Training on epoch 45 minibatch 4601/5000 completed\n",
      " bpr_loss on current minibatch is 0.693843, and regularization loss is 0.000696.\n",
      " Top K precision = 0.020338983050847456, recall = 0.008162733944300534.\n",
      "Training on epoch 45 minibatch 4701/5000 completed\n",
      " bpr_loss on current minibatch is 0.693679, and regularization loss is 0.000532.\n",
      " Top K precision = 0.013559322033898305, recall = 0.005787243532560214.\n",
      "Training on epoch 45 minibatch 4801/5000 completed\n",
      " bpr_loss on current minibatch is 0.693832, and regularization loss is 0.000685.\n",
      " Top K precision = 0.011864406779661016, recall = 0.007327428075528602.\n",
      "Training on epoch 45 minibatch 4901/5000 completed\n",
      " bpr_loss on current minibatch is 0.693631, and regularization loss is 0.000484.\n",
      " Top K precision = 0.01694915254237288, recall = 0.007337720897042931.\n",
      "\n",
      "Training on 45 epoch completed.\n",
      " Average bpr_loss on train set is 0.011563 for the current epoch.\n",
      " Training top K precision = 0.015333333333333454, recall = 0.006569260254733907.\n",
      " Average bpr_loss on the validation set is 2e-06, and regularization loss is 0.0.\n",
      " Validation top K precision = 0.014266666666666768, recall = 0.005918253169373039.\n",
      "\n",
      "Training on the 46 epoch\n",
      "Training on epoch 46 minibatch 1/5000 completed\n",
      " bpr_loss on current minibatch is 0.693859, and regularization loss is 0.000712.\n",
      " Top K precision = 0.0033333333333333335, recall = 0.0012626262626262627.\n",
      "Training on epoch 46 minibatch 101/5000 completed\n",
      " bpr_loss on current minibatch is 0.693801, and regularization loss is 0.000653.\n",
      " Top K precision = 0.015517241379310343, recall = 0.006730341801685442.\n",
      "Training on epoch 46 minibatch 201/5000 completed\n",
      " bpr_loss on current minibatch is 0.693787, and regularization loss is 0.00064.\n",
      " Top K precision = 0.025423728813559327, recall = 0.0103888010225097.\n",
      "Training on epoch 46 minibatch 301/5000 completed\n",
      " bpr_loss on current minibatch is 0.693865, and regularization loss is 0.000718.\n",
      " Top K precision = 0.018644067796610167, recall = 0.011271612149007137.\n",
      "Training on epoch 46 minibatch 401/5000 completed\n",
      " bpr_loss on current minibatch is 0.693767, and regularization loss is 0.00062.\n",
      " Top K precision = 0.011666666666666665, recall = 0.004575915969733174.\n",
      "Training on epoch 46 minibatch 501/5000 completed\n",
      " bpr_loss on current minibatch is 0.693944, and regularization loss is 0.000797.\n",
      " Top K precision = 0.01206896551724138, recall = 0.004779913193353532.\n",
      "Training on epoch 46 minibatch 601/5000 completed\n",
      " bpr_loss on current minibatch is 0.693852, and regularization loss is 0.000705.\n",
      " Top K precision = 0.020000000000000004, recall = 0.00882003693334923.\n",
      "Training on epoch 46 minibatch 701/5000 completed\n",
      " bpr_loss on current minibatch is 0.693806, and regularization loss is 0.000659.\n",
      " Top K precision = 0.01, recall = 0.0031655773420479296.\n",
      "Training on epoch 46 minibatch 801/5000 completed\n",
      " bpr_loss on current minibatch is 0.693771, and regularization loss is 0.000623.\n",
      " Top K precision = 0.020338983050847456, recall = 0.008593185536728845.\n",
      "Training on epoch 46 minibatch 901/5000 completed\n",
      " bpr_loss on current minibatch is 0.694007, and regularization loss is 0.00086.\n",
      " Top K precision = 0.022033898305084745, recall = 0.0111784449025816.\n",
      "Training on epoch 46 minibatch 1001/5000 completed\n",
      " bpr_loss on current minibatch is 0.693795, and regularization loss is 0.000647.\n",
      " Top K precision = 0.01, recall = 0.0027476211810889225.\n",
      "Training on epoch 46 minibatch 1101/5000 completed\n",
      " bpr_loss on current minibatch is 0.693862, and regularization loss is 0.000715.\n",
      " Top K precision = 0.00847457627118644, recall = 0.002958053268190638.\n",
      "Training on epoch 46 minibatch 1201/5000 completed\n",
      " bpr_loss on current minibatch is 0.693816, and regularization loss is 0.000668.\n",
      " Top K precision = 0.016949152542372878, recall = 0.00821001799723244.\n",
      "Training on epoch 46 minibatch 1301/5000 completed\n",
      " bpr_loss on current minibatch is 0.69377, and regularization loss is 0.000623.\n",
      " Top K precision = 0.005000000000000001, recall = 0.0018178276453171263.\n",
      "Training on epoch 46 minibatch 1401/5000 completed\n",
      " bpr_loss on current minibatch is 0.693915, and regularization loss is 0.000768.\n",
      " Top K precision = 0.01, recall = 0.00561367908407382.\n",
      "Training on epoch 46 minibatch 1501/5000 completed\n",
      " bpr_loss on current minibatch is 0.6937, and regularization loss is 0.000552.\n",
      " Top K precision = 0.008333333333333333, recall = 0.003538911547810324.\n",
      "Training on epoch 46 minibatch 1601/5000 completed\n",
      " bpr_loss on current minibatch is 0.693839, and regularization loss is 0.000692.\n",
      " Top K precision = 0.006666666666666667, recall = 0.0022777673987351404.\n",
      "Training on epoch 46 minibatch 1701/5000 completed\n",
      " bpr_loss on current minibatch is 0.693665, and regularization loss is 0.000517.\n",
      " Top K precision = 0.013333333333333332, recall = 0.006860463594980572.\n",
      "Training on epoch 46 minibatch 1801/5000 completed\n",
      " bpr_loss on current minibatch is 0.693797, and regularization loss is 0.00065.\n",
      " Top K precision = 0.00847457627118644, recall = 0.0028925597893037676.\n",
      "Training on epoch 46 minibatch 1901/5000 completed\n",
      " bpr_loss on current minibatch is 0.693906, and regularization loss is 0.000759.\n",
      " Top K precision = 0.013333333333333332, recall = 0.008086344005172724.\n",
      "Training on epoch 46 minibatch 2001/5000 completed\n",
      " bpr_loss on current minibatch is 0.693848, and regularization loss is 0.000701.\n",
      " Top K precision = 0.014999999999999998, recall = 0.007163889263504427.\n",
      "Training on epoch 46 minibatch 2101/5000 completed\n",
      " bpr_loss on current minibatch is 0.693705, and regularization loss is 0.000558.\n",
      " Top K precision = 0.006666666666666667, recall = 0.002762400793650794.\n",
      "Training on epoch 46 minibatch 2201/5000 completed\n",
      " bpr_loss on current minibatch is 0.693881, and regularization loss is 0.000734.\n",
      " Top K precision = 0.011864406779661016, recall = 0.004401516900629184.\n",
      "Training on epoch 46 minibatch 2301/5000 completed\n",
      " bpr_loss on current minibatch is 0.693717, and regularization loss is 0.00057.\n",
      " Top K precision = 0.008333333333333333, recall = 0.0031418140682846567.\n",
      "Training on epoch 46 minibatch 2401/5000 completed\n",
      " bpr_loss on current minibatch is 0.693849, and regularization loss is 0.000701.\n",
      " Top K precision = 0.016949152542372878, recall = 0.00797483781847173.\n",
      "Training on epoch 46 minibatch 2501/5000 completed\n",
      " bpr_loss on current minibatch is 0.693631, and regularization loss is 0.000484.\n",
      " Top K precision = 0.01833333333333333, recall = 0.006855101093347823.\n",
      "Training on epoch 46 minibatch 2601/5000 completed\n",
      " bpr_loss on current minibatch is 0.693801, and regularization loss is 0.000654.\n",
      " Top K precision = 0.00847457627118644, recall = 0.003073479366967324.\n",
      "Training on epoch 46 minibatch 2701/5000 completed\n",
      " bpr_loss on current minibatch is 0.693774, and regularization loss is 0.000627.\n",
      " Top K precision = 0.011864406779661016, recall = 0.009431159227422612.\n",
      "Training on epoch 46 minibatch 2801/5000 completed\n",
      " bpr_loss on current minibatch is 0.693958, and regularization loss is 0.000811.\n",
      " Top K precision = 0.011666666666666665, recall = 0.004955906404659386.\n",
      "Training on epoch 46 minibatch 2901/5000 completed\n",
      " bpr_loss on current minibatch is 0.693922, and regularization loss is 0.000775.\n",
      " Top K precision = 0.01, recall = 0.0033135004502979053.\n",
      "Training on epoch 46 minibatch 3001/5000 completed\n",
      " bpr_loss on current minibatch is 0.693801, and regularization loss is 0.000654.\n",
      " Top K precision = 0.013333333333333334, recall = 0.0054313321050048465.\n",
      "Training on epoch 46 minibatch 3101/5000 completed\n",
      " bpr_loss on current minibatch is 0.693768, and regularization loss is 0.00062.\n",
      " Top K precision = 0.014999999999999998, recall = 0.005457992538745893.\n",
      "Training on epoch 46 minibatch 3201/5000 completed\n",
      " bpr_loss on current minibatch is 0.693825, and regularization loss is 0.000678.\n",
      " Top K precision = 0.02033898305084746, recall = 0.008814662712967799.\n",
      "Training on epoch 46 minibatch 3301/5000 completed\n",
      " bpr_loss on current minibatch is 0.693785, and regularization loss is 0.000637.\n",
      " Top K precision = 0.023333333333333338, recall = 0.010849585967844374.\n",
      "Training on epoch 46 minibatch 3401/5000 completed\n",
      " bpr_loss on current minibatch is 0.693705, and regularization loss is 0.000558.\n",
      " Top K precision = 0.01, recall = 0.0062439874939874945.\n",
      "Training on epoch 46 minibatch 3501/5000 completed\n",
      " bpr_loss on current minibatch is 0.693732, and regularization loss is 0.000585.\n",
      " Top K precision = 0.005000000000000001, recall = 0.0017752849002849003.\n",
      "Training on epoch 46 minibatch 3601/5000 completed\n",
      " bpr_loss on current minibatch is 0.693646, and regularization loss is 0.000499.\n",
      " Top K precision = 0.005084745762711865, recall = 0.0038442643085237044.\n",
      "Training on epoch 46 minibatch 3701/5000 completed\n",
      " bpr_loss on current minibatch is 0.693871, and regularization loss is 0.000724.\n",
      " Top K precision = 0.014999999999999998, recall = 0.010110514485514484.\n",
      "Training on epoch 46 minibatch 3801/5000 completed\n",
      " bpr_loss on current minibatch is 0.693915, and regularization loss is 0.000768.\n",
      " Top K precision = 0.01, recall = 0.004914990421455939.\n",
      "Training on epoch 46 minibatch 3901/5000 completed\n",
      " bpr_loss on current minibatch is 0.69371, and regularization loss is 0.000563.\n",
      " Top K precision = 0.013333333333333332, recall = 0.00775055114638448.\n",
      "Training on epoch 46 minibatch 4001/5000 completed\n",
      " bpr_loss on current minibatch is 0.693801, and regularization loss is 0.000654.\n",
      " Top K precision = 0.015254237288135592, recall = 0.00815181999431311.\n",
      "Training on epoch 46 minibatch 4101/5000 completed\n",
      " bpr_loss on current minibatch is 0.693815, and regularization loss is 0.000667.\n",
      " Top K precision = 0.015000000000000001, recall = 0.007608101709332609.\n",
      "Training on epoch 46 minibatch 4201/5000 completed\n",
      " bpr_loss on current minibatch is 0.693874, and regularization loss is 0.000727.\n",
      " Top K precision = 0.006666666666666667, recall = 0.002456349206349206.\n",
      "Training on epoch 46 minibatch 4301/5000 completed\n",
      " bpr_loss on current minibatch is 0.693605, and regularization loss is 0.000458.\n",
      " Top K precision = 0.013559322033898305, recall = 0.00516930461661486.\n",
      "Training on epoch 46 minibatch 4401/5000 completed\n",
      " bpr_loss on current minibatch is 0.693708, and regularization loss is 0.000561.\n",
      " Top K precision = 0.013333333333333332, recall = 0.005386774769336777.\n",
      "Training on epoch 46 minibatch 4501/5000 completed\n",
      " bpr_loss on current minibatch is 0.693849, and regularization loss is 0.000702.\n",
      " Top K precision = 0.010169491525423728, recall = 0.00412863972186006.\n",
      "Training on epoch 46 minibatch 4601/5000 completed\n",
      " bpr_loss on current minibatch is 0.693828, and regularization loss is 0.000681.\n",
      " Top K precision = 0.013559322033898305, recall = 0.005970978265536239.\n",
      "Training on epoch 46 minibatch 4701/5000 completed\n",
      " bpr_loss on current minibatch is 0.693842, and regularization loss is 0.000694.\n",
      " Top K precision = 0.016949152542372878, recall = 0.006357970730501101.\n",
      "Training on epoch 46 minibatch 4801/5000 completed\n",
      " bpr_loss on current minibatch is 0.693842, and regularization loss is 0.000694.\n",
      " Top K precision = 0.025000000000000005, recall = 0.011822721343002584.\n",
      "Training on epoch 46 minibatch 4901/5000 completed\n",
      " bpr_loss on current minibatch is 0.693854, and regularization loss is 0.000707.\n",
      " Top K precision = 0.016666666666666666, recall = 0.0058664969427970285.\n",
      "\n",
      "Training on 46 epoch completed.\n",
      " Average bpr_loss on train set is 0.011563 for the current epoch.\n",
      " Training top K precision = 0.014100000000000097, recall = 0.006357071518960027.\n",
      " Average bpr_loss on the validation set is 2e-06, and regularization loss is 0.0.\n",
      " Validation top K precision = 0.015066666666666782, recall = 0.006624368757154834.\n",
      "\n",
      "Training on the 47 epoch\n",
      "Training on epoch 47 minibatch 1/5000 completed\n",
      " bpr_loss on current minibatch is 0.693786, and regularization loss is 0.000639.\n",
      " Top K precision = 0.01, recall = 0.003253413891344926.\n",
      "Training on epoch 47 minibatch 101/5000 completed\n",
      " bpr_loss on current minibatch is 0.69372, and regularization loss is 0.000573.\n",
      " Top K precision = 0.02, recall = 0.011308498534729433.\n",
      "Training on epoch 47 minibatch 201/5000 completed\n",
      " bpr_loss on current minibatch is 0.693599, and regularization loss is 0.000451.\n",
      " Top K precision = 0.014999999999999998, recall = 0.0068029365742398335.\n",
      "Training on epoch 47 minibatch 301/5000 completed\n",
      " bpr_loss on current minibatch is 0.693763, and regularization loss is 0.000616.\n",
      " Top K precision = 0.010169491525423728, recall = 0.003987820089515005.\n",
      "Training on epoch 47 minibatch 401/5000 completed\n",
      " bpr_loss on current minibatch is 0.693849, and regularization loss is 0.000701.\n",
      " Top K precision = 0.00847457627118644, recall = 0.003275737688570618.\n",
      "Training on epoch 47 minibatch 501/5000 completed\n",
      " bpr_loss on current minibatch is 0.693733, and regularization loss is 0.000586.\n",
      " Top K precision = 0.016666666666666666, recall = 0.008486906576420643.\n",
      "Training on epoch 47 minibatch 601/5000 completed\n",
      " bpr_loss on current minibatch is 0.693939, and regularization loss is 0.000792.\n",
      " Top K precision = 0.011666666666666665, recall = 0.0054525136421688155.\n",
      "Training on epoch 47 minibatch 701/5000 completed\n",
      " bpr_loss on current minibatch is 0.693678, and regularization loss is 0.000531.\n",
      " Top K precision = 0.011864406779661016, recall = 0.0043276226946637264.\n",
      "Training on epoch 47 minibatch 801/5000 completed\n",
      " bpr_loss on current minibatch is 0.693838, and regularization loss is 0.000691.\n",
      " Top K precision = 0.0033333333333333335, recall = 0.000940646528881823.\n",
      "Training on epoch 47 minibatch 901/5000 completed\n",
      " bpr_loss on current minibatch is 0.693672, and regularization loss is 0.000525.\n",
      " Top K precision = 0.0016949152542372883, recall = 0.00025297242600556537.\n",
      "Training on epoch 47 minibatch 1001/5000 completed\n",
      " bpr_loss on current minibatch is 0.693755, and regularization loss is 0.000608.\n",
      " Top K precision = 0.018965517241379314, recall = 0.007429651577014971.\n",
      "Training on epoch 47 minibatch 1101/5000 completed\n",
      " bpr_loss on current minibatch is 0.693811, and regularization loss is 0.000664.\n",
      " Top K precision = 0.006666666666666667, recall = 0.0034989316239316236.\n",
      "Training on epoch 47 minibatch 1201/5000 completed\n",
      " bpr_loss on current minibatch is 0.693696, and regularization loss is 0.000549.\n",
      " Top K precision = 0.011666666666666665, recall = 0.0042987501289209066.\n",
      "Training on epoch 47 minibatch 1301/5000 completed\n",
      " bpr_loss on current minibatch is 0.693747, and regularization loss is 0.0006.\n",
      " Top K precision = 0.014999999999999998, recall = 0.005460344716343168.\n",
      "Training on epoch 47 minibatch 1401/5000 completed\n",
      " bpr_loss on current minibatch is 0.693801, and regularization loss is 0.000654.\n",
      " Top K precision = 0.014999999999999998, recall = 0.0069204237654598945.\n",
      "Training on epoch 47 minibatch 1501/5000 completed\n",
      " bpr_loss on current minibatch is 0.693729, and regularization loss is 0.000582.\n",
      " Top K precision = 0.00847457627118644, recall = 0.003414255978930376.\n",
      "Training on epoch 47 minibatch 1601/5000 completed\n",
      " bpr_loss on current minibatch is 0.693732, and regularization loss is 0.000585.\n",
      " Top K precision = 0.005084745762711865, recall = 0.0024909246619117006.\n",
      "Training on epoch 47 minibatch 1701/5000 completed\n",
      " bpr_loss on current minibatch is 0.693875, and regularization loss is 0.000728.\n",
      " Top K precision = 0.005000000000000001, recall = 0.0020061728395061726.\n",
      "Training on epoch 47 minibatch 1801/5000 completed\n",
      " bpr_loss on current minibatch is 0.693887, and regularization loss is 0.00074.\n",
      " Top K precision = 0.011666666666666667, recall = 0.0034071480360793583.\n",
      "Training on epoch 47 minibatch 1901/5000 completed\n",
      " bpr_loss on current minibatch is 0.693735, and regularization loss is 0.000588.\n",
      " Top K precision = 0.01, recall = 0.005713495548502723.\n",
      "Training on epoch 47 minibatch 2001/5000 completed\n",
      " bpr_loss on current minibatch is 0.693866, and regularization loss is 0.000719.\n",
      " Top K precision = 0.00847457627118644, recall = 0.003687951630816584.\n",
      "Training on epoch 47 minibatch 2101/5000 completed\n",
      " bpr_loss on current minibatch is 0.69374, and regularization loss is 0.000593.\n",
      " Top K precision = 0.01833333333333333, recall = 0.006002579135270921.\n",
      "Training on epoch 47 minibatch 2201/5000 completed\n",
      " bpr_loss on current minibatch is 0.693956, and regularization loss is 0.000809.\n",
      " Top K precision = 0.008333333333333333, recall = 0.007222653554175293.\n",
      "Training on epoch 47 minibatch 2301/5000 completed\n",
      " bpr_loss on current minibatch is 0.693894, and regularization loss is 0.000747.\n",
      " Top K precision = 0.010344827586206896, recall = 0.00408357117451993.\n",
      "Training on epoch 47 minibatch 2401/5000 completed\n",
      " bpr_loss on current minibatch is 0.693826, and regularization loss is 0.000679.\n",
      " Top K precision = 0.01, recall = 0.004135711829677347.\n",
      "Training on epoch 47 minibatch 2501/5000 completed\n",
      " bpr_loss on current minibatch is 0.69368, and regularization loss is 0.000532.\n",
      " Top K precision = 0.011864406779661016, recall = 0.0036582161186136716.\n",
      "Training on epoch 47 minibatch 2601/5000 completed\n",
      " bpr_loss on current minibatch is 0.693792, and regularization loss is 0.000645.\n",
      " Top K precision = 0.016666666666666666, recall = 0.010112030649581908.\n",
      "Training on epoch 47 minibatch 2701/5000 completed\n",
      " bpr_loss on current minibatch is 0.693886, and regularization loss is 0.000738.\n",
      " Top K precision = 0.011666666666666665, recall = 0.005738705738705738.\n",
      "Training on epoch 47 minibatch 2801/5000 completed\n",
      " bpr_loss on current minibatch is 0.693775, and regularization loss is 0.000628.\n",
      " Top K precision = 0.01, recall = 0.003208689860863774.\n",
      "Training on epoch 47 minibatch 2901/5000 completed\n",
      " bpr_loss on current minibatch is 0.693881, and regularization loss is 0.000734.\n",
      " Top K precision = 0.016949152542372878, recall = 0.010622737383403661.\n",
      "Training on epoch 47 minibatch 3001/5000 completed\n",
      " bpr_loss on current minibatch is 0.693877, and regularization loss is 0.00073.\n",
      " Top K precision = 0.016949152542372878, recall = 0.007824515933372916.\n",
      "Training on epoch 47 minibatch 3101/5000 completed\n",
      " bpr_loss on current minibatch is 0.693854, and regularization loss is 0.000707.\n",
      " Top K precision = 0.00847457627118644, recall = 0.0029271018989363955.\n",
      "Training on epoch 47 minibatch 3201/5000 completed\n",
      " bpr_loss on current minibatch is 0.693856, and regularization loss is 0.000709.\n",
      " Top K precision = 0.011666666666666665, recall = 0.004425833988932484.\n",
      "Training on epoch 47 minibatch 3301/5000 completed\n",
      " bpr_loss on current minibatch is 0.693694, and regularization loss is 0.000547.\n",
      " Top K precision = 0.014999999999999998, recall = 0.006931952944883978.\n",
      "Training on epoch 47 minibatch 3401/5000 completed\n",
      " bpr_loss on current minibatch is 0.693774, and regularization loss is 0.000627.\n",
      " Top K precision = 0.011864406779661016, recall = 0.006439301799123972.\n",
      "Training on epoch 47 minibatch 3501/5000 completed\n",
      " bpr_loss on current minibatch is 0.693701, and regularization loss is 0.000554.\n",
      " Top K precision = 0.013333333333333332, recall = 0.005336962259400589.\n",
      "Training on epoch 47 minibatch 3601/5000 completed\n",
      " bpr_loss on current minibatch is 0.693803, and regularization loss is 0.000656.\n",
      " Top K precision = 0.008333333333333333, recall = 0.0035741267833298194.\n",
      "Training on epoch 47 minibatch 3701/5000 completed\n",
      " bpr_loss on current minibatch is 0.693707, and regularization loss is 0.00056.\n",
      " Top K precision = 0.013333333333333332, recall = 0.004725864413364414.\n",
      "Training on epoch 47 minibatch 3801/5000 completed\n",
      " bpr_loss on current minibatch is 0.693763, and regularization loss is 0.000616.\n",
      " Top K precision = 0.013559322033898305, recall = 0.004967497563394085.\n",
      "Training on epoch 47 minibatch 3901/5000 completed\n",
      " bpr_loss on current minibatch is 0.693864, and regularization loss is 0.000717.\n",
      " Top K precision = 0.015254237288135592, recall = 0.008201842790767662.\n",
      "Training on epoch 47 minibatch 4001/5000 completed\n",
      " bpr_loss on current minibatch is 0.693989, and regularization loss is 0.000842.\n",
      " Top K precision = 0.013559322033898305, recall = 0.0083698653413194.\n",
      "Training on epoch 47 minibatch 4101/5000 completed\n",
      " bpr_loss on current minibatch is 0.6938, and regularization loss is 0.000653.\n",
      " Top K precision = 0.013333333333333332, recall = 0.004431515075738631.\n",
      "Training on epoch 47 minibatch 4201/5000 completed\n",
      " bpr_loss on current minibatch is 0.69376, and regularization loss is 0.000613.\n",
      " Top K precision = 0.010344827586206896, recall = 0.005257752305166099.\n",
      "Training on epoch 47 minibatch 4301/5000 completed\n",
      " bpr_loss on current minibatch is 0.693746, and regularization loss is 0.000599.\n",
      " Top K precision = 0.013559322033898305, recall = 0.004729971046673115.\n",
      "Training on epoch 47 minibatch 4401/5000 completed\n",
      " bpr_loss on current minibatch is 0.693799, and regularization loss is 0.000651.\n",
      " Top K precision = 0.00847457627118644, recall = 0.0036098481578467766.\n",
      "Training on epoch 47 minibatch 4501/5000 completed\n",
      " bpr_loss on current minibatch is 0.693747, and regularization loss is 0.000599.\n",
      " Top K precision = 0.011666666666666665, recall = 0.004198543969975798.\n",
      "Training on epoch 47 minibatch 4601/5000 completed\n",
      " bpr_loss on current minibatch is 0.693812, and regularization loss is 0.000665.\n",
      " Top K precision = 0.011864406779661016, recall = 0.005376548924654609.\n",
      "Training on epoch 47 minibatch 4701/5000 completed\n",
      " bpr_loss on current minibatch is 0.693884, and regularization loss is 0.000737.\n",
      " Top K precision = 0.013333333333333332, recall = 0.00654463126358029.\n",
      "Training on epoch 47 minibatch 4801/5000 completed\n",
      " bpr_loss on current minibatch is 0.693768, and regularization loss is 0.000621.\n",
      " Top K precision = 0.006896551724137932, recall = 0.002616468780261884.\n",
      "Training on epoch 47 minibatch 4901/5000 completed\n",
      " bpr_loss on current minibatch is 0.69386, and regularization loss is 0.000713.\n",
      " Top K precision = 0.0033898305084745766, recall = 0.0011815514993481096.\n",
      "\n",
      "Training on 47 epoch completed.\n",
      " Average bpr_loss on train set is 0.011563 for the current epoch.\n",
      " Training top K precision = 0.014366666666666767, recall = 0.006394498200810882.\n",
      " Average bpr_loss on the validation set is 2e-06, and regularization loss is 0.0.\n",
      " Validation top K precision = 0.014733333333333437, recall = 0.0067871568298215465.\n",
      "\n",
      "Training on the 48 epoch\n",
      "Training on epoch 48 minibatch 1/5000 completed\n",
      " bpr_loss on current minibatch is 0.693939, and regularization loss is 0.000791.\n",
      " Top K precision = 0.013793103448275864, recall = 0.005865966728035694.\n",
      "Training on epoch 48 minibatch 101/5000 completed\n",
      " bpr_loss on current minibatch is 0.693807, and regularization loss is 0.000659.\n",
      " Top K precision = 0.011666666666666665, recall = 0.005822091471828374.\n",
      "Training on epoch 48 minibatch 201/5000 completed\n",
      " bpr_loss on current minibatch is 0.693805, and regularization loss is 0.000658.\n",
      " Top K precision = 0.013333333333333332, recall = 0.005433774744920255.\n",
      "Training on epoch 48 minibatch 301/5000 completed\n",
      " bpr_loss on current minibatch is 0.693787, and regularization loss is 0.00064.\n",
      " Top K precision = 0.013559322033898305, recall = 0.005306669277880645.\n",
      "Training on epoch 48 minibatch 401/5000 completed\n",
      " bpr_loss on current minibatch is 0.693792, and regularization loss is 0.000645.\n",
      " Top K precision = 0.011666666666666665, recall = 0.0076569410122041695.\n",
      "Training on epoch 48 minibatch 501/5000 completed\n",
      " bpr_loss on current minibatch is 0.693854, and regularization loss is 0.000707.\n",
      " Top K precision = 0.016666666666666666, recall = 0.008051847763710849.\n",
      "Training on epoch 48 minibatch 601/5000 completed\n",
      " bpr_loss on current minibatch is 0.693693, and regularization loss is 0.000546.\n",
      " Top K precision = 0.006779661016949153, recall = 0.0024679639111163778.\n",
      "Training on epoch 48 minibatch 701/5000 completed\n",
      " bpr_loss on current minibatch is 0.693843, and regularization loss is 0.000696.\n",
      " Top K precision = 0.01, recall = 0.004613650238650239.\n",
      "Training on epoch 48 minibatch 801/5000 completed\n",
      " bpr_loss on current minibatch is 0.693762, and regularization loss is 0.000615.\n",
      " Top K precision = 0.008333333333333333, recall = 0.0034821605409840707.\n",
      "Training on epoch 48 minibatch 901/5000 completed\n",
      " bpr_loss on current minibatch is 0.693839, and regularization loss is 0.000692.\n",
      " Top K precision = 0.01833333333333333, recall = 0.006969990488259762.\n",
      "Training on epoch 48 minibatch 1001/5000 completed\n",
      " bpr_loss on current minibatch is 0.693719, and regularization loss is 0.000571.\n",
      " Top K precision = 0.0033898305084745766, recall = 0.0012429378531073447.\n",
      "Training on epoch 48 minibatch 1101/5000 completed\n",
      " bpr_loss on current minibatch is 0.693906, and regularization loss is 0.000759.\n",
      " Top K precision = 0.01, recall = 0.0036747147689485155.\n",
      "Training on epoch 48 minibatch 1201/5000 completed\n",
      " bpr_loss on current minibatch is 0.693662, and regularization loss is 0.000515.\n",
      " Top K precision = 0.006666666666666667, recall = 0.00406084656084656.\n",
      "Training on epoch 48 minibatch 1301/5000 completed\n",
      " bpr_loss on current minibatch is 0.69364, and regularization loss is 0.000493.\n",
      " Top K precision = 0.01833333333333333, recall = 0.010695253155741661.\n",
      "Training on epoch 48 minibatch 1401/5000 completed\n",
      " bpr_loss on current minibatch is 0.693903, and regularization loss is 0.000756.\n",
      " Top K precision = 0.02, recall = 0.008435520797679792.\n",
      "Training on epoch 48 minibatch 1501/5000 completed\n",
      " bpr_loss on current minibatch is 0.693741, and regularization loss is 0.000593.\n",
      " Top K precision = 0.008333333333333333, recall = 0.003684556184556184.\n",
      "Training on epoch 48 minibatch 1601/5000 completed\n",
      " bpr_loss on current minibatch is 0.693711, and regularization loss is 0.000564.\n",
      " Top K precision = 0.010169491525423728, recall = 0.005669079821622194.\n",
      "Training on epoch 48 minibatch 1701/5000 completed\n",
      " bpr_loss on current minibatch is 0.693868, and regularization loss is 0.000721.\n",
      " Top K precision = 0.006779661016949153, recall = 0.005368814192343604.\n",
      "Training on epoch 48 minibatch 1801/5000 completed\n",
      " bpr_loss on current minibatch is 0.69377, and regularization loss is 0.000623.\n",
      " Top K precision = 0.016949152542372878, recall = 0.006256420133538778.\n",
      "Training on epoch 48 minibatch 1901/5000 completed\n",
      " bpr_loss on current minibatch is 0.693768, and regularization loss is 0.000621.\n",
      " Top K precision = 0.011864406779661016, recall = 0.005155457318176479.\n",
      "Training on epoch 48 minibatch 2001/5000 completed\n",
      " bpr_loss on current minibatch is 0.693684, and regularization loss is 0.000536.\n",
      " Top K precision = 0.0016949152542372883, recall = 0.0004985044865403788.\n",
      "Training on epoch 48 minibatch 2101/5000 completed\n",
      " bpr_loss on current minibatch is 0.693717, and regularization loss is 0.000569.\n",
      " Top K precision = 0.015254237288135592, recall = 0.007025382443168357.\n",
      "Training on epoch 48 minibatch 2201/5000 completed\n",
      " bpr_loss on current minibatch is 0.693667, and regularization loss is 0.00052.\n",
      " Top K precision = 0.010169491525423728, recall = 0.0034207489681358457.\n",
      "Training on epoch 48 minibatch 2301/5000 completed\n",
      " bpr_loss on current minibatch is 0.693803, and regularization loss is 0.000656.\n",
      " Top K precision = 0.00847457627118644, recall = 0.006189008731381612.\n",
      "Training on epoch 48 minibatch 2401/5000 completed\n",
      " bpr_loss on current minibatch is 0.693802, and regularization loss is 0.000655.\n",
      " Top K precision = 0.005084745762711865, recall = 0.003649141267992033.\n",
      "Training on epoch 48 minibatch 2501/5000 completed\n",
      " bpr_loss on current minibatch is 0.693763, and regularization loss is 0.000616.\n",
      " Top K precision = 0.006666666666666667, recall = 0.0021629072681704263.\n",
      "Training on epoch 48 minibatch 2601/5000 completed\n",
      " bpr_loss on current minibatch is 0.693863, and regularization loss is 0.000716.\n",
      " Top K precision = 0.017857142857142856, recall = 0.007007677450632859.\n",
      "Training on epoch 48 minibatch 2701/5000 completed\n",
      " bpr_loss on current minibatch is 0.693779, and regularization loss is 0.000632.\n",
      " Top K precision = 0.008333333333333333, recall = 0.005102513227513228.\n",
      "Training on epoch 48 minibatch 2801/5000 completed\n",
      " bpr_loss on current minibatch is 0.693701, and regularization loss is 0.000553.\n",
      " Top K precision = 0.011666666666666665, recall = 0.005475575233985768.\n",
      "Training on epoch 48 minibatch 2901/5000 completed\n",
      " bpr_loss on current minibatch is 0.693716, and regularization loss is 0.000569.\n",
      " Top K precision = 0.014999999999999998, recall = 0.0068217260322523485.\n",
      "Training on epoch 48 minibatch 3001/5000 completed\n",
      " bpr_loss on current minibatch is 0.693714, and regularization loss is 0.000567.\n",
      " Top K precision = 0.006666666666666667, recall = 0.0018258034087952123.\n",
      "Training on epoch 48 minibatch 3101/5000 completed\n",
      " bpr_loss on current minibatch is 0.693868, and regularization loss is 0.00072.\n",
      " Top K precision = 0.00847457627118644, recall = 0.0042582719482226914.\n",
      "Training on epoch 48 minibatch 3201/5000 completed\n",
      " bpr_loss on current minibatch is 0.693793, and regularization loss is 0.000646.\n",
      " Top K precision = 0.011864406779661016, recall = 0.004038028154250915.\n",
      "Training on epoch 48 minibatch 3301/5000 completed\n",
      " bpr_loss on current minibatch is 0.693981, and regularization loss is 0.000834.\n",
      " Top K precision = 0.01, recall = 0.004274743008234125.\n",
      "Training on epoch 48 minibatch 3401/5000 completed\n",
      " bpr_loss on current minibatch is 0.6938, and regularization loss is 0.000653.\n",
      " Top K precision = 0.013559322033898305, recall = 0.005955288126633709.\n",
      "Training on epoch 48 minibatch 3501/5000 completed\n",
      " bpr_loss on current minibatch is 0.693909, and regularization loss is 0.000761.\n",
      " Top K precision = 0.011864406779661016, recall = 0.005976707733132008.\n",
      "Training on epoch 48 minibatch 3601/5000 completed\n",
      " bpr_loss on current minibatch is 0.693835, and regularization loss is 0.000687.\n",
      " Top K precision = 0.015000000000000001, recall = 0.0071512864260722285.\n",
      "Training on epoch 48 minibatch 3701/5000 completed\n",
      " bpr_loss on current minibatch is 0.693749, and regularization loss is 0.000602.\n",
      " Top K precision = 0.005000000000000001, recall = 0.001461301044634378.\n",
      "Training on epoch 48 minibatch 3801/5000 completed\n",
      " bpr_loss on current minibatch is 0.693746, and regularization loss is 0.000598.\n",
      " Top K precision = 0.011666666666666667, recall = 0.004299888611501187.\n",
      "Training on epoch 48 minibatch 3901/5000 completed\n",
      " bpr_loss on current minibatch is 0.693661, and regularization loss is 0.000513.\n",
      " Top K precision = 0.015517241379310343, recall = 0.006104167135418352.\n",
      "Training on epoch 48 minibatch 4001/5000 completed\n",
      " bpr_loss on current minibatch is 0.693754, and regularization loss is 0.000607.\n",
      " Top K precision = 0.011666666666666667, recall = 0.0049177211677211684.\n",
      "Training on epoch 48 minibatch 4101/5000 completed\n",
      " bpr_loss on current minibatch is 0.693791, and regularization loss is 0.000644.\n",
      " Top K precision = 0.013559322033898305, recall = 0.006017906746577321.\n",
      "Training on epoch 48 minibatch 4201/5000 completed\n",
      " bpr_loss on current minibatch is 0.693772, and regularization loss is 0.000624.\n",
      " Top K precision = 0.01833333333333333, recall = 0.008113615191104673.\n",
      "Training on epoch 48 minibatch 4301/5000 completed\n",
      " bpr_loss on current minibatch is 0.693832, and regularization loss is 0.000685.\n",
      " Top K precision = 0.006779661016949153, recall = 0.002856831700395423.\n",
      "Training on epoch 48 minibatch 4401/5000 completed\n",
      " bpr_loss on current minibatch is 0.693671, and regularization loss is 0.000524.\n",
      " Top K precision = 0.013559322033898305, recall = 0.005780562644969424.\n",
      "Training on epoch 48 minibatch 4501/5000 completed\n",
      " bpr_loss on current minibatch is 0.69378, and regularization loss is 0.000633.\n",
      " Top K precision = 0.016666666666666666, recall = 0.005431378073383684.\n",
      "Training on epoch 48 minibatch 4601/5000 completed\n",
      " bpr_loss on current minibatch is 0.694149, and regularization loss is 0.001002.\n",
      " Top K precision = 0.013333333333333332, recall = 0.007336671377418406.\n",
      "Training on epoch 48 minibatch 4701/5000 completed\n",
      " bpr_loss on current minibatch is 0.693797, and regularization loss is 0.00065.\n",
      " Top K precision = 0.008333333333333333, recall = 0.005133169934640523.\n",
      "Training on epoch 48 minibatch 4801/5000 completed\n",
      " bpr_loss on current minibatch is 0.693887, and regularization loss is 0.000739.\n",
      " Top K precision = 0.00847457627118644, recall = 0.004835371784524326.\n",
      "Training on epoch 48 minibatch 4901/5000 completed\n",
      " bpr_loss on current minibatch is 0.693864, and regularization loss is 0.000717.\n",
      " Top K precision = 0.008333333333333333, recall = 0.006370603797074385.\n",
      "\n",
      "Training on 48 epoch completed.\n",
      " Average bpr_loss on train set is 0.011563 for the current epoch.\n",
      " Training top K precision = 0.014833333333333445, recall = 0.0067069250426814025.\n",
      " Average bpr_loss on the validation set is 2e-06, and regularization loss is 0.0.\n",
      " Validation top K precision = 0.01483333333333344, recall = 0.006485438634565351.\n",
      "\n",
      "Training on the 49 epoch\n",
      "Training on epoch 49 minibatch 1/5000 completed\n",
      " bpr_loss on current minibatch is 0.693682, and regularization loss is 0.000535.\n",
      " Top K precision = 0.010169491525423728, recall = 0.004117281024060685.\n",
      "Training on epoch 49 minibatch 101/5000 completed\n",
      " bpr_loss on current minibatch is 0.693648, and regularization loss is 0.000501.\n",
      " Top K precision = 0.011666666666666665, recall = 0.0066999124064341465.\n",
      "Training on epoch 49 minibatch 201/5000 completed\n",
      " bpr_loss on current minibatch is 0.693979, and regularization loss is 0.000831.\n",
      " Top K precision = 0.008333333333333333, recall = 0.004146615658243565.\n",
      "Training on epoch 49 minibatch 301/5000 completed\n",
      " bpr_loss on current minibatch is 0.693807, and regularization loss is 0.00066.\n",
      " Top K precision = 0.016949152542372878, recall = 0.008645107230348508.\n",
      "Training on epoch 49 minibatch 401/5000 completed\n",
      " bpr_loss on current minibatch is 0.693774, and regularization loss is 0.000627.\n",
      " Top K precision = 0.014999999999999998, recall = 0.005276159039132391.\n",
      "Training on epoch 49 minibatch 501/5000 completed\n",
      " bpr_loss on current minibatch is 0.693887, and regularization loss is 0.00074.\n",
      " Top K precision = 0.021666666666666667, recall = 0.009475554448142166.\n",
      "Training on epoch 49 minibatch 601/5000 completed\n",
      " bpr_loss on current minibatch is 0.693721, and regularization loss is 0.000574.\n",
      " Top K precision = 0.014999999999999998, recall = 0.008563056798350916.\n",
      "Training on epoch 49 minibatch 701/5000 completed\n",
      " bpr_loss on current minibatch is 0.693843, and regularization loss is 0.000695.\n",
      " Top K precision = 0.006779661016949153, recall = 0.0030785786717990107.\n",
      "Training on epoch 49 minibatch 801/5000 completed\n",
      " bpr_loss on current minibatch is 0.693772, and regularization loss is 0.000624.\n",
      " Top K precision = 0.01, recall = 0.005868412118412118.\n",
      "Training on epoch 49 minibatch 901/5000 completed\n",
      " bpr_loss on current minibatch is 0.693807, and regularization loss is 0.00066.\n",
      " Top K precision = 0.0016949152542372883, recall = 0.00048426150121065375.\n",
      "Training on epoch 49 minibatch 1001/5000 completed\n",
      " bpr_loss on current minibatch is 0.693706, and regularization loss is 0.000559.\n",
      " Top K precision = 0.005000000000000001, recall = 0.00258008008008008.\n",
      "Training on epoch 49 minibatch 1101/5000 completed\n",
      " bpr_loss on current minibatch is 0.693643, and regularization loss is 0.000496.\n",
      " Top K precision = 0.013333333333333332, recall = 0.008030486883938447.\n",
      "Training on epoch 49 minibatch 1201/5000 completed\n",
      " bpr_loss on current minibatch is 0.693624, and regularization loss is 0.000477.\n",
      " Top K precision = 0.010169491525423728, recall = 0.006098759997065082.\n",
      "Training on epoch 49 minibatch 1301/5000 completed\n",
      " bpr_loss on current minibatch is 0.693672, and regularization loss is 0.000525.\n",
      " Top K precision = 0.011864406779661016, recall = 0.0046975448993080305.\n",
      "Training on epoch 49 minibatch 1401/5000 completed\n",
      " bpr_loss on current minibatch is 0.693758, and regularization loss is 0.000611.\n",
      " Top K precision = 0.013333333333333332, recall = 0.00471067821067821.\n",
      "Training on epoch 49 minibatch 1501/5000 completed\n",
      " bpr_loss on current minibatch is 0.693725, and regularization loss is 0.000578.\n",
      " Top K precision = 0.016666666666666666, recall = 0.00883634414590838.\n",
      "Training on epoch 49 minibatch 1601/5000 completed\n",
      " bpr_loss on current minibatch is 0.693757, and regularization loss is 0.000609.\n",
      " Top K precision = 0.023333333333333338, recall = 0.011825802193449251.\n",
      "Training on epoch 49 minibatch 1701/5000 completed\n",
      " bpr_loss on current minibatch is 0.694014, and regularization loss is 0.000867.\n",
      " Top K precision = 0.010169491525423728, recall = 0.0027635170407804385.\n",
      "Training on epoch 49 minibatch 1801/5000 completed\n",
      " bpr_loss on current minibatch is 0.693755, and regularization loss is 0.000608.\n",
      " Top K precision = 0.011666666666666665, recall = 0.00430814928229738.\n",
      "Training on epoch 49 minibatch 1901/5000 completed\n",
      " bpr_loss on current minibatch is 0.693796, and regularization loss is 0.000649.\n",
      " Top K precision = 0.016666666666666666, recall = 0.005249377235592775.\n",
      "Training on epoch 49 minibatch 2001/5000 completed\n",
      " bpr_loss on current minibatch is 0.693823, and regularization loss is 0.000675.\n",
      " Top K precision = 0.008333333333333333, recall = 0.0023860174912806492.\n",
      "Training on epoch 49 minibatch 2101/5000 completed\n",
      " bpr_loss on current minibatch is 0.693771, and regularization loss is 0.000624.\n",
      " Top K precision = 0.012068965517241381, recall = 0.005248923525853173.\n",
      "Training on epoch 49 minibatch 2201/5000 completed\n",
      " bpr_loss on current minibatch is 0.69388, and regularization loss is 0.000732.\n",
      " Top K precision = 0.01833333333333333, recall = 0.007107141834794083.\n",
      "Training on epoch 49 minibatch 2301/5000 completed\n",
      " bpr_loss on current minibatch is 0.693703, and regularization loss is 0.000556.\n",
      " Top K precision = 0.010169491525423728, recall = 0.003969602579425285.\n",
      "Training on epoch 49 minibatch 2401/5000 completed\n",
      " bpr_loss on current minibatch is 0.693693, and regularization loss is 0.000546.\n",
      " Top K precision = 0.01, recall = 0.004729166666666667.\n",
      "Training on epoch 49 minibatch 2501/5000 completed\n",
      " bpr_loss on current minibatch is 0.693601, and regularization loss is 0.000454.\n",
      " Top K precision = 0.01206896551724138, recall = 0.005258052835579861.\n",
      "Training on epoch 49 minibatch 2601/5000 completed\n",
      " bpr_loss on current minibatch is 0.693825, and regularization loss is 0.000677.\n",
      " Top K precision = 0.01, recall = 0.004747641549112137.\n",
      "Training on epoch 49 minibatch 2701/5000 completed\n",
      " bpr_loss on current minibatch is 0.693968, and regularization loss is 0.000821.\n",
      " Top K precision = 0.013333333333333332, recall = 0.005657513741716777.\n",
      "Training on epoch 49 minibatch 2801/5000 completed\n",
      " bpr_loss on current minibatch is 0.693711, and regularization loss is 0.000564.\n",
      " Top K precision = 0.01, recall = 0.006321330301593459.\n",
      "Training on epoch 49 minibatch 2901/5000 completed\n",
      " bpr_loss on current minibatch is 0.69362, and regularization loss is 0.000472.\n",
      " Top K precision = 0.011864406779661016, recall = 0.005315201782706067.\n",
      "Training on epoch 49 minibatch 3001/5000 completed\n",
      " bpr_loss on current minibatch is 0.693645, and regularization loss is 0.000498.\n",
      " Top K precision = 0.01, recall = 0.0036985887261453704.\n",
      "Training on epoch 49 minibatch 3101/5000 completed\n",
      " bpr_loss on current minibatch is 0.693786, and regularization loss is 0.000639.\n",
      " Top K precision = 0.006666666666666667, recall = 0.003063749116380695.\n",
      "Training on epoch 49 minibatch 3201/5000 completed\n",
      " bpr_loss on current minibatch is 0.693766, and regularization loss is 0.000619.\n",
      " Top K precision = 0.016666666666666666, recall = 0.006661723411723412.\n",
      "Training on epoch 49 minibatch 3301/5000 completed\n",
      " bpr_loss on current minibatch is 0.693853, and regularization loss is 0.000705.\n",
      " Top K precision = 0.006779661016949153, recall = 0.00240598801601839.\n",
      "Training on epoch 49 minibatch 3401/5000 completed\n",
      " bpr_loss on current minibatch is 0.693723, and regularization loss is 0.000575.\n",
      " Top K precision = 0.005084745762711865, recall = 0.002494170926374316.\n",
      "Training on epoch 49 minibatch 3501/5000 completed\n",
      " bpr_loss on current minibatch is 0.693886, and regularization loss is 0.000739.\n",
      " Top K precision = 0.006666666666666667, recall = 0.0022180250305250306.\n",
      "Training on epoch 49 minibatch 3601/5000 completed\n",
      " bpr_loss on current minibatch is 0.69371, and regularization loss is 0.000562.\n",
      " Top K precision = 0.011864406779661016, recall = 0.0037430757271235842.\n",
      "Training on epoch 49 minibatch 3701/5000 completed\n",
      " bpr_loss on current minibatch is 0.693766, and regularization loss is 0.000619.\n",
      " Top K precision = 0.015517241379310343, recall = 0.0076810222823153855.\n",
      "Training on epoch 49 minibatch 3801/5000 completed\n",
      " bpr_loss on current minibatch is 0.693827, and regularization loss is 0.00068.\n",
      " Top K precision = 0.008333333333333333, recall = 0.0049174974649357946.\n",
      "Training on epoch 49 minibatch 3901/5000 completed\n",
      " bpr_loss on current minibatch is 0.693803, and regularization loss is 0.000656.\n",
      " Top K precision = 0.015254237288135592, recall = 0.009056448886957362.\n",
      "Training on epoch 49 minibatch 4001/5000 completed\n",
      " bpr_loss on current minibatch is 0.693892, and regularization loss is 0.000745.\n",
      " Top K precision = 0.025, recall = 0.010395189711551267.\n",
      "Training on epoch 49 minibatch 4101/5000 completed\n",
      " bpr_loss on current minibatch is 0.69373, and regularization loss is 0.000583.\n",
      " Top K precision = 0.01864406779661017, recall = 0.0074836339424394095.\n",
      "Training on epoch 49 minibatch 4201/5000 completed\n",
      " bpr_loss on current minibatch is 0.693768, and regularization loss is 0.000621.\n",
      " Top K precision = 0.011864406779661016, recall = 0.006598807317304002.\n",
      "Training on epoch 49 minibatch 4301/5000 completed\n",
      " bpr_loss on current minibatch is 0.69372, and regularization loss is 0.000573.\n",
      " Top K precision = 0.008333333333333333, recall = 0.003847802524273113.\n",
      "Training on epoch 49 minibatch 4401/5000 completed\n",
      " bpr_loss on current minibatch is 0.693892, and regularization loss is 0.000745.\n",
      " Top K precision = 0.01833333333333333, recall = 0.006875261677893257.\n",
      "Training on epoch 49 minibatch 4501/5000 completed\n",
      " bpr_loss on current minibatch is 0.693711, and regularization loss is 0.000564.\n",
      " Top K precision = 0.013333333333333332, recall = 0.007502698211901249.\n",
      "Training on epoch 49 minibatch 4601/5000 completed\n",
      " bpr_loss on current minibatch is 0.693701, and regularization loss is 0.000554.\n",
      " Top K precision = 0.00847457627118644, recall = 0.004112130382739122.\n",
      "Training on epoch 49 minibatch 4701/5000 completed\n",
      " bpr_loss on current minibatch is 0.693826, and regularization loss is 0.000679.\n",
      " Top K precision = 0.013559322033898306, recall = 0.006519726628313571.\n",
      "Training on epoch 49 minibatch 4801/5000 completed\n",
      " bpr_loss on current minibatch is 0.693981, and regularization loss is 0.000833.\n",
      " Top K precision = 0.006779661016949153, recall = 0.0028349195589410427.\n",
      "Training on epoch 49 minibatch 4901/5000 completed\n",
      " bpr_loss on current minibatch is 0.693759, and regularization loss is 0.000612.\n",
      " Top K precision = 0.005000000000000001, recall = 0.0012566137566137566.\n",
      "\n",
      "Training on 49 epoch completed.\n",
      " Average bpr_loss on train set is 0.011563 for the current epoch.\n",
      " Training top K precision = 0.013933333333333431, recall = 0.006197469554035128.\n",
      " Average bpr_loss on the validation set is 2e-06, and regularization loss is 0.0.\n",
      " Validation top K precision = 0.014433333333333435, recall = 0.006486667855767885.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "epochs_tracked = []\n",
    "train_topks = []\n",
    "val_topks = []\n",
    "bprs = []\n",
    "K = config_dict[\"K\"]\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(\"Training on the {} epoch\".format(epoch))\n",
    "    lightGCN.train()\n",
    "    loss_sum = 0\n",
    "    # Shuffle the order of rows.\n",
    "    samples_train = samples_train[torch.randperm(samples_train.size()[0])]\n",
    "    for batch_idx in range(math.ceil(len(samples_train) / batch_size)):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        current_batch = \\\n",
    "            samples_train[batch_idx*batch_size: (batch_idx+1)*batch_size]\n",
    "        # Shuffle the order of rows.\n",
    "        current_batch = current_batch[torch.randperm(current_batch.size()[0])]\n",
    "        users = current_batch[:, 0:1]\n",
    "        pos = current_batch[:, 1:2]\n",
    "        neg = current_batch[:, 2:3]\n",
    "\n",
    "        loss, reg_loss = bpr_loss(lightGCN, users, pos, neg, mov,\n",
    "                                  train_mask)\n",
    "        reg_loss = reg_loss * weight_decay\n",
    "        loss = loss + reg_loss\n",
    "        loss_sum += loss.detach()\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch_idx % config_dict[\"minibatch_per_print\"] == 0:\n",
    "            all_users = torch.linspace(start=0,\n",
    "                                       end=n_users - 1, steps=n_users).long()\n",
    "            user_indices = current_batch[:, 0]\n",
    "            user_indices = user_indices.repeat(2).long()\n",
    "            item_indices = torch.cat(\n",
    "                (current_batch[:, 1], current_batch[:, 2])).long()\n",
    "            pred = getUsersRating(lightGCN,\n",
    "                                  all_users,\n",
    "                                  mov)[user_indices, item_indices]\n",
    "            truth = global_edge_index[user_indices, item_indices]\n",
    "            topk_precision, topk_recall = \\\n",
    "                personalized_topk(pred, K, user_indices, global_edge_index)\n",
    "\n",
    "            print(\"Training on epoch {} minibatch {}/{} completed\\n\".format(epoch, batch_idx+1,\n",
    "                                                                            math.ceil(len(samples_train) / batch_size)),\n",
    "                  \"bpr_loss on current minibatch is {}, and regularization loss is {}.\\n\".format(round(float(loss.detach().cpu()), 6),\n",
    "                                                                                                 round(float(reg_loss.detach().cpu()), 6)),\n",
    "                  \"Top K precision = {}, recall = {}.\".format(topk_precision, topk_recall))\n",
    "\n",
    "    if epoch % config_dict[\"epochs_per_print\"] == 0:\n",
    "        epochs_tracked.append(epoch)\n",
    "\n",
    "        # evaluation on both the trainisng and validation set\n",
    "        lightGCN.eval()\n",
    "        # predict on the training set\n",
    "        users = samples_train[:, 0:1]\n",
    "        user_indices = samples_train[:, 0]\n",
    "        user_indices = user_indices.repeat(2).long()\n",
    "        item_indices = torch.cat(\n",
    "            (samples_train[:, 1], samples_train[:, 2])).long()\n",
    "        pred = getUsersRating(lightGCN,\n",
    "                              users[:,0],\n",
    "                              mov)[user_indices, item_indices]\n",
    "        truth = global_edge_index[users.long()[:,0]]\\\n",
    "            [user_indices, item_indices]\n",
    "        train_topk_precision, train_topk_recall = \\\n",
    "            personalized_topk(pred, K, user_indices, global_edge_index)\n",
    "        train_topks.append((train_topk_precision, train_topk_recall))\n",
    "\n",
    "        # predict on the validation set\n",
    "        users_val = samples_val[:, 0:1]\n",
    "        pos_val = samples_val[:, 1:2]\n",
    "        neg_val = samples_val[:, 2:3]\n",
    "\n",
    "        loss_val, reg_loss_val = bpr_loss(\n",
    "            lightGCN, users_val, pos_val, neg_val, mov, val_mask)\n",
    "        bprs.append(round(float((loss_val+reg_loss_val)/len(samples_val)), 6))\n",
    "        reg_loss_val = reg_loss_val * weight_decay\n",
    "\n",
    "        # predict on the validation set\n",
    "        user_indices = samples_val[:, 0]\n",
    "        user_indices = user_indices.repeat(2).long()\n",
    "        item_indices = torch.cat((samples_val[:, 1], samples_val[:, 2])).long()\n",
    "        pred_val = getUsersRating(lightGCN,\n",
    "                                  users_val[:,0],\n",
    "                                  mov)[user_indices, item_indices]\n",
    "        truth_val = global_edge_index[users_val.long()[:,0]]\\\n",
    "            [user_indices, item_indices]\n",
    "        val_topk_precision, val_topk_recall = \\\n",
    "            personalized_topk(pred_val, K, user_indices, global_edge_index)\n",
    "        val_topks.append((val_topk_precision, val_topk_recall))\n",
    "\n",
    "        print(\"\\nTraining on {} epoch completed.\\n\".format(epoch),\n",
    "              \"Average bpr_loss on train set is {} for the current epoch.\\n\".format(round(float(loss_sum/len(samples_train)), 6)),\n",
    "              \"Training top K precision = {}, recall = {}.\\n\".format(train_topk_precision, train_topk_recall),\n",
    "              \"Average bpr_loss on the validation set is {}, and regularization loss is {}.\\n\".format(round(float((loss_val+reg_loss_val)/len(samples_val)), 6),\n",
    "                                                                                                      round(float(reg_loss_val/len(samples_val)), 6)),\n",
    "              \"Validation top K precision = {}, recall = {}.\\n\".format(val_topk_precision, val_topk_recall))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e5740ad-ce2c-44cd-853f-dac2bad6e06d",
   "metadata": {},
   "source": [
    "# Plot Top K over epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9f940387-40e0-4216-8597-c072f804d54f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(epochs_tracked, [precision for precision, _ in train_topks],\n",
    "         label=\"Train\")\n",
    "plt.plot(epochs_tracked, [precision for precision, _ in val_topks],\n",
    "         label=\"Val\")\n",
    "#plt.plot(epochs_tracked, [loss for loss in bprs],\n",
    "#         label=\"BPR Loss\")\n",
    "plt.ylabel(f\"Top {K} precision\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.legend()\n",
    "plt.title(\"Top 10 Precision for LightGCN-Att on Douban (100 samples/user)\")\n",
    "plt.show()\n",
    "\n",
    "plt.plot(epochs_tracked, [loss for loss in bprs],\n",
    "         label=\"BPR Loss\")\n",
    "plt.ylabel(f\"Loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "362ce4f8-dafb-4874-949e-b4f5f7bb3b33",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "db294ae3-07df-4550-a387-fd4100a09696",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training completed after 50 epochs\n",
      "Average bpr_loss on the test set is 2e-06, and regularization loss is 0.0.\n",
      " Top K precision = 0.01396666666666676, recall = 0.0059278283357094225.\n"
     ]
    }
   ],
   "source": [
    "# predict on the test set\n",
    "lightGCN.eval()\n",
    "print(\"Training completed after {} epochs\".format(epochs))\n",
    "\n",
    "users_test = samples_test[:, 0:1]\n",
    "pos_test = samples_test[:, 1:2]\n",
    "neg_test = samples_test[:, 2:3]\n",
    "\n",
    "loss_test, reg_loss_test = bpr_loss(\n",
    "    lightGCN, users_test, pos_test, neg_test, mov, test_mask)\n",
    "reg_loss_test = reg_loss_test * weight_decay\n",
    "\n",
    "# predict on the test set\n",
    "user_indices = samples_test[:, 0]\n",
    "user_indices = user_indices.repeat(2).long()\n",
    "item_indices = torch.cat((samples_test[:, 1], samples_test[:, 2])).long()\n",
    "pred_test = getUsersRating(lightGCN, users_test[:,0], mov)\\\n",
    "    [user_indices, item_indices]\n",
    "truth_test = global_edge_index[users_test.long()[:,0]]\\\n",
    "    [user_indices, item_indices]\n",
    "test_topk_precision, test_topk_recall = personalized_topk(\n",
    "    pred_test, K, user_indices, global_edge_index)\n",
    "\n",
    "print(\"Average bpr_loss on the test set is {}, and regularization loss is {}.\\n\".format(round(float((loss_test+reg_loss_test)/len(samples_test)), 6),\n",
    "                                                                                                round(float(reg_loss_test/len(samples_test)), 6)),\n",
    "      \"Top K precision = {}, recall = {}.\".format(test_topk_precision, test_topk_recall))\n",
    "\n",
    "# Save model embeddings.\n",
    "torch.save(lightGCN, config_dict[\"model_name\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64d33dad-8bb4-4f4b-8874-b1fa1c6c1609",
   "metadata": {},
   "source": [
    "# Baseline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a1c8a704",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline (PARAFAC matrix factorization) produces  Top K precision = 0.014866666666666771, recall = 0.00645557951088146.\n"
     ]
    }
   ],
   "source": [
    "from tensorly import decomposition\n",
    "\n",
    "def matrix_factorization(user_item, rank):\n",
    "    \"\"\"Runs matrix factorization on `user_item` and get user-item similarities.\n",
    "\n",
    "    Args:\n",
    "        user_item: User-item connectivity matrix.\n",
    "        rank: Number of numbers to represent a user / item.\n",
    "\n",
    "    Returns:\n",
    "        User-item similarities.\n",
    "    \"\"\"\n",
    "    weights, (user_factors, item_factors) = \\\n",
    "        decomposition.parafac(user_item, rank)\n",
    "    similarities = user_factors @ item_factors.T\n",
    "    return 1 / (1 + np.exp(- similarities))\n",
    "\n",
    "# Compute baseline metrics using matrix factorization.\n",
    "user_indices = samples_test[:, 0]\n",
    "user_indices = user_indices.repeat(2).long()\n",
    "item_indices = torch.cat((samples_test[:, 1], samples_test[:, 2])).long()\n",
    "baseline_pred = matrix_factorization(\n",
    "        global_edge_index.detach().cpu().numpy(),\n",
    "        config_dict[\"mf_rank\"])[user_indices.cpu(), item_indices.cpu()]\n",
    "baseline_topk_precision, baseline_topk_recall = \\\n",
    "        personalized_topk(baseline_pred, config_dict[\"K\"], user_indices, global_edge_index)\n",
    "print(\"Baseline (PARAFAC matrix factorization) produces \",\n",
    "      \"Top K precision = {}, recall = {}.\".format(baseline_topk_precision,\n",
    "                                                  baseline_topk_recall))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
